{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fp30SB4bxeQb"
   },
   "source": [
    "# **Homework 12 - Reinforcement Learning**\n",
    "\n",
    "若有任何問題，歡迎來信至助教信箱 ntu-ml-2021spring-ta@googlegroups.com\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXsnCWPtWSNk"
   },
   "source": [
    "## 前置作業\n",
    "\n",
    "首先我們需要安裝必要的系統套件及 PyPi 套件。\n",
    "gym 這個套件由 OpenAI 所提供，是一套用來開發與比較 Reinforcement Learning 演算法的工具包（toolkit）。\n",
    "而其餘套件則是為了在 Notebook 中繪圖所需要的套件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1622991984585,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "u394ON6kIms5",
    "outputId": "83ae3eb5-9981-4afa-bf69-653bd6c3d2fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jun  6 15:06:24 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   35C    P0    24W / 300W |      0MiB / 16160MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 677,
     "status": "ok",
     "timestamp": 1622991985620,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "ZfEcy0_-z3ZP"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1622991985621,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "RJDIY-c30LqB"
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "\n",
    "# your workspace in your drive\n",
    "#workspace = 'ML2021-hw12'\n",
    "\n",
    "#try:\n",
    "#    os.chdir(os.path.join('/content/gdrive/MyDrive/', workspace))\n",
    "#except:\n",
    "#    os.mkdir(os.path.join('/content/gdrive/MyDrive/', workspace))\n",
    "#    os.chdir(os.path.join('/content/gdrive/MyDrive/', workspace))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6398,
     "status": "ok",
     "timestamp": 1622991991999,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "5e2bScpnkVbv",
    "outputId": "f96c4c13-5277-4cab-9908-4b45f8c885aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m\r",
      "0% [Working]\u001b[0m\r",
      "            \r",
      "Hit:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
      "\u001b[33m\r",
      "0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.38)] [Co\u001b[0m\r",
      "                                                                               \r",
      "Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
      "\u001b[33m\r",
      "0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.38)] [Co\u001b[0m\u001b[33m\r",
      "0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Connecting to security.ubu\u001b[0m\r",
      "                                                                               \r",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
      "\u001b[33m\r",
      "0% [1 InRelease gpgv 15.9 kB] [3 InRelease 14.2 kB/88.7 kB 16%] [Connecting to \u001b[0m\r",
      "                                                                               \r",
      "Hit:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
      "\u001b[33m\r",
      "0% [1 InRelease gpgv 15.9 kB] [3 InRelease 14.2 kB/88.7 kB 16%] [Connecting to \u001b[0m\r",
      "                                                                               \r",
      "Hit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
      "\u001b[33m\r",
      "0% [1 InRelease gpgv 15.9 kB] [3 InRelease 15.6 kB/88.7 kB 18%] [Connecting to \u001b[0m\u001b[33m\r",
      "0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Connecting to security.ubu\u001b[0m\r",
      "                                                                               \r",
      "Hit:6 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
      "\u001b[33m\r",
      "0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Connecting to security.ubu\u001b[0m\r",
      "                                                                               \r",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
      "\u001b[33m\r",
      "0% [1 InRelease gpgv 15.9 kB] [7 InRelease 11.3 kB/74.6 kB 15%] [Connecting to \u001b[0m\u001b[33m\r",
      "0% [1 InRelease gpgv 15.9 kB] [Connecting to security.ubuntu.com (91.189.91.38)\u001b[0m\r",
      "                                                                               \r",
      "Hit:8 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
      "\u001b[33m\r",
      "0% [1 InRelease gpgv 15.9 kB] [Connecting to security.ubuntu.com (91.189.91.38)\u001b[0m\r",
      "                                                                               \r",
      "Get:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
      "Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
      "Ign:11 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
      "Hit:12 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
      "Hit:13 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
      "Fetched 252 kB in 2s (148 kB/s)\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "46 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
      "xvfb is already the newest version (2:1.19.6-1ubuntu4.9).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n",
      "Requirement already satisfied: gym[box2d]==0.18.3 in /usr/local/lib/python3.7/dist-packages (0.18.3)\n",
      "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (2.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
      "Requirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (1.19.5)\n",
      "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (1.4.1)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (1.3.0)\n",
      "Requirement already satisfied: pyglet<=1.5.15,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (1.5.0)\n",
      "Requirement already satisfied: Pillow<=8.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (7.1.2)\n",
      "Requirement already satisfied: box2d-py~=2.3.5; extra == \"box2d\" in /usr/local/lib/python3.7/dist-packages (from gym[box2d]==0.18.3) (2.3.8)\n",
      "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.7/dist-packages (from pyvirtualdisplay) (0.3)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.7.4.3)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.15,>=1.4.0->gym[box2d]==0.18.3) (0.16.0)\n"
     ]
    }
   ],
   "source": [
    "!apt update\n",
    "!apt install python-opengl xvfb -y\n",
    "!pip install gym[box2d]==0.18.3 pyvirtualdisplay tqdm numpy==1.19.5 torch==1.8.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_-i3cdoYsks"
   },
   "source": [
    "接下來，設置好 virtual display，並引入所有必要的套件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 718,
     "status": "ok",
     "timestamp": 1622991992712,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "nl2nREINDLiw"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "from pyvirtualdisplay import Display\n",
    "virtual_display = Display(visible=0, size=(1400, 900))\n",
    "virtual_display.start()\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython import display\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HVu9-Vdrl4E3"
   },
   "source": [
    "# 請不要更改 random seed !!!!\n",
    "# 不然在judgeboi上 你的成績不會被reproduce !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 84,
     "status": "ok",
     "timestamp": 1622991992713,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "fV9i8i2YkRbO"
   },
   "outputs": [],
   "source": [
    "seed = 543 # Do not change this\n",
    "def fix(env, seed):\n",
    "    env.seed(seed)\n",
    "    env.action_space.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.set_deterministic(True)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "He0XDx6bzjgC"
   },
   "source": [
    "最後，引入 OpenAI 的 gym，並建立一個 [Lunar Lander](https://gym.openai.com/envs/LunarLander-v2/) 環境。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 83,
     "status": "ok",
     "timestamp": 1622991992713,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "N_4-xJcbBt09"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import gym\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('LunarLander-v2')\n",
    "\n",
    "fix(env, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 83,
     "status": "ok",
     "timestamp": 1622991992714,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "NmiAOfqRwRX5"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NrkVvTrvWZ5H"
   },
   "source": [
    "## 什麼是 Lunar Lander？\n",
    "\n",
    "“LunarLander-v2” 這個環境是在模擬登月小艇降落在月球表面時的情形。\n",
    "這個任務的目標是讓登月小艇「安全地」降落在兩個黃色旗幟間的平地上。\n",
    "> Landing pad is always at coordinates (0,0).\n",
    "> Coordinates are the first two numbers in state vector.\n",
    "\n",
    "![](https://gym.openai.com/assets/docs/aeloop-138c89d44114492fd02822303e6b4b07213010bb14ca5856d2d49d6b62d88e53.svg)\n",
    "\n",
    "所謂的「環境」其實同時包括了 agent 和 environment。\n",
    "我們利用 `step()` 這個函式讓 agent 行動，而後函式便會回傳 environment 給予的 observation/state（以下這兩個名詞代表同樣的意思）和 reward。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIbp82sljvAt"
   },
   "source": [
    "### Observation / State\n",
    "\n",
    "首先，我們可以看看 environment 回傳給 agent 的 observation 究竟是長什麼樣子的資料："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83,
     "status": "ok",
     "timestamp": 1622991992715,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "rsXZra3N9R5T",
    "outputId": "f811e8c2-3bb8-403d-b79e-aa65e4eff691"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box(-inf, inf, (8,), float32)\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezdfoThbAQ49"
   },
   "source": [
    "`Box(8,)` 說明我們會拿到 8 維的向量作為 observation，其中包含：垂直及水平座標、速度、角度、加速度等等，這部分我們就不細說。\n",
    "> State has 8 components: horizontal and vertical position, horizontal and vertical velocity, angle and angular velocity, and left and right leg contact\n",
    "### Action\n",
    "\n",
    "而在 agent 得到 observation 和 reward 以後，能夠採取的動作有："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83,
     "status": "ok",
     "timestamp": 1622991992716,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "p1k4dIrBAaKi",
    "outputId": "31d17754-f833-4e49-87d8-cb83e2a8985c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(4)\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dejXT6PHBrPn"
   },
   "source": [
    "`Discrete(4)` 說明 agent 可以採取四種離散的行動：\n",
    "- 0 代表不採取任何行動\n",
    "- 2 代表主引擎向下噴射\n",
    "- 1, 3 則是向左右噴射\n",
    "\n",
    "接下來，我們嘗試讓 agent 與 environment 互動。\n",
    "在進行任何操作前，建議先呼叫 `reset()` 函式讓整個「環境」重置。\n",
    "而這個函式同時會回傳「環境」最初始的狀態。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 71,
     "status": "ok",
     "timestamp": 1622991992716,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "pi4OmrmZgnWA",
    "outputId": "4e9a1751-6e75-43f3-8b7b-ce64de303cad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00396109  1.4083536   0.40119505 -0.11407257 -0.00458307 -0.09087662\n",
      "  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "initial_state = env.reset()\n",
    "print(initial_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBx0mEqqgxJ9"
   },
   "source": [
    "接著，我們試著從 agent 的四種行動空間中，隨機採取一個行動"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 59,
     "status": "ok",
     "timestamp": 1622991992717,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "vxkOEXRKgizt",
    "outputId": "c4fc28bd-b61a-4d8e-d58a-2fa65ce8210d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "random_action = env.action_space.sample()\n",
    "print(random_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mns-bO01g0-J"
   },
   "source": [
    "再利用 `step()` 函式讓 agent 根據我們隨機抽樣出來的 `random_action` 動作。\n",
    "而這個函式會回傳四項資訊：\n",
    "- observation / state\n",
    "- reward\n",
    "- 完成與否\n",
    "- 其餘資訊"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1622991992717,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "E_WViSxGgIk9"
   },
   "outputs": [],
   "source": [
    "observation, reward, done, info = env.step(random_action)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdieGq7NuBIm"
   },
   "source": [
    "第一項資訊 `observation` 即為 agent 採取行動之後，agent 對於環境的 observation 或者說環境的 state 為何。\n",
    "而第三項資訊 `done` 則是 `True` 或 `False` 的布林值，當登月小艇成功著陸或是不幸墜毀時，代表這個回合（episode）也就跟著結束了，此時 `step()` 函式便會回傳 `done = True`，而在那之前，`done` 則保持 `False`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48,
     "status": "ok",
     "timestamp": 1622991992718,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "WFpGJYdSIlCp",
    "outputId": "8d32d775-29e5-4006-dc50-5cb3ff022efd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00792227  1.4052099   0.4006532  -0.139737   -0.00907371 -0.08982073\n",
      "  0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36,
     "status": "ok",
     "timestamp": 1622991992718,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "yK7r126kuCNp",
    "outputId": "f11e92e3-42e0-4f72-d6e0-1b463b7d4aad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(done)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GKdS8vOihxhc"
   },
   "source": [
    "### Reward\n",
    "\n",
    "而「環境」給予的 reward 大致是這樣計算：\n",
    "- 小艇墜毀得到 -100 分\n",
    "- 小艇在黃旗幟之間成功著地則得 100~140 分\n",
    "- 噴射主引擎（向下噴火）每次 -0.3 分\n",
    "- 小艇最終完全靜止則再得 100 分\n",
    "- 小艇每隻腳碰觸地面 +10 分\n",
    "\n",
    "> Reward for moving from the top of the screen to landing pad and zero speed is about 100..140 points.\n",
    "> If lander moves away from landing pad it loses reward back.\n",
    "> Episode finishes if the lander crashes or comes to rest, receiving additional -100 or +100 points.\n",
    "> Each leg ground contact is +10.\n",
    "> Firing main engine is -0.3 points each frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1622991992719,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "vxQNs77hi0_7",
    "outputId": "52a2ce24-4a66-41e7-95aa-46221072f67b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.8588900517154912\n"
     ]
    }
   ],
   "source": [
    "print(reward) # after doing a random action (0), the immediate reward is stored in this "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mhqp6D-XgHpe"
   },
   "source": [
    "### Random Agent\n",
    "\n",
    "最後，在進入實做之前，我們就來看看這樣一個 random agent 能否成功登陸月球："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "executionInfo": {
     "elapsed": 10436,
     "status": "ok",
     "timestamp": 1622992003142,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "Y3G0bxoccelv",
    "outputId": "2d473ea0-eef1-4cb6-ab6a-0b70f04159e5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.reset()\n",
    "\n",
    "img = plt.imshow(env.render(mode='rgb_array'))\n",
    "\n",
    "done = False\n",
    "while not done:\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, _ = env.step(action)\n",
    "\n",
    "    img.set_data(env.render(mode='rgb_array'))\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F5paWqo7tWL2"
   },
   "source": [
    "# DQN\n",
    "\n",
    "現在來搭建一個簡單的 policy network。\n",
    "我們預設模型的輸入是 8-dim 的 observation，輸出則是離散的四個動作之一："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1622992003143,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "J8tdmeD-tZew"
   },
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    \"\"\"Actor (Policy) Model.\"\"\"\n",
    "\n",
    "    def __init__(self, state_size=8, action_size=4, fc1_units=64, fc2_units=64):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Params\n",
    "        ======\n",
    "            state_size (int): Dimension of each state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            fc1_units (int): Number of nodes in first hidden layer\n",
    "            fc2_units (int): Number of nodes in second hidden layer\n",
    "        \"\"\"\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, fc1_units)\n",
    "        self.fc2 = nn.Linear(fc1_units, fc2_units)\n",
    "        self.fc3 = nn.Linear(fc2_units, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        \"\"\"Build a network that maps state -> action values.\"\"\"\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynbqJrhIFTC3"
   },
   "source": [
    "再來，搭建一個簡單的 agent，並搭配上方的 policy network 來採取行動。\n",
    "這個 agent 能做到以下幾件事：\n",
    "- `learn()`：從記下來的 log probabilities 及 rewards 來更新 policy network。\n",
    "- `sample()`：從 environment 得到 observation 之後，利用 policy network 得出應該採取的行動。\n",
    "而此函式除了回傳抽樣出來的 action，也會回傳此次抽樣的 log probabilities。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1622992003144,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "d3SSjdnNIlCw"
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "class ReplayMemory:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "    def __init__(self, CAPACITY):\n",
    "        self.capacity = CAPACITY  \n",
    "        self.memory = []  \n",
    "        self.index = 0  \n",
    "        self.transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "        \n",
    "    def push(self, state, action, state_next, reward):\n",
    "        \"\"\"Push a new experience to memory.\"\"\"\n",
    "        if len(self.memory) < self.capacity: # if still has capacity, initialize memory[index] to None\n",
    "            self.memory.append(None)\n",
    "\n",
    "        self.memory[self.index] = self.transition(state, action, state_next, reward)\n",
    "\n",
    "        self.index = (self.index + 1) % self.capacity  # circular index\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"Randomly sample a batch of experiences from memory.\"\"\"\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1622992003144,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "zZo-IxJx286z"
   },
   "outputs": [],
   "source": [
    "class DQNAgent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "    def __init__(self, num_states, num_actions):\n",
    "        \"\"\"Initialize an Agent object.\"\"\"\n",
    "        \n",
    "        self.num_states = num_states\n",
    "        self.num_actions = num_actions\n",
    "        \n",
    "        # Replay memory\n",
    "        self.memory_capacity = 10000\n",
    "        self.memory = ReplayMemory(self.memory_capacity)\n",
    "        \n",
    "        # Q-Network\n",
    "        self.main_q_network = DQN() \n",
    "        self.target_q_network = DQN()\n",
    "        \n",
    "        # optimizer\n",
    "        self.optimizer = optim.RMSprop(self.main_q_network.parameters(), lr=1e-4)\n",
    "    \n",
    "    def update_q_function(self):\n",
    "        '''update q function'''\n",
    "        \n",
    "        # no enough samples, just return\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "        # If enough samples are available in memory, get random subset and learn\n",
    "        self.batch, self.state_batch, self.action_batch, self.reward_batch, self.non_final_next_states = self.make_minibatch()\n",
    "        \n",
    "        self.expected_state_action_values = self.get_expected_state_action_values()\n",
    "\n",
    "        self.update_main_q_network()\n",
    "\n",
    "    def make_minibatch(self):\n",
    "        '''Creating a mini-batch'''\n",
    "\n",
    "        transitions = self.memory.sample(BATCH_SIZE)\n",
    "\n",
    "        Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward'))\n",
    "        batch = Transition(*zip(*transitions))\n",
    "\n",
    "\n",
    "        state_batch = torch.cat(batch.state)\n",
    "        action_batch = torch.cat(batch.action)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "        non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                           if s is not None])\n",
    "\n",
    "        return batch, state_batch, action_batch, reward_batch, non_final_next_states\n",
    "\n",
    "    def get_expected_state_action_values(self):\n",
    "        '''calculate Q（St,at）'''\n",
    "\n",
    "        self.main_q_network.eval()\n",
    "        self.target_q_network.eval()\n",
    "\n",
    "        self.state_action_values = self.main_q_network(\n",
    "            self.state_batch).gather(1, self.action_batch)\n",
    "\n",
    "        non_final_mask = torch.BoolTensor(tuple(map(lambda s: s is not None,\n",
    "                                                    self.batch.next_state)))\n",
    "        # set all state to 0\n",
    "        next_state_values = torch.zeros(BATCH_SIZE)\n",
    "\n",
    "        next_state_values[non_final_mask] = self.target_q_network(\n",
    "            self.non_final_next_states).max(1)[0].detach()\n",
    "        # DQN formula\n",
    "        expected_state_action_values = self.reward_batch + GAMMA * next_state_values\n",
    "        \n",
    "        return expected_state_action_values \n",
    "        \n",
    "    def get_action(self, state, episode, test=False):\n",
    "        \"\"\"Returns actions for given state as per current policy.\"\"\"\n",
    "        if test:\n",
    "            self.main_q_network.eval()\n",
    "            with torch.no_grad():\n",
    "                # t.max(1) will return largest column value of each row.\n",
    "                # second column on max result is index of where max element was\n",
    "                # found, so we pick action with the larger expected reward.\n",
    "                action = self.main_q_network(torch.from_numpy(state).unsqueeze(0)).max(1)[1].view(1, 1)\n",
    "            return action.item()\n",
    "        \n",
    "        global steps_done\n",
    "        # Epsilon-greedy policy\n",
    "        #epsilon = episode\n",
    "        #epsilon = 0.5 * (1 / (episode + 1))\n",
    "        epsilon = EPS_END + (EPS_START - EPS_END) * \\\n",
    "                np.exp(-1. * steps_done / EPS_DECAY)\n",
    "        #print('epsilon', epsilon)\n",
    "        \n",
    "        steps_done += 1\n",
    "        \n",
    "        if epsilon <= np.random.uniform(0, 1):\n",
    "            #print('use max')\n",
    "            self.main_q_network.eval()\n",
    "            with torch.no_grad():\n",
    "                # t.max(1) will return largest column value of each row.\n",
    "                # second column on max result is index of where max element was\n",
    "                # found, so we pick action with the larger expected reward.\n",
    "                action = self.main_q_network(state).max(1)[1].view(1, 1)\n",
    "        else:\n",
    "            #print('random')\n",
    "            action = torch.LongTensor(\n",
    "                [[random.randrange(self.num_actions)]])  \n",
    "            \n",
    "        return action\n",
    "\n",
    "    def update_main_q_network(self):\n",
    "        \n",
    "        '''update main q net'''\n",
    "\n",
    "        # set train mode\n",
    "        self.main_q_network.train()\n",
    "        # Hurberloss function\n",
    "        # expected_state_action_values (minbatch,)->(minbatchx1)\n",
    "\n",
    "        loss = F.smooth_l1_loss(self.state_action_values,\n",
    "                                self.expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "        # update\n",
    "        self.optimizer.zero_grad()  # reset gradient\n",
    "        loss.backward()  # backpropagation\n",
    "        for param in self.main_q_network.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        self.optimizer.step()  # update network\n",
    "\n",
    "\n",
    "    def memorize(self, state, action, state_next, reward):\n",
    "        '''save state, action, state_next, reward into replay memory'''\n",
    "        self.memory.push(state, action, state_next, reward)\n",
    "\n",
    "    def update_target_q_function(self):\n",
    "        \n",
    "        '''synchronize Target Q-Network to Main Q-Network'''\n",
    "        self.target_q_network.load_state_dict(self.main_q_network.state_dict())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ehPlnTKyRZf9"
   },
   "source": [
    "最後，建立一個 network 和 agent，就可以開始進行訓練了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1622992003145,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "GfJIvML-RYjL"
   },
   "outputs": [],
   "source": [
    "network = DQN()\n",
    "agent = DQNAgent(env.observation_space.shape[0], env.action_space.n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ouv23glgf5Qt"
   },
   "source": [
    "## 訓練 Agent\n",
    "\n",
    "現在我們開始訓練 agent。\n",
    "透過讓 agent 和 environment 互動，我們記住每一組對應的 log probabilities 及 reward，並在成功登陸或者不幸墜毀後，回放這些「記憶」來訓練 policy network。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "933a3ea3831648e4bcb7079e47580691",
      "ca77cc53f271432ca4f311eb34098250",
      "09d8700c082848af8328d746998e721b",
      "4aef868dce034f94a52ce46fd19cbc88",
      "98c7bd45812b402d95230e781fb7cfec",
      "976ca84aba354ed1ad46487b9e91c8ea",
      "88588620a2314c1b87eb37a1a84b0a7c",
      "cf7ecf87efa5404982dc47579d1275cb"
     ]
    },
    "executionInfo": {
     "elapsed": 3842984,
     "status": "ok",
     "timestamp": 1622995846121,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "vg5rxBBaf38_",
    "outputId": "9b35607a-0186-45b8-8496-a00e73d88671",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933a3ea3831648e4bcb7079e47580691",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=600.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.from_numpy(rewards) looks like  torch.Size([712])\n",
      "-196.5292340798315\n",
      "length of actions is  65\n",
      "-248.4060791636938\n",
      "length of actions is  66\n",
      "-229.0882009391201\n",
      "length of actions is  68\n",
      "-240.0468410449334\n",
      "length of actions is  67\n",
      "-364.3726309414928\n",
      "length of actions is  79\n",
      "Your final reward is : -255.69\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/__init__.py:422: UserWarning: torch.set_deterministic is deprecated and will be removed in a future release. Please use torch.use_deterministic_algorithms instead\n",
      "  \"torch.set_deterministic is deprecated and will be removed in a future \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.from_numpy(rewards) looks like  torch.Size([358])\n",
      "-295.80096012708566\n",
      "length of actions is  64\n",
      "-398.18011003102254\n",
      "length of actions is  76\n",
      "-312.4317717193137\n",
      "length of actions is  66\n",
      "-109.81622709782555\n",
      "length of actions is  76\n",
      "-113.36256609710372\n",
      "length of actions is  64\n",
      "Your final reward is : -245.92\n",
      "torch.from_numpy(rewards) looks like  torch.Size([373])\n",
      "-211.20014515260644\n",
      "length of actions is  65\n",
      "-78.97505840467004\n",
      "length of actions is  73\n",
      "-213.0882867476982\n",
      "length of actions is  52\n",
      "-197.56959249021003\n",
      "length of actions is  86\n",
      "-242.39172824198\n",
      "length of actions is  64\n",
      "Your final reward is : -188.64\n",
      "torch.from_numpy(rewards) looks like  torch.Size([534])\n",
      "-118.02922148881689\n",
      "length of actions is  152\n",
      "78.53997632164662\n",
      "length of actions is  1000\n",
      "12.507114424198392\n",
      "length of actions is  163\n",
      "245.26813575122577\n",
      "length of actions is  266\n",
      "10.266348106086127\n",
      "length of actions is  192\n",
      "Your final reward is : 45.71\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3456])\n",
      "-443.01542022254193\n",
      "length of actions is  204\n",
      "-270.33337082447156\n",
      "length of actions is  252\n",
      "-444.66456085761155\n",
      "length of actions is  333\n",
      "-295.17125880774023\n",
      "length of actions is  187\n",
      "-164.57164459688568\n",
      "length of actions is  227\n",
      "Your final reward is : -323.55\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1118])\n",
      "-370.7600330414103\n",
      "length of actions is  175\n",
      "-546.2358029810446\n",
      "length of actions is  214\n",
      "-462.4728981861137\n",
      "length of actions is  187\n",
      "-485.33744572449245\n",
      "length of actions is  246\n",
      "-365.02130643932037\n",
      "length of actions is  107\n",
      "Your final reward is : -445.97\n",
      "torch.from_numpy(rewards) looks like  torch.Size([915])\n",
      "-63.792295148290556\n",
      "length of actions is  194\n",
      "-278.95273892301634\n",
      "length of actions is  227\n",
      "-236.10070151010592\n",
      "length of actions is  178\n",
      "-57.70800500993206\n",
      "length of actions is  135\n",
      "-465.5401696130633\n",
      "length of actions is  174\n",
      "Your final reward is : -220.42\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1205])\n",
      "-769.9693505339534\n",
      "length of actions is  178\n",
      "-429.5175078991421\n",
      "length of actions is  172\n",
      "-762.349360897876\n",
      "length of actions is  173\n",
      "-448.2083440473457\n",
      "length of actions is  167\n",
      "-883.3752246424536\n",
      "length of actions is  177\n",
      "Your final reward is : -658.68\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1435])\n",
      "-451.94998532891105\n",
      "length of actions is  307\n",
      "-459.6303093245833\n",
      "length of actions is  383\n",
      "-319.617129954037\n",
      "length of actions is  903\n",
      "-998.1985284909762\n",
      "length of actions is  246\n",
      "-643.698104507775\n",
      "length of actions is  294\n",
      "Your final reward is : -574.62\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2088])\n",
      "-68.05319749840136\n",
      "length of actions is  1000\n",
      "-233.67352890239013\n",
      "length of actions is  523\n",
      "111.0150736022546\n",
      "length of actions is  965\n",
      "-297.5802553518187\n",
      "length of actions is  1000\n",
      "-82.98868894752941\n",
      "length of actions is  497\n",
      "Your final reward is : -114.26\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3706])\n",
      "86.37617371547285\n",
      "length of actions is  857\n",
      "-169.49390695913547\n",
      "length of actions is  280\n",
      "-127.8183267750716\n",
      "length of actions is  538\n",
      "-184.23207048772798\n",
      "length of actions is  1000\n",
      "-212.48019564479623\n",
      "length of actions is  1000\n",
      "Your final reward is : -121.53\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2658])\n",
      "164.13456947426482\n",
      "length of actions is  774\n",
      "168.8874087269112\n",
      "length of actions is  943\n",
      "196.69159203784892\n",
      "length of actions is  703\n",
      "166.853505031998\n",
      "length of actions is  600\n",
      "119.31023623316783\n",
      "length of actions is  638\n",
      "Your final reward is : 163.18\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3085])\n",
      "-220.3909394019949\n",
      "length of actions is  379\n",
      "-8.359589537135719\n",
      "length of actions is  324\n",
      "-194.63083248727608\n",
      "length of actions is  234\n",
      "-264.937994586608\n",
      "length of actions is  467\n",
      "210.25920522594066\n",
      "length of actions is  450\n",
      "Your final reward is : -95.61\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1784])\n",
      "80.61130999763229\n",
      "length of actions is  1000\n",
      "210.96045720718058\n",
      "length of actions is  548\n",
      "-222.5319005742698\n",
      "length of actions is  362\n",
      "-193.24088773220768\n",
      "length of actions is  284\n",
      "63.0536855774563\n",
      "length of actions is  1000\n",
      "Your final reward is : -12.23\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2983])\n",
      "-17.054404751028812\n",
      "length of actions is  377\n",
      "-234.3548517216685\n",
      "length of actions is  426\n",
      "-119.76464257774829\n",
      "length of actions is  1000\n",
      "102.04139326429421\n",
      "length of actions is  1000\n",
      "210.84644885343923\n",
      "length of actions is  449\n",
      "Your final reward is : -11.66\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3273])\n",
      "-24.75194506529356\n",
      "length of actions is  1000\n",
      "139.71050483422286\n",
      "length of actions is  1000\n",
      "125.86760011228421\n",
      "length of actions is  1000\n",
      "-6.548262719377789\n",
      "length of actions is  296\n",
      "-149.22851007020182\n",
      "length of actions is  1000\n",
      "Your final reward is : 17.01\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3031])\n",
      "-115.49403139381599\n",
      "length of actions is  1000\n",
      "209.14508546208666\n",
      "length of actions is  762\n",
      "-105.17019145602717\n",
      "length of actions is  1000\n",
      "27.73156930642766\n",
      "length of actions is  252\n",
      "64.93200731137745\n",
      "length of actions is  1000\n",
      "Your final reward is : 16.23\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4081])\n",
      "-134.1344203216365\n",
      "length of actions is  1000\n",
      "-69.75298524548808\n",
      "length of actions is  1000\n",
      "-90.47058229796686\n",
      "length of actions is  1000\n",
      "-125.68224332644053\n",
      "length of actions is  1000\n",
      "-159.86328488451042\n",
      "length of actions is  1000\n",
      "Your final reward is : -115.98\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3759])\n",
      "-137.7847497728999\n",
      "length of actions is  1000\n",
      "-78.35396276854367\n",
      "length of actions is  1000\n",
      "-94.10151423155149\n",
      "length of actions is  1000\n",
      "-131.70371163200284\n",
      "length of actions is  1000\n",
      "-171.75047862576352\n",
      "length of actions is  1000\n",
      "Your final reward is : -122.74\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4239])\n",
      "-127.40429522231078\n",
      "length of actions is  1000\n",
      "-85.80085561475249\n",
      "length of actions is  1000\n",
      "-104.42493967404748\n",
      "length of actions is  1000\n",
      "-122.73206325118511\n",
      "length of actions is  1000\n",
      "-155.84188027874796\n",
      "length of actions is  1000\n",
      "Your final reward is : -119.24\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4226])\n",
      "-142.97666453735454\n",
      "length of actions is  1000\n",
      "-92.44469614027365\n",
      "length of actions is  1000\n",
      "-99.95172476378667\n",
      "length of actions is  1000\n",
      "-133.93869842044265\n",
      "length of actions is  1000\n",
      "-167.99273776562822\n",
      "length of actions is  1000\n",
      "Your final reward is : -127.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4487])\n",
      "-141.75997922447127\n",
      "length of actions is  1000\n",
      "-71.38868537991334\n",
      "length of actions is  1000\n",
      "-84.14702359156753\n",
      "length of actions is  1000\n",
      "-131.48007200275595\n",
      "length of actions is  1000\n",
      "-165.28422898571\n",
      "length of actions is  1000\n",
      "Your final reward is : -118.81\n",
      "torch.from_numpy(rewards) looks like  torch.Size([5000])\n",
      "-123.3387674706198\n",
      "length of actions is  1000\n",
      "-72.00391903015158\n",
      "length of actions is  1000\n",
      "-81.54422071265827\n",
      "length of actions is  1000\n",
      "-115.20773100086656\n",
      "length of actions is  1000\n",
      "-152.8317184652679\n",
      "length of actions is  1000\n",
      "Your final reward is : -108.99\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4775])\n",
      "-101.21722612084358\n",
      "length of actions is  1000\n",
      "-14.585883173372657\n",
      "length of actions is  1000\n",
      "-32.03331997121352\n",
      "length of actions is  1000\n",
      "-84.30651496937492\n",
      "length of actions is  1000\n",
      "-127.32105153408824\n",
      "length of actions is  1000\n",
      "Your final reward is : -71.89\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4285])\n",
      "-97.97623358682074\n",
      "length of actions is  1000\n",
      "21.27044517702805\n",
      "length of actions is  1000\n",
      "14.602347461855814\n",
      "length of actions is  1000\n",
      "-86.77889505498054\n",
      "length of actions is  1000\n",
      "-126.40255155005516\n",
      "length of actions is  1000\n",
      "Your final reward is : -55.06\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4274])\n",
      "-86.80718135672439\n",
      "length of actions is  1000\n",
      "13.490507501966018\n",
      "length of actions is  1000\n",
      "109.78175290008734\n",
      "length of actions is  758\n",
      "-82.01913445638078\n",
      "length of actions is  1000\n",
      "95.75616599850848\n",
      "length of actions is  881\n",
      "Your final reward is : 10.04\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4140])\n",
      "-86.83623768140531\n",
      "length of actions is  1000\n",
      "-21.289028960992145\n",
      "length of actions is  1000\n",
      "77.18907414260002\n",
      "length of actions is  860\n",
      "-71.73407339623104\n",
      "length of actions is  1000\n",
      "224.820779803626\n",
      "length of actions is  566\n",
      "Your final reward is : 24.43\n",
      "torch.from_numpy(rewards) looks like  torch.Size([5000])\n",
      "-45.81212622536282\n",
      "length of actions is  1000\n",
      "145.8350191286533\n",
      "length of actions is  579\n",
      "112.65530414981548\n",
      "length of actions is  620\n",
      "71.65902895779185\n",
      "length of actions is  1000\n",
      "-37.307857721538085\n",
      "length of actions is  1000\n",
      "Your final reward is : 49.41\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4018])\n",
      "-69.73222288242002\n",
      "length of actions is  1000\n",
      "193.85293177556008\n",
      "length of actions is  253\n",
      "-88.7803284732008\n",
      "length of actions is  223\n",
      "-82.8199296986904\n",
      "length of actions is  151\n",
      "-84.09272909194306\n",
      "length of actions is  196\n",
      "Your final reward is : -26.31\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4070])\n",
      "-64.95801929387713\n",
      "length of actions is  1000\n",
      "-51.160961202924014\n",
      "length of actions is  153\n",
      "188.95220690809083\n",
      "length of actions is  338\n",
      "-77.16871090537218\n",
      "length of actions is  238\n",
      "-33.644986063024504\n",
      "length of actions is  1000\n",
      "Your final reward is : -7.60\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1754])\n",
      "-28.742350581630344\n",
      "length of actions is  1000\n",
      "-55.684253975805106\n",
      "length of actions is  147\n",
      "-74.00947267486882\n",
      "length of actions is  454\n",
      "280.28168942841364\n",
      "length of actions is  397\n",
      "-64.15765212485907\n",
      "length of actions is  142\n",
      "Your final reward is : 11.54\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3600])\n",
      "-23.158695416213597\n",
      "length of actions is  1000\n",
      "-14.39056246683306\n",
      "length of actions is  173\n",
      "121.33712041051058\n",
      "length of actions is  343\n",
      "-59.39132194124085\n",
      "length of actions is  161\n",
      "154.08449748535682\n",
      "length of actions is  612\n",
      "Your final reward is : 35.70\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3163])\n",
      "83.96947924605098\n",
      "length of actions is  949\n",
      "-124.05548197527068\n",
      "length of actions is  703\n",
      "-84.22876517751938\n",
      "length of actions is  327\n",
      "128.20820077321673\n",
      "length of actions is  327\n",
      "-30.505896223770606\n",
      "length of actions is  1000\n",
      "Your final reward is : -5.32\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3971])\n",
      "62.71740945762835\n",
      "length of actions is  978\n",
      "56.65213650074941\n",
      "length of actions is  955\n",
      "-206.63519883953916\n",
      "length of actions is  685\n",
      "133.94078470537846\n",
      "length of actions is  526\n",
      "-55.29093389730037\n",
      "length of actions is  1000\n",
      "Your final reward is : -1.72\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3561])\n",
      "-27.843464938746102\n",
      "length of actions is  1000\n",
      "146.93978288466099\n",
      "length of actions is  442\n",
      "164.0691599681121\n",
      "length of actions is  272\n",
      "-42.61223849842775\n",
      "length of actions is  1000\n",
      "-91.43702394010982\n",
      "length of actions is  567\n",
      "Your final reward is : 29.82\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4352])\n",
      "-64.11906526799494\n",
      "length of actions is  1000\n",
      "210.48609502011834\n",
      "length of actions is  491\n",
      "-115.45984341525876\n",
      "length of actions is  692\n",
      "189.32223672117235\n",
      "length of actions is  458\n",
      "-113.71664091890386\n",
      "length of actions is  490\n",
      "Your final reward is : 21.30\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4245])\n",
      "79.5560015319421\n",
      "length of actions is  757\n",
      "103.58271916506622\n",
      "length of actions is  963\n",
      "-35.22627172963074\n",
      "length of actions is  181\n",
      "214.46109568167196\n",
      "length of actions is  254\n",
      "134.97747376426994\n",
      "length of actions is  803\n",
      "Your final reward is : 99.47\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2966])\n",
      "66.7390316207385\n",
      "length of actions is  814\n",
      "160.52421464848248\n",
      "length of actions is  745\n",
      "-100.28358133372181\n",
      "length of actions is  426\n",
      "-72.83217759307254\n",
      "length of actions is  297\n",
      "-63.89361119851472\n",
      "length of actions is  496\n",
      "Your final reward is : -1.95\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2921])\n",
      "125.52101591503538\n",
      "length of actions is  504\n",
      "-42.04592898400364\n",
      "length of actions is  249\n",
      "37.89353431019795\n",
      "length of actions is  1000\n",
      "69.65667024724576\n",
      "length of actions is  823\n",
      "-18.610130555647856\n",
      "length of actions is  199\n",
      "Your final reward is : 34.48\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2745])\n",
      "150.50090184466944\n",
      "length of actions is  328\n",
      "166.595864568516\n",
      "length of actions is  307\n",
      "-161.3229858338131\n",
      "length of actions is  323\n",
      "193.91044944122433\n",
      "length of actions is  222\n",
      "184.34023180872146\n",
      "length of actions is  251\n",
      "Your final reward is : 106.80\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1773])\n",
      "-69.1658720284504\n",
      "length of actions is  127\n",
      "-107.90648101061188\n",
      "length of actions is  96\n",
      "-76.61996352187435\n",
      "length of actions is  105\n",
      "192.78382853981043\n",
      "length of actions is  567\n",
      "-66.22141238635153\n",
      "length of actions is  210\n",
      "Your final reward is : -25.43\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2689])\n",
      "-66.46558301581523\n",
      "length of actions is  130\n",
      "-57.86999548660716\n",
      "length of actions is  90\n",
      "-27.624916441918685\n",
      "length of actions is  194\n",
      "-98.34537142886653\n",
      "length of actions is  93\n",
      "-69.35238936805247\n",
      "length of actions is  426\n",
      "Your final reward is : -63.93\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1710])\n",
      "-58.57700200741059\n",
      "length of actions is  136\n",
      "-63.679747495068284\n",
      "length of actions is  87\n",
      "-78.36981780125902\n",
      "length of actions is  104\n",
      "-104.22872439183534\n",
      "length of actions is  395\n",
      "-92.13924087786533\n",
      "length of actions is  250\n",
      "Your final reward is : -79.40\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2054])\n",
      "-52.780240597809225\n",
      "length of actions is  142\n",
      "88.15343287579229\n",
      "length of actions is  674\n",
      "-78.612391951078\n",
      "length of actions is  176\n",
      "174.15379383843901\n",
      "length of actions is  452\n",
      "157.8032428314002\n",
      "length of actions is  348\n",
      "Your final reward is : 57.74\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2315])\n",
      "-44.12452038193729\n",
      "length of actions is  143\n",
      "-53.19602859578972\n",
      "length of actions is  192\n",
      "-96.99977621872188\n",
      "length of actions is  326\n",
      "-39.50838167739528\n",
      "length of actions is  135\n",
      "-62.49130065519455\n",
      "length of actions is  137\n",
      "Your final reward is : -59.26\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1871])\n",
      "-65.5890359879222\n",
      "length of actions is  150\n",
      "179.56978680984017\n",
      "length of actions is  422\n",
      "201.9958870711502\n",
      "length of actions is  505\n",
      "164.01424979733673\n",
      "length of actions is  462\n",
      "47.309460423881504\n",
      "length of actions is  1000\n",
      "Your final reward is : 105.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2686])\n",
      "-56.049803340295895\n",
      "length of actions is  158\n",
      "-4.126289894401211\n",
      "length of actions is  344\n",
      "-41.72856609210335\n",
      "length of actions is  306\n",
      "151.30151559363736\n",
      "length of actions is  277\n",
      "213.13694235491064\n",
      "length of actions is  616\n",
      "Your final reward is : 52.51\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1835])\n",
      "-52.27686322896738\n",
      "length of actions is  139\n",
      "201.9840405843628\n",
      "length of actions is  469\n",
      "-38.151611497473965\n",
      "length of actions is  433\n",
      "-69.25181557100467\n",
      "length of actions is  178\n",
      "-75.87243401726163\n",
      "length of actions is  413\n",
      "Your final reward is : -6.71\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1716])\n",
      "-36.55229945454523\n",
      "length of actions is  149\n",
      "-70.92758446313503\n",
      "length of actions is  151\n",
      "-92.56521467634013\n",
      "length of actions is  137\n",
      "-43.838477230659876\n",
      "length of actions is  121\n",
      "-56.526218148283874\n",
      "length of actions is  121\n",
      "Your final reward is : -60.08\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1882])\n",
      "-53.59399044856912\n",
      "length of actions is  137\n",
      "-17.706206360409027\n",
      "length of actions is  317\n",
      "-60.072415270193616\n",
      "length of actions is  267\n",
      "-8.064292991822555\n",
      "length of actions is  313\n",
      "-37.87581130042098\n",
      "length of actions is  99\n",
      "Your final reward is : -35.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1178])\n",
      "-50.30354095439675\n",
      "length of actions is  145\n",
      "169.123988388874\n",
      "length of actions is  462\n",
      "-28.55759867741355\n",
      "length of actions is  95\n",
      "93.71695523584361\n",
      "length of actions is  1000\n",
      "-27.067415192662608\n",
      "length of actions is  178\n",
      "Your final reward is : 31.38\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1781])\n",
      "-58.30438767263337\n",
      "length of actions is  143\n",
      "-53.27125611955759\n",
      "length of actions is  177\n",
      "183.39167183970392\n",
      "length of actions is  266\n",
      "-64.9537320175449\n",
      "length of actions is  119\n",
      "217.8737280158088\n",
      "length of actions is  529\n",
      "Your final reward is : 44.95\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1232])\n",
      "-53.545623035787095\n",
      "length of actions is  134\n",
      "197.54680589873624\n",
      "length of actions is  396\n",
      "181.85706565704663\n",
      "length of actions is  302\n",
      "171.94441673932272\n",
      "length of actions is  318\n",
      "215.93449357926693\n",
      "length of actions is  517\n",
      "Your final reward is : 142.75\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1881])\n",
      "-47.315843044294276\n",
      "length of actions is  133\n",
      "190.32566736670555\n",
      "length of actions is  408\n",
      "-55.644721757239964\n",
      "length of actions is  157\n",
      "-53.385453095473565\n",
      "length of actions is  330\n",
      "165.6646244034133\n",
      "length of actions is  471\n",
      "Your final reward is : 39.93\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1748])\n",
      "-56.6628392738273\n",
      "length of actions is  138\n",
      "223.35457916314817\n",
      "length of actions is  433\n",
      "-27.48483147950961\n",
      "length of actions is  130\n",
      "0.5446045622606448\n",
      "length of actions is  275\n",
      "189.71676174124855\n",
      "length of actions is  349\n",
      "Your final reward is : 65.89\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2123])\n",
      "-52.575914579890515\n",
      "length of actions is  140\n",
      "105.25234160064531\n",
      "length of actions is  1000\n",
      "180.598933293566\n",
      "length of actions is  443\n",
      "146.76754805707637\n",
      "length of actions is  557\n",
      "87.22442041715827\n",
      "length of actions is  1000\n",
      "Your final reward is : 93.45\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2427])\n",
      "166.20179190396064\n",
      "length of actions is  265\n",
      "-57.90766269369661\n",
      "length of actions is  191\n",
      "186.83291963448377\n",
      "length of actions is  386\n",
      "-42.54021132753667\n",
      "length of actions is  172\n",
      "-42.02008665626552\n",
      "length of actions is  179\n",
      "Your final reward is : 42.11\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1660])\n",
      "166.3424526163128\n",
      "length of actions is  254\n",
      "209.1255844910915\n",
      "length of actions is  366\n",
      "-32.9178239954155\n",
      "length of actions is  106\n",
      "149.3091777773296\n",
      "length of actions is  486\n",
      "-42.611012756538344\n",
      "length of actions is  198\n",
      "Your final reward is : 89.85\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1886])\n",
      "155.9240104657394\n",
      "length of actions is  257\n",
      "-34.6744617830837\n",
      "length of actions is  277\n",
      "166.989194704181\n",
      "length of actions is  503\n",
      "159.39224525256975\n",
      "length of actions is  484\n",
      "-100.9791402695563\n",
      "length of actions is  183\n",
      "Your final reward is : 69.33\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1411])\n",
      "155.7485431080314\n",
      "length of actions is  261\n",
      "187.5044271593787\n",
      "length of actions is  316\n",
      "-70.11164175635571\n",
      "length of actions is  203\n",
      "160.44056257900513\n",
      "length of actions is  363\n",
      "-36.86775999526023\n",
      "length of actions is  127\n",
      "Your final reward is : 79.34\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2146])\n",
      "192.62722625998592\n",
      "length of actions is  261\n",
      "181.99533502201712\n",
      "length of actions is  336\n",
      "195.63035505160644\n",
      "length of actions is  352\n",
      "163.94484502240766\n",
      "length of actions is  417\n",
      "-13.179403257684271\n",
      "length of actions is  239\n",
      "Your final reward is : 144.20\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2728])\n",
      "162.81427296438892\n",
      "length of actions is  267\n",
      "239.32674170004375\n",
      "length of actions is  381\n",
      "211.51898518988003\n",
      "length of actions is  376\n",
      "202.36992404310737\n",
      "length of actions is  405\n",
      "219.7472271996153\n",
      "length of actions is  342\n",
      "Your final reward is : 207.16\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2341])\n",
      "192.29152324757916\n",
      "length of actions is  296\n",
      "58.126544535630856\n",
      "length of actions is  1000\n",
      "193.58850561969308\n",
      "length of actions is  894\n",
      "142.00175318812686\n",
      "length of actions is  459\n",
      "191.4269409479424\n",
      "length of actions is  466\n",
      "Your final reward is : 155.49\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2041])\n",
      "145.3218858979994\n",
      "length of actions is  383\n",
      "224.17696203463896\n",
      "length of actions is  383\n",
      "-62.78276223795828\n",
      "length of actions is  342\n",
      "177.2155026275663\n",
      "length of actions is  347\n",
      "218.6593888687355\n",
      "length of actions is  386\n",
      "Your final reward is : 140.52\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2490])\n",
      "174.01858928091667\n",
      "length of actions is  326\n",
      "165.80864994847343\n",
      "length of actions is  503\n",
      "69.50105716822661\n",
      "length of actions is  1000\n",
      "234.49328425941906\n",
      "length of actions is  186\n",
      "205.68905046169354\n",
      "length of actions is  389\n",
      "Your final reward is : 169.90\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "176.48648627434787\n",
      "length of actions is  365\n",
      "91.90438169351546\n",
      "length of actions is  1000\n",
      "183.6169056915745\n",
      "length of actions is  895\n",
      "249.33805138298297\n",
      "length of actions is  399\n",
      "131.94651677634923\n",
      "length of actions is  504\n",
      "Your final reward is : 166.66\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1680])\n",
      "162.84709639797452\n",
      "length of actions is  341\n",
      "-94.81570666039367\n",
      "length of actions is  360\n",
      "142.0206529181967\n",
      "length of actions is  475\n",
      "153.56241788408272\n",
      "length of actions is  320\n",
      "224.0167207755547\n",
      "length of actions is  322\n",
      "Your final reward is : 117.53\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2198])\n",
      "155.25597665483787\n",
      "length of actions is  384\n",
      "96.66149430350423\n",
      "length of actions is  1000\n",
      "222.6137088146047\n",
      "length of actions is  297\n",
      "155.37835303052168\n",
      "length of actions is  460\n",
      "127.94854529038705\n",
      "length of actions is  781\n",
      "Your final reward is : 151.57\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2350])\n",
      "149.40279580733653\n",
      "length of actions is  413\n",
      "-18.03374863874116\n",
      "length of actions is  169\n",
      "-4.098458815887895\n",
      "length of actions is  179\n",
      "185.76935494811897\n",
      "length of actions is  322\n",
      "193.95632849344136\n",
      "length of actions is  368\n",
      "Your final reward is : 101.40\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2317])\n",
      "64.05738098382373\n",
      "length of actions is  1000\n",
      "189.3040144539534\n",
      "length of actions is  374\n",
      "-19.36804856415698\n",
      "length of actions is  251\n",
      "-15.317759706316352\n",
      "length of actions is  236\n",
      "205.73427443282463\n",
      "length of actions is  454\n",
      "Your final reward is : 84.88\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2144])\n",
      "-21.068069582376438\n",
      "length of actions is  295\n",
      "-16.2935106607585\n",
      "length of actions is  365\n",
      "165.5100227628872\n",
      "length of actions is  443\n",
      "188.4955359708082\n",
      "length of actions is  240\n",
      "188.5493946021329\n",
      "length of actions is  581\n",
      "Your final reward is : 101.04\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2197])\n",
      "-15.645310924489095\n",
      "length of actions is  341\n",
      "-80.48615538888762\n",
      "length of actions is  228\n",
      "146.45271996550656\n",
      "length of actions is  420\n",
      "221.64444425050073\n",
      "length of actions is  377\n",
      "-40.73827147728029\n",
      "length of actions is  466\n",
      "Your final reward is : 46.25\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3211])\n",
      "-31.84690178609729\n",
      "length of actions is  315\n",
      "16.90022332791819\n",
      "length of actions is  1000\n",
      "-54.02976366078644\n",
      "length of actions is  235\n",
      "182.47423301840786\n",
      "length of actions is  448\n",
      "-8.07603066651977\n",
      "length of actions is  271\n",
      "Your final reward is : 21.08\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2086])\n",
      "-19.439174760203016\n",
      "length of actions is  355\n",
      "208.7117859315823\n",
      "length of actions is  334\n",
      "209.10632071716344\n",
      "length of actions is  254\n",
      "208.64253865476644\n",
      "length of actions is  260\n",
      "-52.81620867979814\n",
      "length of actions is  332\n",
      "Your final reward is : 110.84\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "199.96766328190967\n",
      "length of actions is  403\n",
      "68.19459554683996\n",
      "length of actions is  1000\n",
      "-22.036606183610076\n",
      "length of actions is  379\n",
      "-36.29668225874106\n",
      "length of actions is  197\n",
      "173.49505436406386\n",
      "length of actions is  419\n",
      "Your final reward is : 76.66\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2183])\n",
      "181.07789145672808\n",
      "length of actions is  432\n",
      "182.91210058323995\n",
      "length of actions is  484\n",
      "220.89209689933898\n",
      "length of actions is  450\n",
      "211.21369950481258\n",
      "length of actions is  356\n",
      "193.02110229973832\n",
      "length of actions is  445\n",
      "Your final reward is : 197.82\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2859])\n",
      "-62.69515882573408\n",
      "length of actions is  541\n",
      "193.3205736170826\n",
      "length of actions is  226\n",
      "139.84541664069818\n",
      "length of actions is  465\n",
      "144.63829850799374\n",
      "length of actions is  454\n",
      "231.7177347293958\n",
      "length of actions is  406\n",
      "Your final reward is : 129.37\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2645])\n",
      "-9.197948782719184\n",
      "length of actions is  1000\n",
      "181.74875203413467\n",
      "length of actions is  295\n",
      "173.10077567279768\n",
      "length of actions is  330\n",
      "-54.175480906659416\n",
      "length of actions is  292\n",
      "75.44857941767114\n",
      "length of actions is  1000\n",
      "Your final reward is : 73.38\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2711])\n",
      "121.93678073426264\n",
      "length of actions is  701\n",
      "53.820942108706674\n",
      "length of actions is  1000\n",
      "156.04227648212103\n",
      "length of actions is  476\n",
      "142.6970579234664\n",
      "length of actions is  531\n",
      "164.5513735006106\n",
      "length of actions is  352\n",
      "Your final reward is : 127.81\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2322])\n",
      "113.74887474061897\n",
      "length of actions is  667\n",
      "-14.255019557230312\n",
      "length of actions is  388\n",
      "205.08897087739263\n",
      "length of actions is  543\n",
      "180.28501843996014\n",
      "length of actions is  511\n",
      "170.29718929988394\n",
      "length of actions is  465\n",
      "Your final reward is : 131.03\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2730])\n",
      "94.65635569687458\n",
      "length of actions is  852\n",
      "-55.379767254444545\n",
      "length of actions is  251\n",
      "178.89715861780564\n",
      "length of actions is  254\n",
      "112.95210135787472\n",
      "length of actions is  761\n",
      "29.49660584780998\n",
      "length of actions is  1000\n",
      "Your final reward is : 72.12\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2869])\n",
      "15.285629035119767\n",
      "length of actions is  1000\n",
      "175.40366762336328\n",
      "length of actions is  627\n",
      "-49.18211356561905\n",
      "length of actions is  270\n",
      "179.20123846404988\n",
      "length of actions is  292\n",
      "191.72160857730745\n",
      "length of actions is  479\n",
      "Your final reward is : 102.49\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2539])\n",
      "-13.438375033026304\n",
      "length of actions is  357\n",
      "106.81353099043997\n",
      "length of actions is  756\n",
      "210.76338293738758\n",
      "length of actions is  430\n",
      "-150.21841451922418\n",
      "length of actions is  401\n",
      "150.19069917467465\n",
      "length of actions is  431\n",
      "Your final reward is : 60.82\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2547])\n",
      "-46.50035581938797\n",
      "length of actions is  576\n",
      "206.3097624334121\n",
      "length of actions is  494\n",
      "64.12540312369858\n",
      "length of actions is  1000\n",
      "180.1585704840561\n",
      "length of actions is  515\n",
      "166.89483238597154\n",
      "length of actions is  606\n",
      "Your final reward is : 114.20\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2979])\n",
      "-46.61732820486455\n",
      "length of actions is  531\n",
      "174.86454468644018\n",
      "length of actions is  434\n",
      "207.55060715029043\n",
      "length of actions is  395\n",
      "198.66267510726638\n",
      "length of actions is  541\n",
      "206.24497197085736\n",
      "length of actions is  451\n",
      "Your final reward is : 148.14\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3082])\n",
      "-33.886104309758096\n",
      "length of actions is  477\n",
      "201.64239936525345\n",
      "length of actions is  434\n",
      "188.88386240477956\n",
      "length of actions is  414\n",
      "207.29646174926475\n",
      "length of actions is  470\n",
      "217.62816845144448\n",
      "length of actions is  890\n",
      "Your final reward is : 156.31\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2309])\n",
      "202.96185942351593\n",
      "length of actions is  362\n",
      "144.09513037504166\n",
      "length of actions is  631\n",
      "-36.434772028140756\n",
      "length of actions is  441\n",
      "180.6246343109272\n",
      "length of actions is  315\n",
      "232.6311604384528\n",
      "length of actions is  401\n",
      "Your final reward is : 144.78\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2917])\n",
      "203.3156390375476\n",
      "length of actions is  367\n",
      "195.22975965431147\n",
      "length of actions is  429\n",
      "187.15574266373744\n",
      "length of actions is  435\n",
      "201.01096544232047\n",
      "length of actions is  902\n",
      "206.60722850225642\n",
      "length of actions is  410\n",
      "Your final reward is : 198.66\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2417])\n",
      "194.648524352824\n",
      "length of actions is  397\n",
      "226.3805714203488\n",
      "length of actions is  355\n",
      "196.91486317314286\n",
      "length of actions is  416\n",
      "163.0063221018754\n",
      "length of actions is  942\n",
      "177.78189949037937\n",
      "length of actions is  415\n",
      "Your final reward is : 191.75\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2154])\n",
      "201.76710356386357\n",
      "length of actions is  383\n",
      "230.6505979036198\n",
      "length of actions is  374\n",
      "246.3652885372303\n",
      "length of actions is  352\n",
      "224.0344028886472\n",
      "length of actions is  388\n",
      "191.36032961064677\n",
      "length of actions is  328\n",
      "Your final reward is : 218.84\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3404])\n",
      "-47.5564873107369\n",
      "length of actions is  531\n",
      "216.37599459127028\n",
      "length of actions is  388\n",
      "170.48563550460125\n",
      "length of actions is  461\n",
      "232.73707395202288\n",
      "length of actions is  361\n",
      "222.8152645288884\n",
      "length of actions is  388\n",
      "Your final reward is : 158.97\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2318])\n",
      "173.24874512522393\n",
      "length of actions is  666\n",
      "171.45636045108276\n",
      "length of actions is  518\n",
      "191.2704717574279\n",
      "length of actions is  459\n",
      "74.56052598051839\n",
      "length of actions is  1000\n",
      "223.50743385035167\n",
      "length of actions is  714\n",
      "Your final reward is : 166.81\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2476])\n",
      "206.71435382022753\n",
      "length of actions is  363\n",
      "250.8601850230536\n",
      "length of actions is  385\n",
      "240.79436661497542\n",
      "length of actions is  368\n",
      "208.45272015507163\n",
      "length of actions is  392\n",
      "186.28297574227776\n",
      "length of actions is  610\n",
      "Your final reward is : 218.62\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2750])\n",
      "192.49050487086677\n",
      "length of actions is  393\n",
      "176.12051891012663\n",
      "length of actions is  406\n",
      "225.93468467700066\n",
      "length of actions is  417\n",
      "213.57874773880414\n",
      "length of actions is  370\n",
      "225.57673441057324\n",
      "length of actions is  392\n",
      "Your final reward is : 206.74\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3123])\n",
      "182.1292740264796\n",
      "length of actions is  787\n",
      "182.31925752809397\n",
      "length of actions is  515\n",
      "238.2857714200202\n",
      "length of actions is  406\n",
      "165.0301670305835\n",
      "length of actions is  558\n",
      "241.37713275723692\n",
      "length of actions is  400\n",
      "Your final reward is : 201.83\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2056])\n",
      "178.58912900645868\n",
      "length of actions is  507\n",
      "248.04166274570704\n",
      "length of actions is  385\n",
      "203.57400644557265\n",
      "length of actions is  423\n",
      "224.76479510469517\n",
      "length of actions is  388\n",
      "233.71857877496876\n",
      "length of actions is  404\n",
      "Your final reward is : 217.74\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2489])\n",
      "156.65579637006036\n",
      "length of actions is  650\n",
      "74.95270992918138\n",
      "length of actions is  1000\n",
      "200.6023975068299\n",
      "length of actions is  377\n",
      "96.4359548582757\n",
      "length of actions is  919\n",
      "245.13506007870092\n",
      "length of actions is  357\n",
      "Your final reward is : 154.76\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2430])\n",
      "175.8292029246544\n",
      "length of actions is  820\n",
      "151.8544616913183\n",
      "length of actions is  567\n",
      "201.10844141134237\n",
      "length of actions is  400\n",
      "206.49570572640874\n",
      "length of actions is  476\n",
      "213.35830537750584\n",
      "length of actions is  434\n",
      "Your final reward is : 189.73\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2687])\n",
      "192.56202569627686\n",
      "length of actions is  689\n",
      "204.94878123295047\n",
      "length of actions is  426\n",
      "186.93945789649416\n",
      "length of actions is  503\n",
      "205.9789862990949\n",
      "length of actions is  352\n",
      "250.6895124358674\n",
      "length of actions is  397\n",
      "Your final reward is : 208.22\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2772])\n",
      "194.92025586318\n",
      "length of actions is  387\n",
      "37.15386074838332\n",
      "length of actions is  290\n",
      "-1.2115785983592104\n",
      "length of actions is  521\n",
      "204.270458640913\n",
      "length of actions is  354\n",
      "117.7879859865756\n",
      "length of actions is  1000\n",
      "Your final reward is : 110.58\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2346])\n",
      "174.9170836443198\n",
      "length of actions is  833\n",
      "256.4193828130891\n",
      "length of actions is  320\n",
      "190.12622876972029\n",
      "length of actions is  473\n",
      "212.5010785516398\n",
      "length of actions is  337\n",
      "105.59045728268667\n",
      "length of actions is  1000\n",
      "Your final reward is : 187.91\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2275])\n",
      "179.44052148791096\n",
      "length of actions is  805\n",
      "-6.095852166035613\n",
      "length of actions is  366\n",
      "97.39888571692572\n",
      "length of actions is  1000\n",
      "245.20051398973524\n",
      "length of actions is  356\n",
      "204.76995983453943\n",
      "length of actions is  405\n",
      "Your final reward is : 144.14\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1964])\n",
      "181.70265548373447\n",
      "length of actions is  680\n",
      "206.05666204162043\n",
      "length of actions is  370\n",
      "221.23175823207902\n",
      "length of actions is  388\n",
      "185.81898395143054\n",
      "length of actions is  416\n",
      "212.12444021165686\n",
      "length of actions is  837\n",
      "Your final reward is : 201.39\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2517])\n",
      "167.8325604467394\n",
      "length of actions is  857\n",
      "194.7363382721716\n",
      "length of actions is  533\n",
      "126.35639205138419\n",
      "length of actions is  1000\n",
      "267.3047671093475\n",
      "length of actions is  339\n",
      "120.13044118395929\n",
      "length of actions is  817\n",
      "Your final reward is : 175.27\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2286])\n",
      "177.83309231877834\n",
      "length of actions is  448\n",
      "187.18915978673715\n",
      "length of actions is  421\n",
      "5.492152395018877\n",
      "length of actions is  725\n",
      "236.19402950142793\n",
      "length of actions is  318\n",
      "246.93428367303926\n",
      "length of actions is  287\n",
      "Your final reward is : 170.73\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2041])\n",
      "188.17805673479384\n",
      "length of actions is  418\n",
      "170.47994332007087\n",
      "length of actions is  542\n",
      "206.83742735228432\n",
      "length of actions is  379\n",
      "197.8143781594951\n",
      "length of actions is  436\n",
      "266.45709114780817\n",
      "length of actions is  334\n",
      "Your final reward is : 205.95\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2226])\n",
      "181.68880623659157\n",
      "length of actions is  470\n",
      "87.18141533491274\n",
      "length of actions is  1000\n",
      "219.5609350188368\n",
      "length of actions is  466\n",
      "203.2508773474986\n",
      "length of actions is  325\n",
      "217.49234071347848\n",
      "length of actions is  375\n",
      "Your final reward is : 181.83\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "166.6351661920418\n",
      "length of actions is  586\n",
      "84.50227042824459\n",
      "length of actions is  1000\n",
      "239.65914397520902\n",
      "length of actions is  283\n",
      "252.56165660970152\n",
      "length of actions is  280\n",
      "211.72908617625558\n",
      "length of actions is  304\n",
      "Your final reward is : 191.02\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2318])\n",
      "179.1873966342523\n",
      "length of actions is  479\n",
      "101.35515872502107\n",
      "length of actions is  1000\n",
      "246.54901129785316\n",
      "length of actions is  294\n",
      "131.1533467112939\n",
      "length of actions is  635\n",
      "240.0155617681514\n",
      "length of actions is  330\n",
      "Your final reward is : 179.65\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2080])\n",
      "177.2339676018794\n",
      "length of actions is  712\n",
      "220.85007535097355\n",
      "length of actions is  294\n",
      "262.0604278628218\n",
      "length of actions is  318\n",
      "263.6599429239888\n",
      "length of actions is  297\n",
      "200.44108431725613\n",
      "length of actions is  342\n",
      "Your final reward is : 224.85\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1970])\n",
      "176.5605857252881\n",
      "length of actions is  524\n",
      "123.06551978402558\n",
      "length of actions is  1000\n",
      "245.76416772308662\n",
      "length of actions is  266\n",
      "283.41828811499306\n",
      "length of actions is  299\n",
      "79.99209913306487\n",
      "length of actions is  1000\n",
      "Your final reward is : 181.76\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2887])\n",
      "183.99676317377055\n",
      "length of actions is  408\n",
      "191.8430858530458\n",
      "length of actions is  498\n",
      "189.65744936728674\n",
      "length of actions is  409\n",
      "256.0821071825346\n",
      "length of actions is  282\n",
      "246.57931454574125\n",
      "length of actions is  286\n",
      "Your final reward is : 213.63\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1961])\n",
      "192.00887147890796\n",
      "length of actions is  379\n",
      "48.21057724626247\n",
      "length of actions is  1000\n",
      "248.9927239993285\n",
      "length of actions is  300\n",
      "230.21930801293516\n",
      "length of actions is  280\n",
      "-11.625432634503014\n",
      "length of actions is  333\n",
      "Your final reward is : 141.56\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3777])\n",
      "192.20258829452115\n",
      "length of actions is  400\n",
      "245.92015448187152\n",
      "length of actions is  960\n",
      "219.94181691983817\n",
      "length of actions is  324\n",
      "286.92968162585\n",
      "length of actions is  311\n",
      "281.95876463884713\n",
      "length of actions is  289\n",
      "Your final reward is : 245.39\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1705])\n",
      "203.08542004210418\n",
      "length of actions is  376\n",
      "265.0983622359885\n",
      "length of actions is  265\n",
      "242.92732051045644\n",
      "length of actions is  275\n",
      "266.5386028317881\n",
      "length of actions is  278\n",
      "106.60971221850068\n",
      "length of actions is  1000\n",
      "Your final reward is : 216.85\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2082])\n",
      "198.40317885046983\n",
      "length of actions is  366\n",
      "271.8701022147844\n",
      "length of actions is  297\n",
      "220.63311019629276\n",
      "length of actions is  347\n",
      "177.83447748236463\n",
      "length of actions is  434\n",
      "138.42583036917057\n",
      "length of actions is  1000\n",
      "Your final reward is : 201.43\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1705])\n",
      "206.82074392188798\n",
      "length of actions is  362\n",
      "77.19244464112543\n",
      "length of actions is  1000\n",
      "192.44339443213843\n",
      "length of actions is  764\n",
      "220.41657541718797\n",
      "length of actions is  512\n",
      "184.2201727443001\n",
      "length of actions is  928\n",
      "Your final reward is : 176.22\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2957])\n",
      "192.9679697249652\n",
      "length of actions is  403\n",
      "206.23421458043782\n",
      "length of actions is  464\n",
      "209.8226669237556\n",
      "length of actions is  388\n",
      "269.3090671360879\n",
      "length of actions is  259\n",
      "247.31616388246965\n",
      "length of actions is  296\n",
      "Your final reward is : 225.13\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2171])\n",
      "156.4242271440439\n",
      "length of actions is  657\n",
      "136.2230016267153\n",
      "length of actions is  1000\n",
      "224.09973893564853\n",
      "length of actions is  409\n",
      "273.74363532605093\n",
      "length of actions is  297\n",
      "169.35122738822622\n",
      "length of actions is  561\n",
      "Your final reward is : 191.97\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1676])\n",
      "106.84391501637005\n",
      "length of actions is  852\n",
      "276.5127394994256\n",
      "length of actions is  313\n",
      "214.52848566343687\n",
      "length of actions is  455\n",
      "244.54377245072473\n",
      "length of actions is  274\n",
      "220.5069662149721\n",
      "length of actions is  293\n",
      "Your final reward is : 212.59\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2446])\n",
      "132.37764760907896\n",
      "length of actions is  831\n",
      "167.14067654064175\n",
      "length of actions is  1000\n",
      "245.69441191522404\n",
      "length of actions is  314\n",
      "287.4775847422005\n",
      "length of actions is  283\n",
      "203.6520052396611\n",
      "length of actions is  648\n",
      "Your final reward is : 207.27\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1676])\n",
      "196.86832954055788\n",
      "length of actions is  363\n",
      "236.54502364865496\n",
      "length of actions is  444\n",
      "187.08835690580938\n",
      "length of actions is  550\n",
      "225.66039025203423\n",
      "length of actions is  417\n",
      "298.6627080502651\n",
      "length of actions is  313\n",
      "Your final reward is : 228.96\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2555])\n",
      "210.50037994891525\n",
      "length of actions is  354\n",
      "258.35246611086643\n",
      "length of actions is  356\n",
      "247.54630347879691\n",
      "length of actions is  303\n",
      "204.01826367063444\n",
      "length of actions is  374\n",
      "226.68210567812326\n",
      "length of actions is  410\n",
      "Your final reward is : 229.42\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2081])\n",
      "79.7486246943368\n",
      "length of actions is  1000\n",
      "280.64896682166057\n",
      "length of actions is  314\n",
      "227.52059881181884\n",
      "length of actions is  289\n",
      "269.85403514970176\n",
      "length of actions is  254\n",
      "231.1960767775837\n",
      "length of actions is  850\n",
      "Your final reward is : 217.79\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2109])\n",
      "218.27841878772765\n",
      "length of actions is  354\n",
      "277.756076835014\n",
      "length of actions is  295\n",
      "284.9577127191447\n",
      "length of actions is  281\n",
      "222.73146823272975\n",
      "length of actions is  422\n",
      "227.25189735657642\n",
      "length of actions is  298\n",
      "Your final reward is : 246.20\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2197])\n",
      "151.48632180249064\n",
      "length of actions is  720\n",
      "193.87916911233606\n",
      "length of actions is  435\n",
      "200.08314950200906\n",
      "length of actions is  417\n",
      "225.4729629999489\n",
      "length of actions is  331\n",
      "244.17932546547587\n",
      "length of actions is  324\n",
      "Your final reward is : 203.02\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1705])\n",
      "124.59228241333012\n",
      "length of actions is  864\n",
      "272.5210163411747\n",
      "length of actions is  307\n",
      "92.2731573704268\n",
      "length of actions is  1000\n",
      "264.42042173879724\n",
      "length of actions is  233\n",
      "213.22760795441653\n",
      "length of actions is  365\n",
      "Your final reward is : 193.41\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2542])\n",
      "-29.30152224655443\n",
      "length of actions is  1000\n",
      "289.9171081140247\n",
      "length of actions is  288\n",
      "5.813209572261173\n",
      "length of actions is  1000\n",
      "9.83521035035209\n",
      "length of actions is  1000\n",
      "78.13130064826379\n",
      "length of actions is  1000\n",
      "Your final reward is : 70.88\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2153])\n",
      "-6.227626997810581\n",
      "length of actions is  1000\n",
      "286.74296272213917\n",
      "length of actions is  285\n",
      "201.91400402499798\n",
      "length of actions is  434\n",
      "267.30660084138094\n",
      "length of actions is  235\n",
      "272.4258409687103\n",
      "length of actions is  275\n",
      "Your final reward is : 204.43\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2539])\n",
      "131.9739581805942\n",
      "length of actions is  785\n",
      "129.42705958443747\n",
      "length of actions is  1000\n",
      "121.75418721640158\n",
      "length of actions is  1000\n",
      "110.29067078933838\n",
      "length of actions is  1000\n",
      "118.98026234726265\n",
      "length of actions is  1000\n",
      "Your final reward is : 122.49\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2320])\n",
      "-9.980103400814304\n",
      "length of actions is  1000\n",
      "22.244101905128502\n",
      "length of actions is  152\n",
      "211.15448502570752\n",
      "length of actions is  563\n",
      "226.44202680841653\n",
      "length of actions is  391\n",
      "97.24489482213157\n",
      "length of actions is  1000\n",
      "Your final reward is : 109.42\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2741])\n",
      "129.40031687369128\n",
      "length of actions is  1000\n",
      "277.9226956859657\n",
      "length of actions is  340\n",
      "139.57163850887454\n",
      "length of actions is  1000\n",
      "265.9630230987608\n",
      "length of actions is  318\n",
      "245.60674793730107\n",
      "length of actions is  316\n",
      "Your final reward is : 211.69\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2148])\n",
      "221.40904943371373\n",
      "length of actions is  419\n",
      "230.4367477226984\n",
      "length of actions is  282\n",
      "284.5913114396161\n",
      "length of actions is  281\n",
      "277.26265718772885\n",
      "length of actions is  248\n",
      "207.03770034479365\n",
      "length of actions is  377\n",
      "Your final reward is : 244.15\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2144])\n",
      "164.84835296462123\n",
      "length of actions is  635\n",
      "252.58722626692588\n",
      "length of actions is  429\n",
      "268.4481861590277\n",
      "length of actions is  353\n",
      "238.62753362439264\n",
      "length of actions is  352\n",
      "259.6157785281529\n",
      "length of actions is  274\n",
      "Your final reward is : 236.83\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1508])\n",
      "230.41411761792642\n",
      "length of actions is  318\n",
      "284.1983511778887\n",
      "length of actions is  263\n",
      "283.2926113346756\n",
      "length of actions is  267\n",
      "279.6176774942875\n",
      "length of actions is  249\n",
      "120.59698247884899\n",
      "length of actions is  1000\n",
      "Your final reward is : 239.62\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2414])\n",
      "215.45774696570638\n",
      "length of actions is  395\n",
      "222.23379161752683\n",
      "length of actions is  414\n",
      "150.81590296017723\n",
      "length of actions is  1000\n",
      "250.28951908837448\n",
      "length of actions is  561\n",
      "102.89644966608577\n",
      "length of actions is  1000\n",
      "Your final reward is : 188.34\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1776])\n",
      "210.29052385918692\n",
      "length of actions is  354\n",
      "276.14951187121824\n",
      "length of actions is  296\n",
      "249.61695017012326\n",
      "length of actions is  275\n",
      "72.20192350909295\n",
      "length of actions is  1000\n",
      "219.5015894528221\n",
      "length of actions is  324\n",
      "Your final reward is : 205.55\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2381])\n",
      "214.10258402379304\n",
      "length of actions is  349\n",
      "143.35694851631422\n",
      "length of actions is  776\n",
      "253.99374002483668\n",
      "length of actions is  230\n",
      "94.43772562992775\n",
      "length of actions is  1000\n",
      "168.71940263175836\n",
      "length of actions is  317\n",
      "Your final reward is : 174.92\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1497])\n",
      "220.35937368514584\n",
      "length of actions is  350\n",
      "255.43906039040237\n",
      "length of actions is  226\n",
      "239.77618231613923\n",
      "length of actions is  326\n",
      "239.48510222766816\n",
      "length of actions is  234\n",
      "221.4363364476516\n",
      "length of actions is  369\n",
      "Your final reward is : 235.30\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1361])\n",
      "198.31559186794107\n",
      "length of actions is  924\n",
      "138.07370514031996\n",
      "length of actions is  1000\n",
      "269.76626587170955\n",
      "length of actions is  228\n",
      "256.2894022142082\n",
      "length of actions is  214\n",
      "16.192813132762865\n",
      "length of actions is  568\n",
      "Your final reward is : 175.73\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1507])\n",
      "190.67413569469178\n",
      "length of actions is  901\n",
      "209.16148759884518\n",
      "length of actions is  382\n",
      "14.744843851749536\n",
      "length of actions is  192\n",
      "254.37098205728287\n",
      "length of actions is  244\n",
      "248.58090417043073\n",
      "length of actions is  255\n",
      "Your final reward is : 183.51\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2316])\n",
      "87.16497500548178\n",
      "length of actions is  1000\n",
      "51.50047505644005\n",
      "length of actions is  176\n",
      "258.672882548607\n",
      "length of actions is  427\n",
      "261.48667682075967\n",
      "length of actions is  216\n",
      "124.07243975782328\n",
      "length of actions is  1000\n",
      "Your final reward is : 156.58\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1500])\n",
      "195.85478812972843\n",
      "length of actions is  362\n",
      "94.29279744338399\n",
      "length of actions is  1000\n",
      "8.450205120412832\n",
      "length of actions is  165\n",
      "95.85817816224609\n",
      "length of actions is  1000\n",
      "177.66252019689045\n",
      "length of actions is  491\n",
      "Your final reward is : 114.42\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1977])\n",
      "186.5577820990555\n",
      "length of actions is  421\n",
      "250.79519428688153\n",
      "length of actions is  231\n",
      "-11.361198858980671\n",
      "length of actions is  114\n",
      "5.255078881200532\n",
      "length of actions is  150\n",
      "287.95867172134774\n",
      "length of actions is  198\n",
      "Your final reward is : 143.84\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1501])\n",
      "201.76320345691582\n",
      "length of actions is  379\n",
      "46.54669833080681\n",
      "length of actions is  1000\n",
      "258.8778758437521\n",
      "length of actions is  238\n",
      "263.2225205274801\n",
      "length of actions is  274\n",
      "44.910775014371126\n",
      "length of actions is  195\n",
      "Your final reward is : 163.06\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1028])\n",
      "189.5192854986777\n",
      "length of actions is  453\n",
      "242.86652621004416\n",
      "length of actions is  352\n",
      "213.34945559873552\n",
      "length of actions is  505\n",
      "90.01741664233845\n",
      "length of actions is  1000\n",
      "112.2658458650929\n",
      "length of actions is  939\n",
      "Your final reward is : 169.60\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2660])\n",
      "186.50632650227695\n",
      "length of actions is  775\n",
      "8.82366495992288\n",
      "length of actions is  168\n",
      "-19.053660293377447\n",
      "length of actions is  172\n",
      "3.5547607360792313\n",
      "length of actions is  159\n",
      "42.6195375570307\n",
      "length of actions is  127\n",
      "Your final reward is : 44.49\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1523])\n",
      "208.17101634597705\n",
      "length of actions is  595\n",
      "253.7588385519683\n",
      "length of actions is  220\n",
      "196.90816369467325\n",
      "length of actions is  519\n",
      "16.1076429360334\n",
      "length of actions is  184\n",
      "-14.380326133663473\n",
      "length of actions is  145\n",
      "Your final reward is : 132.11\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1706])\n",
      "-87.00899243018978\n",
      "length of actions is  82\n",
      "-57.85154910648239\n",
      "length of actions is  159\n",
      "132.29310509343247\n",
      "length of actions is  1000\n",
      "154.83039073918792\n",
      "length of actions is  1000\n",
      "-4.115914196795288\n",
      "length of actions is  163\n",
      "Your final reward is : 27.63\n",
      "torch.from_numpy(rewards) looks like  torch.Size([974])\n",
      "152.61069592556169\n",
      "length of actions is  625\n",
      "15.413799645267275\n",
      "length of actions is  180\n",
      "218.05470107646832\n",
      "length of actions is  505\n",
      "216.52548307264914\n",
      "length of actions is  227\n",
      "37.1141041410132\n",
      "length of actions is  197\n",
      "Your final reward is : 127.94\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2175])\n",
      "-51.92120295098086\n",
      "length of actions is  106\n",
      "132.86724975367224\n",
      "length of actions is  1000\n",
      "11.848765096875411\n",
      "length of actions is  162\n",
      "-2.637679296092159\n",
      "length of actions is  144\n",
      "26.504455215986795\n",
      "length of actions is  135\n",
      "Your final reward is : 23.33\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2601])\n",
      "-81.43685828677344\n",
      "length of actions is  78\n",
      "26.394968082743972\n",
      "length of actions is  187\n",
      "31.60456955646424\n",
      "length of actions is  119\n",
      "-48.835955562245516\n",
      "length of actions is  61\n",
      "254.84220187862425\n",
      "length of actions is  258\n",
      "Your final reward is : 36.51\n",
      "torch.from_numpy(rewards) looks like  torch.Size([986])\n",
      "-79.67555375990207\n",
      "length of actions is  78\n",
      "-8.041428982290356\n",
      "length of actions is  147\n",
      "-26.130410789606714\n",
      "length of actions is  66\n",
      "-37.3593801401242\n",
      "length of actions is  153\n",
      "229.54122905794674\n",
      "length of actions is  531\n",
      "Your final reward is : 15.67\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1850])\n",
      "-77.08508212340917\n",
      "length of actions is  75\n",
      "-13.161993537523685\n",
      "length of actions is  168\n",
      "1.412594356146002\n",
      "length of actions is  126\n",
      "257.3444207725231\n",
      "length of actions is  218\n",
      "34.54697614710918\n",
      "length of actions is  156\n",
      "Your final reward is : 40.61\n",
      "torch.from_numpy(rewards) looks like  torch.Size([894])\n",
      "-72.60269118091568\n",
      "length of actions is  75\n",
      "-5.557158974576637\n",
      "length of actions is  167\n",
      "108.57866582554689\n",
      "length of actions is  1000\n",
      "262.5448366156803\n",
      "length of actions is  213\n",
      "9.661426736798816\n",
      "length of actions is  94\n",
      "Your final reward is : 60.53\n",
      "torch.from_numpy(rewards) looks like  torch.Size([684])\n",
      "-87.30097490325525\n",
      "length of actions is  74\n",
      "-26.087881905095188\n",
      "length of actions is  87\n",
      "-5.825348661841559\n",
      "length of actions is  178\n",
      "-56.90069350555438\n",
      "length of actions is  58\n",
      "25.051787071759577\n",
      "length of actions is  158\n",
      "Your final reward is : -30.21\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1446])\n",
      "-64.93650312722146\n",
      "length of actions is  78\n",
      "19.656285813064514\n",
      "length of actions is  174\n",
      "231.31056417157995\n",
      "length of actions is  187\n",
      "-22.749920727990514\n",
      "length of actions is  178\n",
      "-78.76212258952681\n",
      "length of actions is  125\n",
      "Your final reward is : 16.90\n",
      "torch.from_numpy(rewards) looks like  torch.Size([750])\n",
      "-68.24357517642913\n",
      "length of actions is  80\n",
      "16.80318424172107\n",
      "length of actions is  117\n",
      "-11.058383623477184\n",
      "length of actions is  98\n",
      "220.4203885737565\n",
      "length of actions is  162\n",
      "-41.20694244160464\n",
      "length of actions is  178\n",
      "Your final reward is : 23.34\n",
      "torch.from_numpy(rewards) looks like  torch.Size([799])\n",
      "-68.59490262410071\n",
      "length of actions is  82\n",
      "-36.512801085537205\n",
      "length of actions is  159\n",
      "242.9432032275717\n",
      "length of actions is  242\n",
      "33.23903772955629\n",
      "length of actions is  134\n",
      "-99.59648184274725\n",
      "length of actions is  118\n",
      "Your final reward is : 14.30\n",
      "torch.from_numpy(rewards) looks like  torch.Size([784])\n",
      "-75.48639772528188\n",
      "length of actions is  80\n",
      "231.73714381908655\n",
      "length of actions is  207\n",
      "-47.746296707614746\n",
      "length of actions is  68\n",
      "1.1403002849773713\n",
      "length of actions is  164\n",
      "11.845620001440622\n",
      "length of actions is  169\n",
      "Your final reward is : 24.30\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1146])\n",
      "-71.2878494213262\n",
      "length of actions is  80\n",
      "17.41611015581364\n",
      "length of actions is  120\n",
      "2.581834654050553\n",
      "length of actions is  123\n",
      "244.11697387049472\n",
      "length of actions is  246\n",
      "26.136218106207295\n",
      "length of actions is  133\n",
      "Your final reward is : 43.79\n",
      "torch.from_numpy(rewards) looks like  torch.Size([863])\n",
      "-71.47019926966537\n",
      "length of actions is  81\n",
      "-6.799350628613183\n",
      "length of actions is  80\n",
      "263.81228226108726\n",
      "length of actions is  219\n",
      "-12.279292652334718\n",
      "length of actions is  118\n",
      "3.5019094255758034\n",
      "length of actions is  186\n",
      "Your final reward is : 35.35\n",
      "torch.from_numpy(rewards) looks like  torch.Size([793])\n",
      "-60.06478110125813\n",
      "length of actions is  87\n",
      "-38.81209067170242\n",
      "length of actions is  98\n",
      "-2.8736329135638528\n",
      "length of actions is  184\n",
      "14.797206748060447\n",
      "length of actions is  158\n",
      "-88.03202786617186\n",
      "length of actions is  63\n",
      "Your final reward is : -35.00\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1175])\n",
      "-51.58028182454947\n",
      "length of actions is  93\n",
      "12.155287127619616\n",
      "length of actions is  176\n",
      "-43.12160611608904\n",
      "length of actions is  70\n",
      "-27.423191860094562\n",
      "length of actions is  71\n",
      "243.27912757031322\n",
      "length of actions is  245\n",
      "Your final reward is : 26.66\n",
      "torch.from_numpy(rewards) looks like  torch.Size([972])\n",
      "-42.238344769881024\n",
      "length of actions is  94\n",
      "-4.945200402086016\n",
      "length of actions is  84\n",
      "181.9261295669627\n",
      "length of actions is  209\n",
      "-83.11972837206116\n",
      "length of actions is  76\n",
      "264.43506144076724\n",
      "length of actions is  277\n",
      "Your final reward is : 63.21\n",
      "torch.from_numpy(rewards) looks like  torch.Size([948])\n",
      "-58.913652874543146\n",
      "length of actions is  90\n",
      "29.34797144655991\n",
      "length of actions is  197\n",
      "-42.200186260821795\n",
      "length of actions is  94\n",
      "16.356317451121612\n",
      "length of actions is  143\n",
      "35.56760348661581\n",
      "length of actions is  196\n",
      "Your final reward is : -3.97\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2859])\n",
      "-52.45512830982544\n",
      "length of actions is  120\n",
      "165.66709166184438\n",
      "length of actions is  576\n",
      "6.98634554716898\n",
      "length of actions is  200\n",
      "8.77440689841363\n",
      "length of actions is  176\n",
      "196.25914965314175\n",
      "length of actions is  240\n",
      "Your final reward is : 65.05\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1917])\n",
      "-38.45035048425228\n",
      "length of actions is  114\n",
      "185.7735964892054\n",
      "length of actions is  599\n",
      "228.26523641567337\n",
      "length of actions is  621\n",
      "235.2114129066048\n",
      "length of actions is  265\n",
      "109.32830178905601\n",
      "length of actions is  1000\n",
      "Your final reward is : 144.03\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1710])\n",
      "-12.683560532563462\n",
      "length of actions is  297\n",
      "237.75318024739516\n",
      "length of actions is  251\n",
      "189.22904469795216\n",
      "length of actions is  342\n",
      "215.35460454052844\n",
      "length of actions is  293\n",
      "243.13778841164648\n",
      "length of actions is  231\n",
      "Your final reward is : 174.56\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2326])\n",
      "95.94916980482165\n",
      "length of actions is  1000\n",
      "20.60396441515327\n",
      "length of actions is  187\n",
      "184.58153034000827\n",
      "length of actions is  387\n",
      "233.96307065349987\n",
      "length of actions is  421\n",
      "-7.6767177180184945\n",
      "length of actions is  197\n",
      "Your final reward is : 105.48\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "-0.993102352941321\n",
      "length of actions is  256\n",
      "214.42055030023232\n",
      "length of actions is  409\n",
      "20.59989904005124\n",
      "length of actions is  207\n",
      "183.59669811093357\n",
      "length of actions is  476\n",
      "202.8276099621992\n",
      "length of actions is  653\n",
      "Your final reward is : 124.09\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2275])\n",
      "210.0372101339643\n",
      "length of actions is  322\n",
      "199.8467469552516\n",
      "length of actions is  450\n",
      "214.47696407134117\n",
      "length of actions is  449\n",
      "79.12731803814874\n",
      "length of actions is  1000\n",
      "171.90197986964512\n",
      "length of actions is  567\n",
      "Your final reward is : 175.08\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2319])\n",
      "208.97292145937496\n",
      "length of actions is  859\n",
      "107.69063620667666\n",
      "length of actions is  1000\n",
      "234.42681993328748\n",
      "length of actions is  317\n",
      "248.29937149986628\n",
      "length of actions is  286\n",
      "244.34694449890583\n",
      "length of actions is  223\n",
      "Your final reward is : 208.75\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2740])\n",
      "106.85775539799354\n",
      "length of actions is  1000\n",
      "267.62587616490464\n",
      "length of actions is  253\n",
      "240.38197192246508\n",
      "length of actions is  348\n",
      "247.97497189407284\n",
      "length of actions is  352\n",
      "232.2894733293565\n",
      "length of actions is  282\n",
      "Your final reward is : 219.03\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1703])\n",
      "57.5194714122231\n",
      "length of actions is  1000\n",
      "254.52553913551753\n",
      "length of actions is  282\n",
      "216.9390082464026\n",
      "length of actions is  394\n",
      "264.65281989970833\n",
      "length of actions is  272\n",
      "135.65913281226366\n",
      "length of actions is  1000\n",
      "Your final reward is : 185.86\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2657])\n",
      "194.73500916312958\n",
      "length of actions is  436\n",
      "252.85351234641215\n",
      "length of actions is  274\n",
      "174.95068854122593\n",
      "length of actions is  602\n",
      "230.67970630833796\n",
      "length of actions is  419\n",
      "256.5619520778367\n",
      "length of actions is  171\n",
      "Your final reward is : 221.96\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2558])\n",
      "190.44142309715102\n",
      "length of actions is  790\n",
      "125.48281482844901\n",
      "length of actions is  1000\n",
      "135.93303328144233\n",
      "length of actions is  1000\n",
      "-6.248146775211779\n",
      "length of actions is  89\n",
      "227.80882598316936\n",
      "length of actions is  803\n",
      "Your final reward is : 134.68\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2772])\n",
      "207.11467367579712\n",
      "length of actions is  533\n",
      "243.72041738399864\n",
      "length of actions is  338\n",
      "223.92526129163997\n",
      "length of actions is  281\n",
      "112.78304438169955\n",
      "length of actions is  1000\n",
      "186.3515237803441\n",
      "length of actions is  794\n",
      "Your final reward is : 194.78\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1964])\n",
      "142.49456713073315\n",
      "length of actions is  761\n",
      "246.24778475283853\n",
      "length of actions is  377\n",
      "249.81209544613037\n",
      "length of actions is  291\n",
      "224.56783207458338\n",
      "length of actions is  528\n",
      "92.2057806060587\n",
      "length of actions is  1000\n",
      "Your final reward is : 191.07\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1984])\n",
      "204.08996356912303\n",
      "length of actions is  353\n",
      "111.57362282790608\n",
      "length of actions is  1000\n",
      "193.07488595269444\n",
      "length of actions is  608\n",
      "190.05372624303905\n",
      "length of actions is  368\n",
      "183.46748352187976\n",
      "length of actions is  542\n",
      "Your final reward is : 176.45\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2839])\n",
      "185.641095641681\n",
      "length of actions is  453\n",
      "182.1752866440655\n",
      "length of actions is  651\n",
      "197.33686547258444\n",
      "length of actions is  479\n",
      "218.8998132651989\n",
      "length of actions is  458\n",
      "206.35405356068912\n",
      "length of actions is  281\n",
      "Your final reward is : 198.08\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2855])\n",
      "-45.83399083972854\n",
      "length of actions is  285\n",
      "180.1889799628957\n",
      "length of actions is  737\n",
      "117.3446506114193\n",
      "length of actions is  902\n",
      "237.50302708601535\n",
      "length of actions is  243\n",
      "-56.138604327464066\n",
      "length of actions is  86\n",
      "Your final reward is : 86.61\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4743])\n",
      "-54.45011387985138\n",
      "length of actions is  276\n",
      "143.8903828829824\n",
      "length of actions is  1000\n",
      "20.407020428853855\n",
      "length of actions is  201\n",
      "-49.39359327656321\n",
      "length of actions is  80\n",
      "193.46041360912807\n",
      "length of actions is  531\n",
      "Your final reward is : 50.78\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2807])\n",
      "143.75780436270227\n",
      "length of actions is  825\n",
      "164.34503098096226\n",
      "length of actions is  558\n",
      "-24.10211614602001\n",
      "length of actions is  227\n",
      "112.37577899528242\n",
      "length of actions is  1000\n",
      "-59.93356064919297\n",
      "length of actions is  94\n",
      "Your final reward is : 67.29\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2491])\n",
      "-47.51297008487566\n",
      "length of actions is  1000\n",
      "247.51693589662472\n",
      "length of actions is  326\n",
      "194.27683991603408\n",
      "length of actions is  806\n",
      "-214.53274734344402\n",
      "length of actions is  395\n",
      "-45.47058459146506\n",
      "length of actions is  1000\n",
      "Your final reward is : 26.86\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2021])\n",
      "92.70700180218714\n",
      "length of actions is  971\n",
      "213.13239527767553\n",
      "length of actions is  280\n",
      "229.7011122679095\n",
      "length of actions is  212\n",
      "234.19130100745858\n",
      "length of actions is  227\n",
      "213.87685379836938\n",
      "length of actions is  264\n",
      "Your final reward is : 196.72\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3147])\n",
      "-53.343844051205764\n",
      "length of actions is  1000\n",
      "237.08477172078977\n",
      "length of actions is  290\n",
      "196.79191823738086\n",
      "length of actions is  520\n",
      "205.38692909869252\n",
      "length of actions is  419\n",
      "195.18483782504194\n",
      "length of actions is  422\n",
      "Your final reward is : 156.22\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3360])\n",
      "-28.62425430841819\n",
      "length of actions is  1000\n",
      "235.3089659146448\n",
      "length of actions is  364\n",
      "-10.866953913417586\n",
      "length of actions is  1000\n",
      "-23.851912375297196\n",
      "length of actions is  1000\n",
      "218.18334707511357\n",
      "length of actions is  979\n",
      "Your final reward is : 78.03\n",
      "torch.from_numpy(rewards) looks like  torch.Size([5000])\n",
      "-43.49797487101574\n",
      "length of actions is  1000\n",
      "205.86551745824408\n",
      "length of actions is  562\n",
      "-0.25480519420380965\n",
      "length of actions is  1000\n",
      "-6.016434577300781\n",
      "length of actions is  1000\n",
      "78.31513079939188\n",
      "length of actions is  1000\n",
      "Your final reward is : 46.88\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4205])\n",
      "-63.36090815130116\n",
      "length of actions is  1000\n",
      "115.70247938781135\n",
      "length of actions is  1000\n",
      "209.72552252816706\n",
      "length of actions is  834\n",
      "-23.472185339347348\n",
      "length of actions is  1000\n",
      "9.35141508981161\n",
      "length of actions is  1000\n",
      "Your final reward is : 49.59\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2399])\n",
      "-68.84893285325248\n",
      "length of actions is  1000\n",
      "99.18123655801573\n",
      "length of actions is  1000\n",
      "61.56453947142262\n",
      "length of actions is  1000\n",
      "-51.924715187583196\n",
      "length of actions is  1000\n",
      "63.030617581665005\n",
      "length of actions is  1000\n",
      "Your final reward is : 20.60\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2734])\n",
      "-59.058069286019915\n",
      "length of actions is  1000\n",
      "234.90050871119988\n",
      "length of actions is  311\n",
      "98.55798087785834\n",
      "length of actions is  951\n",
      "-33.67270548257013\n",
      "length of actions is  1000\n",
      "-55.74020183394356\n",
      "length of actions is  151\n",
      "Your final reward is : 37.00\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3858])\n",
      "-56.91015202919118\n",
      "length of actions is  1000\n",
      "212.05427824366285\n",
      "length of actions is  769\n",
      "-15.848617685225008\n",
      "length of actions is  298\n",
      "-41.82995860232337\n",
      "length of actions is  1000\n",
      "-46.85826080472148\n",
      "length of actions is  1000\n",
      "Your final reward is : 10.12\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4145])\n",
      "-20.323600831335416\n",
      "length of actions is  1000\n",
      "110.1417025894771\n",
      "length of actions is  1000\n",
      "130.930620795579\n",
      "length of actions is  712\n",
      "73.13876384335246\n",
      "length of actions is  1000\n",
      "-33.08505636907843\n",
      "length of actions is  231\n",
      "Your final reward is : 52.16\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4018])\n",
      "3.8919013543025054\n",
      "length of actions is  1000\n",
      "-26.36542181735019\n",
      "length of actions is  1000\n",
      "154.2337828806006\n",
      "length of actions is  708\n",
      "130.65679880574487\n",
      "length of actions is  536\n",
      "178.38598690264178\n",
      "length of actions is  619\n",
      "Your final reward is : 88.16\n",
      "torch.from_numpy(rewards) looks like  torch.Size([5000])\n",
      "-33.331690081618724\n",
      "length of actions is  1000\n",
      "-20.147859127586155\n",
      "length of actions is  1000\n",
      "-18.55032338126323\n",
      "length of actions is  1000\n",
      "-36.804487192813404\n",
      "length of actions is  1000\n",
      "-62.40428608836094\n",
      "length of actions is  1000\n",
      "Your final reward is : -34.25\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4442])\n",
      "144.76947612588074\n",
      "length of actions is  651\n",
      "164.45261780478324\n",
      "length of actions is  725\n",
      "213.8963868124589\n",
      "length of actions is  361\n",
      "197.11474614130734\n",
      "length of actions is  738\n",
      "191.29463842511467\n",
      "length of actions is  523\n",
      "Your final reward is : 182.31\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4078])\n",
      "11.905078805565726\n",
      "length of actions is  1000\n",
      "8.100892620437142\n",
      "length of actions is  1000\n",
      "93.06277605254229\n",
      "length of actions is  1000\n",
      "108.36176876967204\n",
      "length of actions is  998\n",
      "37.65903166373826\n",
      "length of actions is  1000\n",
      "Your final reward is : 51.82\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4411])\n",
      "-42.511142502422864\n",
      "length of actions is  1000\n",
      "-6.293527856274824\n",
      "length of actions is  1000\n",
      "-10.776376678039846\n",
      "length of actions is  1000\n",
      "-47.45822953645663\n",
      "length of actions is  1000\n",
      "-41.28295586384822\n",
      "length of actions is  1000\n",
      "Your final reward is : -29.66\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2447])\n",
      "-58.35076154012346\n",
      "length of actions is  1000\n",
      "191.09430676334426\n",
      "length of actions is  726\n",
      "-1.543945886389194\n",
      "length of actions is  1000\n",
      "6.546991224414758\n",
      "length of actions is  1000\n",
      "190.95432496976304\n",
      "length of actions is  478\n",
      "Your final reward is : 65.74\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2848])\n",
      "-58.49227570410273\n",
      "length of actions is  1000\n",
      "145.89419287518837\n",
      "length of actions is  1000\n",
      "223.74226196125423\n",
      "length of actions is  663\n",
      "85.60073141815266\n",
      "length of actions is  1000\n",
      "64.4560602184665\n",
      "length of actions is  1000\n",
      "Your final reward is : 92.24\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3284])\n",
      "-55.124142594421556\n",
      "length of actions is  1000\n",
      "253.1144953761823\n",
      "length of actions is  387\n",
      "253.7753004475939\n",
      "length of actions is  383\n",
      "188.23613751302736\n",
      "length of actions is  465\n",
      "261.53932140513325\n",
      "length of actions is  331\n",
      "Your final reward is : 180.31\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4387])\n",
      "-39.78066554954283\n",
      "length of actions is  1000\n",
      "132.12079248928555\n",
      "length of actions is  1000\n",
      "109.92111540118331\n",
      "length of actions is  1000\n",
      "15.59215475225221\n",
      "length of actions is  1000\n",
      "186.77958915632945\n",
      "length of actions is  435\n",
      "Your final reward is : 80.93\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2687])\n",
      "135.77221249781795\n",
      "length of actions is  746\n",
      "167.85520430700785\n",
      "length of actions is  473\n",
      "115.83504297074695\n",
      "length of actions is  1000\n",
      "220.64437029497378\n",
      "length of actions is  447\n",
      "249.19158030393658\n",
      "length of actions is  567\n",
      "Your final reward is : 177.86\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2624])\n",
      "-45.601045172597935\n",
      "length of actions is  1000\n",
      "255.83258054025677\n",
      "length of actions is  422\n",
      "174.2676527707428\n",
      "length of actions is  596\n",
      "-29.560232084855524\n",
      "length of actions is  1000\n",
      "149.50886630543934\n",
      "length of actions is  833\n",
      "Your final reward is : 100.89\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2638])\n",
      "-56.00995464871404\n",
      "length of actions is  1000\n",
      "285.3297474096267\n",
      "length of actions is  300\n",
      "151.4632966871606\n",
      "length of actions is  750\n",
      "-41.24596318914337\n",
      "length of actions is  1000\n",
      "189.20337619937243\n",
      "length of actions is  527\n",
      "Your final reward is : 105.75\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3661])\n",
      "-71.3163494925044\n",
      "length of actions is  1000\n",
      "137.47674765226745\n",
      "length of actions is  1000\n",
      "216.71081671774266\n",
      "length of actions is  515\n",
      "-51.91972573436316\n",
      "length of actions is  1000\n",
      "-51.69526261962774\n",
      "length of actions is  1000\n",
      "Your final reward is : 35.85\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4259])\n",
      "-58.563966371684266\n",
      "length of actions is  1000\n",
      "268.229016699686\n",
      "length of actions is  311\n",
      "121.32080312264472\n",
      "length of actions is  1000\n",
      "236.6263117187879\n",
      "length of actions is  357\n",
      "238.68825139677065\n",
      "length of actions is  305\n",
      "Your final reward is : 161.26\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2916])\n",
      "-55.74840241749924\n",
      "length of actions is  1000\n",
      "249.4490286133026\n",
      "length of actions is  368\n",
      "191.33595113401316\n",
      "length of actions is  489\n",
      "249.75205635836218\n",
      "length of actions is  442\n",
      "95.09131103382106\n",
      "length of actions is  1000\n",
      "Your final reward is : 145.98\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1497])\n",
      "-81.5406861094075\n",
      "length of actions is  1000\n",
      "266.76656989101986\n",
      "length of actions is  348\n",
      "130.31637799861076\n",
      "length of actions is  1000\n",
      "-54.01327969082827\n",
      "length of actions is  1000\n",
      "260.5476369289357\n",
      "length of actions is  404\n",
      "Your final reward is : 104.42\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3145])\n",
      "-59.44613434255907\n",
      "length of actions is  1000\n",
      "29.56346729099147\n",
      "length of actions is  227\n",
      "254.26902564504363\n",
      "length of actions is  346\n",
      "267.4869993835565\n",
      "length of actions is  351\n",
      "220.77327705278628\n",
      "length of actions is  250\n",
      "Your final reward is : 142.53\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2963])\n",
      "-62.6416536465981\n",
      "length of actions is  1000\n",
      "151.23772904577288\n",
      "length of actions is  1000\n",
      "240.37130879009158\n",
      "length of actions is  253\n",
      "261.5936636985663\n",
      "length of actions is  241\n",
      "181.13876571171573\n",
      "length of actions is  554\n",
      "Your final reward is : 154.34\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1735])\n",
      "-65.86734936242355\n",
      "length of actions is  1000\n",
      "262.8245376927379\n",
      "length of actions is  348\n",
      "138.46301396562137\n",
      "length of actions is  1000\n",
      "-47.281195457773705\n",
      "length of actions is  1000\n",
      "214.9810822517056\n",
      "length of actions is  564\n",
      "Your final reward is : 100.62\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3137])\n",
      "-57.853519984874055\n",
      "length of actions is  1000\n",
      "266.4305672541793\n",
      "length of actions is  263\n",
      "277.44823463218916\n",
      "length of actions is  281\n",
      "239.23368009252766\n",
      "length of actions is  250\n",
      "254.23989111000475\n",
      "length of actions is  283\n",
      "Your final reward is : 195.90\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1777])\n",
      "-56.190801472589264\n",
      "length of actions is  1000\n",
      "272.30327991683055\n",
      "length of actions is  286\n",
      "183.74947627597504\n",
      "length of actions is  481\n",
      "270.93083985427893\n",
      "length of actions is  332\n",
      "230.54131058556854\n",
      "length of actions is  340\n",
      "Your final reward is : 180.27\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2744])\n",
      "-86.13081596799395\n",
      "length of actions is  1000\n",
      "50.070670603213415\n",
      "length of actions is  234\n",
      "-49.25757489133967\n",
      "length of actions is  1000\n",
      "251.9244906088255\n",
      "length of actions is  416\n",
      "-12.81695316809021\n",
      "length of actions is  1000\n",
      "Your final reward is : 30.76\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2198])\n",
      "-69.22814031101097\n",
      "length of actions is  1000\n",
      "266.87086883114966\n",
      "length of actions is  285\n",
      "242.32449548870267\n",
      "length of actions is  260\n",
      "215.81856368113446\n",
      "length of actions is  636\n",
      "241.78501159908672\n",
      "length of actions is  261\n",
      "Your final reward is : 179.51\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3182])\n",
      "-72.95747102532121\n",
      "length of actions is  1000\n",
      "29.292949265316366\n",
      "length of actions is  227\n",
      "232.4565453522011\n",
      "length of actions is  828\n",
      "229.28254388018493\n",
      "length of actions is  479\n",
      "212.6736709730366\n",
      "length of actions is  609\n",
      "Your final reward is : 126.15\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2468])\n",
      "-79.52751177797339\n",
      "length of actions is  1000\n",
      "260.71551033696886\n",
      "length of actions is  266\n",
      "222.89820628745997\n",
      "length of actions is  269\n",
      "230.61759399637003\n",
      "length of actions is  310\n",
      "259.63465664866726\n",
      "length of actions is  294\n",
      "Your final reward is : 178.87\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3142])\n",
      "-62.537596218128606\n",
      "length of actions is  1000\n",
      "163.45048510915225\n",
      "length of actions is  1000\n",
      "264.1924598201035\n",
      "length of actions is  249\n",
      "139.61673791043978\n",
      "length of actions is  1000\n",
      "80.2029995234412\n",
      "length of actions is  1000\n",
      "Your final reward is : 116.99\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2327])\n",
      "-80.18892803996607\n",
      "length of actions is  1000\n",
      "50.53641822782572\n",
      "length of actions is  224\n",
      "215.21863776537106\n",
      "length of actions is  431\n",
      "-95.12769877933995\n",
      "length of actions is  851\n",
      "63.873054062184224\n",
      "length of actions is  226\n",
      "Your final reward is : 30.86\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2827])\n",
      "-49.661911371912325\n",
      "length of actions is  1000\n",
      "269.92106691472907\n",
      "length of actions is  306\n",
      "271.06164854736835\n",
      "length of actions is  334\n",
      "176.54598460912996\n",
      "length of actions is  546\n",
      "-31.559698262303186\n",
      "length of actions is  1000\n",
      "Your final reward is : 127.26\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3045])\n",
      "-71.37612237312695\n",
      "length of actions is  1000\n",
      "266.33035478398597\n",
      "length of actions is  252\n",
      "203.25734432415214\n",
      "length of actions is  509\n",
      "253.90287633759934\n",
      "length of actions is  356\n",
      "211.7768189074808\n",
      "length of actions is  338\n",
      "Your final reward is : 172.78\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3272])\n",
      "-76.72095809995636\n",
      "length of actions is  1000\n",
      "265.4101579545652\n",
      "length of actions is  259\n",
      "194.27470244249366\n",
      "length of actions is  470\n",
      "252.39236081822938\n",
      "length of actions is  312\n",
      "205.06809558891484\n",
      "length of actions is  404\n",
      "Your final reward is : 168.08\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2478])\n",
      "-77.28689978359911\n",
      "length of actions is  1000\n",
      "266.85776183208475\n",
      "length of actions is  297\n",
      "-58.71617100126353\n",
      "length of actions is  1000\n",
      "191.4095286803505\n",
      "length of actions is  320\n",
      "183.34655597997133\n",
      "length of actions is  692\n",
      "Your final reward is : 101.12\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3714])\n",
      "-68.19715702895485\n",
      "length of actions is  1000\n",
      "263.2702088835808\n",
      "length of actions is  338\n",
      "158.45304019982484\n",
      "length of actions is  564\n",
      "155.88468721775314\n",
      "length of actions is  695\n",
      "174.2050945490401\n",
      "length of actions is  688\n",
      "Your final reward is : 136.72\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3082])\n",
      "5.330021847147075\n",
      "length of actions is  1000\n",
      "159.17940166591106\n",
      "length of actions is  1000\n",
      "261.63371654484104\n",
      "length of actions is  454\n",
      "121.57279953634448\n",
      "length of actions is  1000\n",
      "218.9130382543447\n",
      "length of actions is  359\n",
      "Your final reward is : 153.33\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2674])\n",
      "125.66244779414907\n",
      "length of actions is  803\n",
      "1.2367578273471997\n",
      "length of actions is  1000\n",
      "-3.928364859373959\n",
      "length of actions is  1000\n",
      "273.52340722378005\n",
      "length of actions is  274\n",
      "241.60580923910123\n",
      "length of actions is  398\n",
      "Your final reward is : 127.62\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2445])\n",
      "-38.69938419765712\n",
      "length of actions is  1000\n",
      "265.9132766084692\n",
      "length of actions is  254\n",
      "-20.15958828523359\n",
      "length of actions is  1000\n",
      "240.7096347373554\n",
      "length of actions is  324\n",
      "250.70014122511242\n",
      "length of actions is  299\n",
      "Your final reward is : 139.69\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3156])\n",
      "74.31448273505394\n",
      "length of actions is  846\n",
      "-15.422379644961026\n",
      "length of actions is  1000\n",
      "4.51656618472595\n",
      "length of actions is  1000\n",
      "276.58937883251815\n",
      "length of actions is  254\n",
      "239.51764320995582\n",
      "length of actions is  310\n",
      "Your final reward is : 115.90\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2197])\n",
      "-58.84198767241757\n",
      "length of actions is  1000\n",
      "265.5523381692002\n",
      "length of actions is  247\n",
      "111.38792942735562\n",
      "length of actions is  1000\n",
      "247.46748247580746\n",
      "length of actions is  378\n",
      "95.31244804990757\n",
      "length of actions is  1000\n",
      "Your final reward is : 132.18\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3175])\n",
      "-0.8486066828037997\n",
      "length of actions is  1000\n",
      "136.11773349034857\n",
      "length of actions is  1000\n",
      "230.79853755481517\n",
      "length of actions is  435\n",
      "183.30115166052764\n",
      "length of actions is  573\n",
      "-34.43148152863825\n",
      "length of actions is  1000\n",
      "Your final reward is : 102.99\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3735])\n",
      "-47.63680925232641\n",
      "length of actions is  1000\n",
      "267.94857474706475\n",
      "length of actions is  284\n",
      "235.1616483785629\n",
      "length of actions is  433\n",
      "77.70916215362173\n",
      "length of actions is  1000\n",
      "-14.016596653838794\n",
      "length of actions is  1000\n",
      "Your final reward is : 103.83\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1974])\n",
      "-46.74734681539513\n",
      "length of actions is  1000\n",
      "272.6268991622133\n",
      "length of actions is  280\n",
      "219.2971566023934\n",
      "length of actions is  518\n",
      "247.8393984372428\n",
      "length of actions is  237\n",
      "-5.554813506364923\n",
      "length of actions is  231\n",
      "Your final reward is : 137.49\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2225])\n",
      "115.6212501229774\n",
      "length of actions is  830\n",
      "5.986414015330895\n",
      "length of actions is  1000\n",
      "228.4269127142895\n",
      "length of actions is  435\n",
      "-5.96579683361619\n",
      "length of actions is  1000\n",
      "249.19153901285685\n",
      "length of actions is  231\n",
      "Your final reward is : 118.65\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3615])\n",
      "-42.349092262453105\n",
      "length of actions is  1000\n",
      "262.1680407284278\n",
      "length of actions is  284\n",
      "267.3548759539418\n",
      "length of actions is  271\n",
      "-6.939529920613388\n",
      "length of actions is  1000\n",
      "246.55125367821537\n",
      "length of actions is  439\n",
      "Your final reward is : 145.36\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1175])\n",
      "210.31967658214145\n",
      "length of actions is  285\n",
      "155.70386994405945\n",
      "length of actions is  1000\n",
      "239.57581096638347\n",
      "length of actions is  237\n",
      "229.88635738707035\n",
      "length of actions is  336\n",
      "245.00263524697277\n",
      "length of actions is  226\n",
      "Your final reward is : 216.10\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2350])\n",
      "148.48492804387098\n",
      "length of actions is  843\n",
      "240.09459828195486\n",
      "length of actions is  317\n",
      "249.9775312331513\n",
      "length of actions is  167\n",
      "253.89534081624498\n",
      "length of actions is  298\n",
      "97.71896667709021\n",
      "length of actions is  1000\n",
      "Your final reward is : 198.03\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1964])\n",
      "149.27043712907124\n",
      "length of actions is  724\n",
      "35.495332158500396\n",
      "length of actions is  1000\n",
      "210.13849314350716\n",
      "length of actions is  740\n",
      "221.48325938678235\n",
      "length of actions is  274\n",
      "138.18325477308173\n",
      "length of actions is  1000\n",
      "Your final reward is : 150.91\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3514])\n",
      "-39.632577933647205\n",
      "length of actions is  1000\n",
      "266.9613032556067\n",
      "length of actions is  273\n",
      "260.4327341578737\n",
      "length of actions is  284\n",
      "237.06856965498366\n",
      "length of actions is  420\n",
      "233.77720515572807\n",
      "length of actions is  403\n",
      "Your final reward is : 191.72\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3449])\n",
      "-34.52921964535739\n",
      "length of actions is  1000\n",
      "256.979999274316\n",
      "length of actions is  280\n",
      "211.53852046332503\n",
      "length of actions is  532\n",
      "145.8070368715677\n",
      "length of actions is  1000\n",
      "84.59287059254885\n",
      "length of actions is  1000\n",
      "Your final reward is : 132.88\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1971])\n",
      "178.159186190991\n",
      "length of actions is  809\n",
      "252.9951660849643\n",
      "length of actions is  234\n",
      "138.58465681596726\n",
      "length of actions is  1000\n",
      "21.67516395343425\n",
      "length of actions is  204\n",
      "57.33605124518144\n",
      "length of actions is  215\n",
      "Your final reward is : 129.75\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2746])\n",
      "148.62642430393015\n",
      "length of actions is  845\n",
      "227.90161108364347\n",
      "length of actions is  310\n",
      "138.27220782559152\n",
      "length of actions is  914\n",
      "101.08693664095293\n",
      "length of actions is  1000\n",
      "119.04452293865111\n",
      "length of actions is  1000\n",
      "Your final reward is : 146.99\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2749])\n",
      "-39.01462055743164\n",
      "length of actions is  1000\n",
      "264.56360848744845\n",
      "length of actions is  308\n",
      "232.73306114129335\n",
      "length of actions is  284\n",
      "16.768879772197884\n",
      "length of actions is  1000\n",
      "137.62815292410937\n",
      "length of actions is  740\n",
      "Your final reward is : 122.54\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1706])\n",
      "-34.45689771047068\n",
      "length of actions is  1000\n",
      "252.7315448213143\n",
      "length of actions is  292\n",
      "71.10001970652333\n",
      "length of actions is  1000\n",
      "18.659408863848807\n",
      "length of actions is  1000\n",
      "125.19862695491318\n",
      "length of actions is  1000\n",
      "Your final reward is : 86.65\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2275])\n",
      "-31.00867352146351\n",
      "length of actions is  1000\n",
      "263.00913210309363\n",
      "length of actions is  265\n",
      "234.3370721909362\n",
      "length of actions is  775\n",
      "226.2729385533929\n",
      "length of actions is  328\n",
      "211.69651485515584\n",
      "length of actions is  495\n",
      "Your final reward is : 180.86\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2336])\n",
      "213.51185300731277\n",
      "length of actions is  313\n",
      "272.84368647227245\n",
      "length of actions is  371\n",
      "3.7593008974338584\n",
      "length of actions is  1000\n",
      "15.087269667416777\n",
      "length of actions is  277\n",
      "245.68544009610733\n",
      "length of actions is  362\n",
      "Your final reward is : 150.18\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1577])\n",
      "217.95211025080005\n",
      "length of actions is  310\n",
      "209.803911598871\n",
      "length of actions is  770\n",
      "138.25517944477875\n",
      "length of actions is  1000\n",
      "261.7612564897328\n",
      "length of actions is  205\n",
      "136.1514798233333\n",
      "length of actions is  1000\n",
      "Your final reward is : 192.78\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2225])\n",
      "252.09549033195174\n",
      "length of actions is  218\n",
      "274.65460155418543\n",
      "length of actions is  238\n",
      "232.31586111446944\n",
      "length of actions is  279\n",
      "242.0717595499018\n",
      "length of actions is  171\n",
      "279.6471289375461\n",
      "length of actions is  187\n",
      "Your final reward is : 256.16\n",
      "Improve to score 256.16 at batch 248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:132: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.from_numpy(rewards) looks like  torch.Size([2259])\n",
      "222.28294236228842\n",
      "length of actions is  290\n",
      "158.7687589506628\n",
      "length of actions is  1000\n",
      "243.118056470123\n",
      "length of actions is  395\n",
      "243.05951245859418\n",
      "length of actions is  320\n",
      "218.49714431399337\n",
      "length of actions is  652\n",
      "Your final reward is : 217.15\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1793])\n",
      "217.12607628405772\n",
      "length of actions is  314\n",
      "263.5840973058311\n",
      "length of actions is  247\n",
      "271.33762092318466\n",
      "length of actions is  227\n",
      "278.6254510555857\n",
      "length of actions is  198\n",
      "247.75241793580955\n",
      "length of actions is  245\n",
      "Your final reward is : 255.69\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2120])\n",
      "221.8620929687265\n",
      "length of actions is  281\n",
      "240.46946609470118\n",
      "length of actions is  554\n",
      "149.94313086877298\n",
      "length of actions is  1000\n",
      "264.3796688695737\n",
      "length of actions is  298\n",
      "214.86363522546054\n",
      "length of actions is  321\n",
      "Your final reward is : 218.30\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3095])\n",
      "107.72831417018304\n",
      "length of actions is  1000\n",
      "156.30307012956348\n",
      "length of actions is  1000\n",
      "257.42994157797597\n",
      "length of actions is  247\n",
      "139.84912731588\n",
      "length of actions is  1000\n",
      "56.65840673211443\n",
      "length of actions is  186\n",
      "Your final reward is : 143.59\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2274])\n",
      "239.794027299143\n",
      "length of actions is  270\n",
      "241.73630479019658\n",
      "length of actions is  242\n",
      "260.9970177957078\n",
      "length of actions is  222\n",
      "294.07788457646\n",
      "length of actions is  205\n",
      "248.15727948829132\n",
      "length of actions is  190\n",
      "Your final reward is : 256.95\n",
      "Improve to score 256.95 at batch 253\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3062])\n",
      "249.80734904513272\n",
      "length of actions is  227\n",
      "267.6883772436988\n",
      "length of actions is  274\n",
      "261.52062705160887\n",
      "length of actions is  209\n",
      "257.49573042489124\n",
      "length of actions is  298\n",
      "-30.543953431028285\n",
      "length of actions is  149\n",
      "Your final reward is : 201.19\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2341])\n",
      "220.63875338880192\n",
      "length of actions is  321\n",
      "253.45329845942553\n",
      "length of actions is  254\n",
      "273.14227178088106\n",
      "length of actions is  217\n",
      "154.6480697094176\n",
      "length of actions is  733\n",
      "253.83447656204763\n",
      "length of actions is  216\n",
      "Your final reward is : 231.14\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1577])\n",
      "254.2755821268742\n",
      "length of actions is  223\n",
      "159.57090005084197\n",
      "length of actions is  1000\n",
      "148.29033206460542\n",
      "length of actions is  1000\n",
      "278.043665004818\n",
      "length of actions is  224\n",
      "221.48004679222385\n",
      "length of actions is  344\n",
      "Your final reward is : 212.33\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2827])\n",
      "226.7427071231807\n",
      "length of actions is  301\n",
      "276.26623592212695\n",
      "length of actions is  226\n",
      "212.57795404971847\n",
      "length of actions is  454\n",
      "262.76906080326887\n",
      "length of actions is  250\n",
      "253.14503190043365\n",
      "length of actions is  327\n",
      "Your final reward is : 246.30\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1499])\n",
      "232.96635942178665\n",
      "length of actions is  302\n",
      "182.90738929628782\n",
      "length of actions is  509\n",
      "265.2279296621613\n",
      "length of actions is  250\n",
      "232.89691518680863\n",
      "length of actions is  450\n",
      "237.15454965137965\n",
      "length of actions is  379\n",
      "Your final reward is : 230.23\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2736])\n",
      "219.69716512789262\n",
      "length of actions is  408\n",
      "14.295997612932197\n",
      "length of actions is  112\n",
      "162.2834257066543\n",
      "length of actions is  705\n",
      "5.818334915034943\n",
      "length of actions is  1000\n",
      "222.5747932192227\n",
      "length of actions is  371\n",
      "Your final reward is : 124.93\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3067])\n",
      "231.44083316169565\n",
      "length of actions is  346\n",
      "127.56914941039969\n",
      "length of actions is  1000\n",
      "244.43241228597964\n",
      "length of actions is  283\n",
      "242.47296218527214\n",
      "length of actions is  277\n",
      "238.5455212575547\n",
      "length of actions is  411\n",
      "Your final reward is : 216.89\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3590])\n",
      "-9.110326109460384\n",
      "length of actions is  1000\n",
      "182.5152288850041\n",
      "length of actions is  849\n",
      "26.395275987099907\n",
      "length of actions is  1000\n",
      "-9.709638484819315\n",
      "length of actions is  1000\n",
      "120.53491468208306\n",
      "length of actions is  965\n",
      "Your final reward is : 62.13\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1620])\n",
      "246.24980018199687\n",
      "length of actions is  297\n",
      "251.48928726257287\n",
      "length of actions is  236\n",
      "243.70679013098777\n",
      "length of actions is  352\n",
      "21.79516741303064\n",
      "length of actions is  111\n",
      "273.2401082585701\n",
      "length of actions is  395\n",
      "Your final reward is : 207.30\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "227.09827688885062\n",
      "length of actions is  408\n",
      "20.448667627459713\n",
      "length of actions is  118\n",
      "205.54492364247125\n",
      "length of actions is  660\n",
      "-15.443475857113171\n",
      "length of actions is  95\n",
      "192.95766188248723\n",
      "length of actions is  698\n",
      "Your final reward is : 126.12\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2198])\n",
      "190.0863839512824\n",
      "length of actions is  587\n",
      "205.08139121110577\n",
      "length of actions is  491\n",
      "219.61236655919618\n",
      "length of actions is  503\n",
      "160.7506063909027\n",
      "length of actions is  648\n",
      "219.51556726365385\n",
      "length of actions is  448\n",
      "Your final reward is : 199.01\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1965])\n",
      "223.88670251498735\n",
      "length of actions is  349\n",
      "119.98952322208497\n",
      "length of actions is  1000\n",
      "173.0166191057496\n",
      "length of actions is  540\n",
      "240.11259455867892\n",
      "length of actions is  363\n",
      "131.5100788882059\n",
      "length of actions is  1000\n",
      "Your final reward is : 177.70\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2578])\n",
      "236.1511694782033\n",
      "length of actions is  348\n",
      "286.65711859010963\n",
      "length of actions is  282\n",
      "258.97795747405553\n",
      "length of actions is  327\n",
      "254.1289052839025\n",
      "length of actions is  309\n",
      "123.94743221090224\n",
      "length of actions is  1000\n",
      "Your final reward is : 231.97\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2275])\n",
      "228.8766199422575\n",
      "length of actions is  340\n",
      "294.0227208131271\n",
      "length of actions is  248\n",
      "205.6781124601289\n",
      "length of actions is  499\n",
      "200.18278986565196\n",
      "length of actions is  629\n",
      "268.0020340461259\n",
      "length of actions is  401\n",
      "Your final reward is : 239.35\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2291])\n",
      "237.78485967407872\n",
      "length of actions is  301\n",
      "264.7046427175337\n",
      "length of actions is  282\n",
      "262.16298331415976\n",
      "length of actions is  198\n",
      "248.9154467417025\n",
      "length of actions is  283\n",
      "256.2851883033453\n",
      "length of actions is  335\n",
      "Your final reward is : 253.97\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1514])\n",
      "241.73992150942217\n",
      "length of actions is  303\n",
      "276.20534155892875\n",
      "length of actions is  244\n",
      "244.26078392549235\n",
      "length of actions is  215\n",
      "304.7666800948483\n",
      "length of actions is  245\n",
      "268.707447006354\n",
      "length of actions is  268\n",
      "Your final reward is : 267.14\n",
      "Improve to score 267.14 at batch 269\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "243.11629854402676\n",
      "length of actions is  329\n",
      "276.9542232483302\n",
      "length of actions is  223\n",
      "270.66600060747066\n",
      "length of actions is  333\n",
      "298.1215605422752\n",
      "length of actions is  204\n",
      "249.69623372325233\n",
      "length of actions is  312\n",
      "Your final reward is : 267.71\n",
      "Improve to score 267.71 at batch 270\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2083])\n",
      "230.67941765214454\n",
      "length of actions is  318\n",
      "180.0078691027464\n",
      "length of actions is  1000\n",
      "240.77159886082308\n",
      "length of actions is  331\n",
      "269.7353393675822\n",
      "length of actions is  245\n",
      "224.45227383105043\n",
      "length of actions is  280\n",
      "Your final reward is : 229.13\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1971])\n",
      "255.05117612139256\n",
      "length of actions is  192\n",
      "247.54957373375288\n",
      "length of actions is  262\n",
      "255.20861247491638\n",
      "length of actions is  255\n",
      "137.59381564610356\n",
      "length of actions is  1000\n",
      "249.1497267056859\n",
      "length of actions is  269\n",
      "Your final reward is : 228.91\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1349])\n",
      "249.4031171772004\n",
      "length of actions is  196\n",
      "264.5790784437427\n",
      "length of actions is  273\n",
      "235.35669738177575\n",
      "length of actions is  222\n",
      "267.4073833480825\n",
      "length of actions is  257\n",
      "259.57778259420843\n",
      "length of actions is  247\n",
      "Your final reward is : 255.26\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3954])\n",
      "264.15546133402347\n",
      "length of actions is  186\n",
      "245.83131083715585\n",
      "length of actions is  265\n",
      "-13.252302909732578\n",
      "length of actions is  118\n",
      "154.28835730480586\n",
      "length of actions is  1000\n",
      "257.2096277414495\n",
      "length of actions is  206\n",
      "Your final reward is : 181.65\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1223])\n",
      "247.33415649082085\n",
      "length of actions is  182\n",
      "259.5761177483655\n",
      "length of actions is  228\n",
      "262.0680429644691\n",
      "length of actions is  251\n",
      "37.74875056880205\n",
      "length of actions is  149\n",
      "270.5830492382902\n",
      "length of actions is  236\n",
      "Your final reward is : 215.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1214])\n",
      "257.3464560388551\n",
      "length of actions is  195\n",
      "236.12317279366374\n",
      "length of actions is  229\n",
      "267.4579465204447\n",
      "length of actions is  711\n",
      "274.69668796288454\n",
      "length of actions is  239\n",
      "289.3789473717893\n",
      "length of actions is  258\n",
      "Your final reward is : 265.00\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1217])\n",
      "243.87524343869205\n",
      "length of actions is  278\n",
      "259.8439274548989\n",
      "length of actions is  261\n",
      "267.2414551542662\n",
      "length of actions is  199\n",
      "262.22963266725355\n",
      "length of actions is  237\n",
      "178.4515142300354\n",
      "length of actions is  1000\n",
      "Your final reward is : 242.33\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1317])\n",
      "240.13934760362878\n",
      "length of actions is  279\n",
      "279.653949982683\n",
      "length of actions is  211\n",
      "260.2658665884377\n",
      "length of actions is  243\n",
      "285.30130941382674\n",
      "length of actions is  257\n",
      "262.3249565214409\n",
      "length of actions is  294\n",
      "Your final reward is : 265.54\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2275])\n",
      "246.80241778562947\n",
      "length of actions is  278\n",
      "269.41232880883024\n",
      "length of actions is  279\n",
      "278.9900210257886\n",
      "length of actions is  303\n",
      "275.64152830567514\n",
      "length of actions is  221\n",
      "261.544679747876\n",
      "length of actions is  364\n",
      "Your final reward is : 266.48\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2412])\n",
      "250.4673624366056\n",
      "length of actions is  281\n",
      "269.77660236379575\n",
      "length of actions is  288\n",
      "255.6514633636594\n",
      "length of actions is  207\n",
      "274.2219211184334\n",
      "length of actions is  242\n",
      "310.30315473544493\n",
      "length of actions is  271\n",
      "Your final reward is : 272.08\n",
      "Improve to score 272.08 at batch 280\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1360])\n",
      "259.66271869116247\n",
      "length of actions is  195\n",
      "229.1140440191862\n",
      "length of actions is  244\n",
      "244.67471312281648\n",
      "length of actions is  233\n",
      "270.87053113171135\n",
      "length of actions is  314\n",
      "256.436890373158\n",
      "length of actions is  226\n",
      "Your final reward is : 252.15\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1497])\n",
      "254.18265956348887\n",
      "length of actions is  220\n",
      "254.27883976624958\n",
      "length of actions is  279\n",
      "278.55051739457036\n",
      "length of actions is  220\n",
      "296.89541634021396\n",
      "length of actions is  245\n",
      "262.76798468630307\n",
      "length of actions is  242\n",
      "Your final reward is : 269.34\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "238.75774084032273\n",
      "length of actions is  187\n",
      "254.99779854307425\n",
      "length of actions is  345\n",
      "280.9301324435712\n",
      "length of actions is  223\n",
      "158.41853876132768\n",
      "length of actions is  1000\n",
      "272.46342065473\n",
      "length of actions is  232\n",
      "Your final reward is : 241.11\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2577])\n",
      "261.1429682684193\n",
      "length of actions is  211\n",
      "274.3459678877141\n",
      "length of actions is  285\n",
      "281.595526460512\n",
      "length of actions is  291\n",
      "154.4860413856214\n",
      "length of actions is  1000\n",
      "177.63354220166244\n",
      "length of actions is  1000\n",
      "Your final reward is : 229.84\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1594])\n",
      "253.46100342958414\n",
      "length of actions is  237\n",
      "239.141311204177\n",
      "length of actions is  214\n",
      "252.89861194219037\n",
      "length of actions is  252\n",
      "259.44474627075806\n",
      "length of actions is  238\n",
      "290.52606594282315\n",
      "length of actions is  299\n",
      "Your final reward is : 259.09\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1369])\n",
      "256.1245904449391\n",
      "length of actions is  216\n",
      "249.09522447295282\n",
      "length of actions is  440\n",
      "249.35358217146\n",
      "length of actions is  261\n",
      "274.2958054305017\n",
      "length of actions is  187\n",
      "279.14152017249637\n",
      "length of actions is  195\n",
      "Your final reward is : 261.60\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1975])\n",
      "250.16888866216001\n",
      "length of actions is  260\n",
      "233.64840765433183\n",
      "length of actions is  212\n",
      "230.57069986591327\n",
      "length of actions is  241\n",
      "267.92483927617803\n",
      "length of actions is  396\n",
      "273.7031126004863\n",
      "length of actions is  222\n",
      "Your final reward is : 251.20\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "242.92175286585754\n",
      "length of actions is  424\n",
      "267.2284763847672\n",
      "length of actions is  294\n",
      "264.931854505072\n",
      "length of actions is  572\n",
      "239.83564456233105\n",
      "length of actions is  223\n",
      "263.33174140302737\n",
      "length of actions is  393\n",
      "Your final reward is : 255.65\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2316])\n",
      "257.01908913226464\n",
      "length of actions is  237\n",
      "236.41741233923318\n",
      "length of actions is  212\n",
      "165.29512955257468\n",
      "length of actions is  1000\n",
      "145.84381217027612\n",
      "length of actions is  1000\n",
      "261.4961516187834\n",
      "length of actions is  253\n",
      "Your final reward is : 213.21\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1497])\n",
      "242.83845285957364\n",
      "length of actions is  266\n",
      "269.6315193316428\n",
      "length of actions is  224\n",
      "261.5107432494566\n",
      "length of actions is  269\n",
      "272.91791835622803\n",
      "length of actions is  283\n",
      "264.67042579303455\n",
      "length of actions is  215\n",
      "Your final reward is : 262.31\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1348])\n",
      "252.70891140805733\n",
      "length of actions is  251\n",
      "266.37359013137717\n",
      "length of actions is  199\n",
      "261.834851800302\n",
      "length of actions is  203\n",
      "266.2865164468579\n",
      "length of actions is  240\n",
      "283.9357454331294\n",
      "length of actions is  230\n",
      "Your final reward is : 266.23\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "242.81849985426254\n",
      "length of actions is  253\n",
      "272.2123664863649\n",
      "length of actions is  248\n",
      "28.62989675921378\n",
      "length of actions is  179\n",
      "133.48060786064133\n",
      "length of actions is  1000\n",
      "268.1769693738064\n",
      "length of actions is  305\n",
      "Your final reward is : 189.06\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2149])\n",
      "249.41979387202\n",
      "length of actions is  321\n",
      "264.34741060023555\n",
      "length of actions is  228\n",
      "287.1123287032556\n",
      "length of actions is  221\n",
      "173.84946494334037\n",
      "length of actions is  1000\n",
      "120.16927385766158\n",
      "length of actions is  1000\n",
      "Your final reward is : 218.98\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2082])\n",
      "251.2579923925929\n",
      "length of actions is  199\n",
      "271.6215826526684\n",
      "length of actions is  218\n",
      "247.74703338527942\n",
      "length of actions is  193\n",
      "181.4961956734524\n",
      "length of actions is  1000\n",
      "272.3161270302402\n",
      "length of actions is  205\n",
      "Your final reward is : 244.89\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2687])\n",
      "251.45773279913428\n",
      "length of actions is  267\n",
      "152.09688744878662\n",
      "length of actions is  1000\n",
      "271.150254627951\n",
      "length of actions is  222\n",
      "67.99828776505285\n",
      "length of actions is  208\n",
      "282.8194198638967\n",
      "length of actions is  219\n",
      "Your final reward is : 205.10\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1178])\n",
      "259.25933050408264\n",
      "length of actions is  231\n",
      "278.0741678987222\n",
      "length of actions is  220\n",
      "176.47307946939893\n",
      "length of actions is  1000\n",
      "265.3827161674198\n",
      "length of actions is  200\n",
      "229.42929744095423\n",
      "length of actions is  237\n",
      "Your final reward is : 241.72\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1378])\n",
      "258.43339794960633\n",
      "length of actions is  245\n",
      "297.03702284390124\n",
      "length of actions is  222\n",
      "240.57874720224112\n",
      "length of actions is  237\n",
      "236.80015370688994\n",
      "length of actions is  226\n",
      "282.85374630318347\n",
      "length of actions is  188\n",
      "Your final reward is : 263.14\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2176])\n",
      "258.5528988744119\n",
      "length of actions is  260\n",
      "236.30623143018602\n",
      "length of actions is  202\n",
      "263.94374588732455\n",
      "length of actions is  226\n",
      "282.8661122272198\n",
      "length of actions is  281\n",
      "290.39364635650315\n",
      "length of actions is  277\n",
      "Your final reward is : 266.41\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1176])\n",
      "118.51399965226405\n",
      "length of actions is  1000\n",
      "56.779620596807376\n",
      "length of actions is  197\n",
      "20.53472420357548\n",
      "length of actions is  195\n",
      "291.28919568035496\n",
      "length of actions is  236\n",
      "269.65292137671474\n",
      "length of actions is  234\n",
      "Your final reward is : 151.35\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1371])\n",
      "265.72511046336865\n",
      "length of actions is  236\n",
      "12.177589193395775\n",
      "length of actions is  188\n",
      "287.88239075093867\n",
      "length of actions is  239\n",
      "174.2349146560684\n",
      "length of actions is  1000\n",
      "287.64574339562193\n",
      "length of actions is  283\n",
      "Your final reward is : 205.53\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3017])\n",
      "263.4279322217052\n",
      "length of actions is  247\n",
      "42.60364388626135\n",
      "length of actions is  169\n",
      "162.92332259961123\n",
      "length of actions is  1000\n",
      "287.12020399404423\n",
      "length of actions is  289\n",
      "193.84142021307633\n",
      "length of actions is  1000\n",
      "Your final reward is : 189.98\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1176])\n",
      "256.1285039057272\n",
      "length of actions is  244\n",
      "246.48634265347243\n",
      "length of actions is  199\n",
      "230.33186879269437\n",
      "length of actions is  310\n",
      "153.02465301519214\n",
      "length of actions is  1000\n",
      "271.38156431082996\n",
      "length of actions is  193\n",
      "Your final reward is : 231.47\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3209])\n",
      "150.36165465485692\n",
      "length of actions is  1000\n",
      "172.10796132326288\n",
      "length of actions is  1000\n",
      "150.31830371297815\n",
      "length of actions is  1000\n",
      "158.2094869755261\n",
      "length of actions is  1000\n",
      "239.80286744190744\n",
      "length of actions is  179\n",
      "Your final reward is : 174.16\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1530])\n",
      "261.34833519964366\n",
      "length of actions is  244\n",
      "240.75789258314174\n",
      "length of actions is  186\n",
      "243.76483041828286\n",
      "length of actions is  271\n",
      "253.11342681005442\n",
      "length of actions is  203\n",
      "288.20989721114154\n",
      "length of actions is  271\n",
      "Your final reward is : 257.44\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2412])\n",
      "241.54450913337436\n",
      "length of actions is  254\n",
      "276.0594419356015\n",
      "length of actions is  243\n",
      "151.3116885035224\n",
      "length of actions is  1000\n",
      "259.51505676172087\n",
      "length of actions is  177\n",
      "294.45749454314176\n",
      "length of actions is  283\n",
      "Your final reward is : 244.58\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1107])\n",
      "259.3954893413865\n",
      "length of actions is  226\n",
      "242.69814657595745\n",
      "length of actions is  231\n",
      "263.5102059014878\n",
      "length of actions is  240\n",
      "233.00772836382183\n",
      "length of actions is  221\n",
      "275.2261939355932\n",
      "length of actions is  205\n",
      "Your final reward is : 254.77\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1992])\n",
      "256.62084740815453\n",
      "length of actions is  220\n",
      "145.2642338604153\n",
      "length of actions is  1000\n",
      "276.93208088352355\n",
      "length of actions is  266\n",
      "289.8561730129984\n",
      "length of actions is  308\n",
      "274.7169553288637\n",
      "length of actions is  188\n",
      "Your final reward is : 248.68\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1349])\n",
      "129.61636509695788\n",
      "length of actions is  1000\n",
      "291.442849543275\n",
      "length of actions is  256\n",
      "172.53689528501872\n",
      "length of actions is  1000\n",
      "311.21911108837827\n",
      "length of actions is  233\n",
      "245.51423538111135\n",
      "length of actions is  697\n",
      "Your final reward is : 230.07\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1497])\n",
      "253.29255184994685\n",
      "length of actions is  605\n",
      "121.96887944791926\n",
      "length of actions is  1000\n",
      "166.1830841847517\n",
      "length of actions is  1000\n",
      "274.5962877327912\n",
      "length of actions is  178\n",
      "140.023686416107\n",
      "length of actions is  1000\n",
      "Your final reward is : 191.21\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1217])\n",
      "259.3418432499586\n",
      "length of actions is  240\n",
      "243.60302661575676\n",
      "length of actions is  178\n",
      "225.51854809248607\n",
      "length of actions is  968\n",
      "257.051881365057\n",
      "length of actions is  248\n",
      "233.63147258236688\n",
      "length of actions is  261\n",
      "Your final reward is : 243.83\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2353])\n",
      "258.94795259087186\n",
      "length of actions is  270\n",
      "243.11536718029234\n",
      "length of actions is  442\n",
      "251.54617333595655\n",
      "length of actions is  205\n",
      "273.5634143020228\n",
      "length of actions is  203\n",
      "224.10826579073552\n",
      "length of actions is  734\n",
      "Your final reward is : 250.26\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1577])\n",
      "263.43610822750213\n",
      "length of actions is  228\n",
      "54.90322610292566\n",
      "length of actions is  188\n",
      "295.87111507169095\n",
      "length of actions is  287\n",
      "270.7378174547903\n",
      "length of actions is  216\n",
      "271.4109815133787\n",
      "length of actions is  202\n",
      "Your final reward is : 231.27\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1500])\n",
      "252.30094518085093\n",
      "length of actions is  264\n",
      "155.51154537182094\n",
      "length of actions is  1000\n",
      "166.81250794222137\n",
      "length of actions is  1000\n",
      "261.37609041748647\n",
      "length of actions is  209\n",
      "159.63139832591608\n",
      "length of actions is  1000\n",
      "Your final reward is : 199.13\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1420])\n",
      "265.65516843946284\n",
      "length of actions is  247\n",
      "264.76689586213917\n",
      "length of actions is  239\n",
      "66.02807030333284\n",
      "length of actions is  183\n",
      "269.3941751472257\n",
      "length of actions is  308\n",
      "293.4191494262316\n",
      "length of actions is  256\n",
      "Your final reward is : 231.85\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1026])\n",
      "149.88505823254704\n",
      "length of actions is  1000\n",
      "289.3861825231229\n",
      "length of actions is  282\n",
      "256.64821690292194\n",
      "length of actions is  188\n",
      "280.15195915418576\n",
      "length of actions is  294\n",
      "172.20744605815187\n",
      "length of actions is  1000\n",
      "Your final reward is : 229.66\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1220])\n",
      "260.9244615596296\n",
      "length of actions is  238\n",
      "236.01896336069572\n",
      "length of actions is  222\n",
      "261.1939976162804\n",
      "length of actions is  203\n",
      "296.0455520045085\n",
      "length of actions is  232\n",
      "259.2470542845182\n",
      "length of actions is  252\n",
      "Your final reward is : 262.69\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1990])\n",
      "250.86137348339972\n",
      "length of actions is  786\n",
      "0.1586438142380615\n",
      "length of actions is  156\n",
      "175.97872076857195\n",
      "length of actions is  1000\n",
      "258.04911746860284\n",
      "length of actions is  301\n",
      "140.6488208687236\n",
      "length of actions is  1000\n",
      "Your final reward is : 165.14\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1215])\n",
      "254.31764016922435\n",
      "length of actions is  253\n",
      "282.0278545488968\n",
      "length of actions is  257\n",
      "269.02859912900556\n",
      "length of actions is  324\n",
      "279.5540347716801\n",
      "length of actions is  335\n",
      "281.2041656070475\n",
      "length of actions is  220\n",
      "Your final reward is : 273.23\n",
      "Improve to score 273.23 at batch 318\n",
      "torch.from_numpy(rewards) looks like  torch.Size([845])\n",
      "263.98910818362754\n",
      "length of actions is  251\n",
      "255.57521080537768\n",
      "length of actions is  241\n",
      "240.13131638916923\n",
      "length of actions is  214\n",
      "268.2914587341078\n",
      "length of actions is  204\n",
      "273.2673606205059\n",
      "length of actions is  273\n",
      "Your final reward is : 260.25\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1431])\n",
      "253.68995649217152\n",
      "length of actions is  290\n",
      "56.5250507197953\n",
      "length of actions is  169\n",
      "253.6227869994792\n",
      "length of actions is  326\n",
      "102.66183164519143\n",
      "length of actions is  170\n",
      "226.71333039903016\n",
      "length of actions is  356\n",
      "Your final reward is : 178.64\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1342])\n",
      "135.34364016739647\n",
      "length of actions is  1000\n",
      "57.00916730279059\n",
      "length of actions is  181\n",
      "148.98925904295493\n",
      "length of actions is  1000\n",
      "190.84752070345775\n",
      "length of actions is  1000\n",
      "172.30066507240028\n",
      "length of actions is  1000\n",
      "Your final reward is : 140.90\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1344])\n",
      "150.3036431666177\n",
      "length of actions is  1000\n",
      "58.484027236419706\n",
      "length of actions is  174\n",
      "262.86645745722956\n",
      "length of actions is  187\n",
      "5.788123577433723\n",
      "length of actions is  170\n",
      "236.95621442930752\n",
      "length of actions is  953\n",
      "Your final reward is : 142.88\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1577])\n",
      "252.83370462151044\n",
      "length of actions is  269\n",
      "38.95506231535376\n",
      "length of actions is  181\n",
      "244.98536273485485\n",
      "length of actions is  341\n",
      "44.863859642940355\n",
      "length of actions is  187\n",
      "250.81569042093858\n",
      "length of actions is  305\n",
      "Your final reward is : 166.49\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1613])\n",
      "233.34799968275163\n",
      "length of actions is  393\n",
      "232.4878453917001\n",
      "length of actions is  286\n",
      "240.29100045467678\n",
      "length of actions is  503\n",
      "188.52202277105147\n",
      "length of actions is  1000\n",
      "277.5851814359015\n",
      "length of actions is  279\n",
      "Your final reward is : 234.45\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1373])\n",
      "259.4649530432443\n",
      "length of actions is  244\n",
      "242.87244344410627\n",
      "length of actions is  215\n",
      "271.9573792502856\n",
      "length of actions is  248\n",
      "294.01325584332494\n",
      "length of actions is  275\n",
      "293.6267716620242\n",
      "length of actions is  549\n",
      "Your final reward is : 272.39\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1319])\n",
      "257.40814850275325\n",
      "length of actions is  249\n",
      "221.47234649763146\n",
      "length of actions is  319\n",
      "245.37558064154226\n",
      "length of actions is  251\n",
      "270.2401650150442\n",
      "length of actions is  339\n",
      "137.5755061881631\n",
      "length of actions is  1000\n",
      "Your final reward is : 226.41\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1497])\n",
      "261.2956423399103\n",
      "length of actions is  267\n",
      "271.62910838183086\n",
      "length of actions is  204\n",
      "290.4410993597564\n",
      "length of actions is  239\n",
      "269.5063464794805\n",
      "length of actions is  242\n",
      "261.43540832738046\n",
      "length of actions is  272\n",
      "Your final reward is : 270.86\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1348])\n",
      "257.7307468615745\n",
      "length of actions is  249\n",
      "226.23792532436772\n",
      "length of actions is  286\n",
      "272.21673788424994\n",
      "length of actions is  249\n",
      "218.2995953475737\n",
      "length of actions is  378\n",
      "291.3899394595034\n",
      "length of actions is  232\n",
      "Your final reward is : 253.17\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1348])\n",
      "260.6310764699771\n",
      "length of actions is  246\n",
      "270.35227371072006\n",
      "length of actions is  241\n",
      "243.80461316956593\n",
      "length of actions is  230\n",
      "278.9753279162815\n",
      "length of actions is  267\n",
      "183.7420512538471\n",
      "length of actions is  1000\n",
      "Your final reward is : 247.50\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1423])\n",
      "264.2157530398058\n",
      "length of actions is  252\n",
      "274.395742376524\n",
      "length of actions is  196\n",
      "256.91081848928854\n",
      "length of actions is  219\n",
      "172.3537118113376\n",
      "length of actions is  1000\n",
      "232.7362241835923\n",
      "length of actions is  261\n",
      "Your final reward is : 240.12\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1533])\n",
      "252.72749296074085\n",
      "length of actions is  237\n",
      "234.41077459178092\n",
      "length of actions is  220\n",
      "252.08004269808615\n",
      "length of actions is  261\n",
      "280.52349162051064\n",
      "length of actions is  256\n",
      "290.2215429859999\n",
      "length of actions is  217\n",
      "Your final reward is : 261.99\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1356])\n",
      "129.34176465823813\n",
      "length of actions is  1000\n",
      "284.6433262346702\n",
      "length of actions is  247\n",
      "282.39373992661547\n",
      "length of actions is  228\n",
      "240.73357819777118\n",
      "length of actions is  205\n",
      "279.29306631680583\n",
      "length of actions is  273\n",
      "Your final reward is : 243.28\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1082])\n",
      "260.5213603091404\n",
      "length of actions is  245\n",
      "294.542847483629\n",
      "length of actions is  250\n",
      "227.0326732700961\n",
      "length of actions is  282\n",
      "219.287633853407\n",
      "length of actions is  397\n",
      "293.76080242814794\n",
      "length of actions is  266\n",
      "Your final reward is : 259.03\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1416])\n",
      "132.19716151867664\n",
      "length of actions is  1000\n",
      "279.91782221731074\n",
      "length of actions is  253\n",
      "252.58011420971474\n",
      "length of actions is  266\n",
      "268.4207942223644\n",
      "length of actions is  254\n",
      "254.0981363049972\n",
      "length of actions is  248\n",
      "Your final reward is : 237.44\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1022])\n",
      "254.31341642835935\n",
      "length of actions is  228\n",
      "6.468124351793776\n",
      "length of actions is  170\n",
      "-13.794736185979573\n",
      "length of actions is  174\n",
      "245.18832376194064\n",
      "length of actions is  224\n",
      "249.95404525499967\n",
      "length of actions is  528\n",
      "Your final reward is : 148.43\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1314])\n",
      "258.7775762792696\n",
      "length of actions is  257\n",
      "250.18778931687802\n",
      "length of actions is  320\n",
      "158.1339676870105\n",
      "length of actions is  1000\n",
      "256.9664965094389\n",
      "length of actions is  226\n",
      "288.6547117058777\n",
      "length of actions is  231\n",
      "Your final reward is : 242.54\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "256.35716061545565\n",
      "length of actions is  238\n",
      "233.49050996707592\n",
      "length of actions is  262\n",
      "231.5900495042775\n",
      "length of actions is  272\n",
      "279.46302384970113\n",
      "length of actions is  250\n",
      "269.846718622136\n",
      "length of actions is  246\n",
      "Your final reward is : 254.15\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "255.5794820096592\n",
      "length of actions is  234\n",
      "263.46487894174334\n",
      "length of actions is  262\n",
      "4.361351366227041\n",
      "length of actions is  188\n",
      "258.0837262135062\n",
      "length of actions is  225\n",
      "267.79899456289274\n",
      "length of actions is  254\n",
      "Your final reward is : 209.86\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2733])\n",
      "248.53801475744217\n",
      "length of actions is  225\n",
      "251.1666437246966\n",
      "length of actions is  244\n",
      "229.82066468973312\n",
      "length of actions is  253\n",
      "9.034226377541955\n",
      "length of actions is  189\n",
      "147.19698432457452\n",
      "length of actions is  1000\n",
      "Your final reward is : 177.15\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "242.78149278853414\n",
      "length of actions is  213\n",
      "252.55780419469573\n",
      "length of actions is  230\n",
      "244.65825021799776\n",
      "length of actions is  225\n",
      "115.05894389175407\n",
      "length of actions is  1000\n",
      "286.0358647907642\n",
      "length of actions is  233\n",
      "Your final reward is : 228.22\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1590])\n",
      "250.74783325605236\n",
      "length of actions is  229\n",
      "271.2879052498764\n",
      "length of actions is  221\n",
      "250.03405899751158\n",
      "length of actions is  290\n",
      "275.56230644576567\n",
      "length of actions is  225\n",
      "276.3295315375826\n",
      "length of actions is  222\n",
      "Your final reward is : 264.79\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1369])\n",
      "254.41201168212433\n",
      "length of actions is  243\n",
      "250.7379345029863\n",
      "length of actions is  242\n",
      "266.59863669273835\n",
      "length of actions is  566\n",
      "246.31608122783445\n",
      "length of actions is  384\n",
      "113.31836947829879\n",
      "length of actions is  1000\n",
      "Your final reward is : 226.28\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1944])\n",
      "239.04501966325242\n",
      "length of actions is  472\n",
      "154.3412949301015\n",
      "length of actions is  1000\n",
      "138.06033270360362\n",
      "length of actions is  1000\n",
      "273.2061856284751\n",
      "length of actions is  232\n",
      "238.9293618134106\n",
      "length of actions is  251\n",
      "Your final reward is : 208.72\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1981])\n",
      "253.24910335204183\n",
      "length of actions is  220\n",
      "142.2448020552101\n",
      "length of actions is  1000\n",
      "271.8966880162985\n",
      "length of actions is  250\n",
      "157.53414561617913\n",
      "length of actions is  1000\n",
      "275.42553473091664\n",
      "length of actions is  260\n",
      "Your final reward is : 220.07\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1348])\n",
      "243.81979705554843\n",
      "length of actions is  790\n",
      "4.110490511424544\n",
      "length of actions is  239\n",
      "240.82275759811012\n",
      "length of actions is  308\n",
      "241.36004514096012\n",
      "length of actions is  278\n",
      "240.96231871493865\n",
      "length of actions is  304\n",
      "Your final reward is : 194.22\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1380])\n",
      "235.3205932868029\n",
      "length of actions is  843\n",
      "145.59212087927807\n",
      "length of actions is  1000\n",
      "170.26063594039297\n",
      "length of actions is  1000\n",
      "238.39401534940558\n",
      "length of actions is  270\n",
      "167.67654406336342\n",
      "length of actions is  1000\n",
      "Your final reward is : 191.45\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2290])\n",
      "247.06060438386277\n",
      "length of actions is  215\n",
      "261.1653749880984\n",
      "length of actions is  230\n",
      "270.0447701694486\n",
      "length of actions is  231\n",
      "25.615135644045154\n",
      "length of actions is  241\n",
      "240.14767186998677\n",
      "length of actions is  239\n",
      "Your final reward is : 208.81\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2828])\n",
      "239.11787577756067\n",
      "length of actions is  235\n",
      "276.1038728565811\n",
      "length of actions is  231\n",
      "157.87772734026709\n",
      "length of actions is  1000\n",
      "261.05735687062906\n",
      "length of actions is  206\n",
      "144.57514002227362\n",
      "length of actions is  1000\n",
      "Your final reward is : 215.75\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1501])\n",
      "246.97722072910676\n",
      "length of actions is  218\n",
      "279.1581107636524\n",
      "length of actions is  269\n",
      "248.0935352347115\n",
      "length of actions is  257\n",
      "257.9966065975003\n",
      "length of actions is  266\n",
      "243.4601736645522\n",
      "length of actions is  237\n",
      "Your final reward is : 255.14\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2141])\n",
      "244.152817875475\n",
      "length of actions is  209\n",
      "270.607933621251\n",
      "length of actions is  282\n",
      "185.83653286033257\n",
      "length of actions is  1000\n",
      "264.4320548937616\n",
      "length of actions is  246\n",
      "248.08795426073945\n",
      "length of actions is  350\n",
      "Your final reward is : 242.62\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2090])\n",
      "251.13470085949035\n",
      "length of actions is  220\n",
      "141.0529284023674\n",
      "length of actions is  1000\n",
      "262.57327815775886\n",
      "length of actions is  289\n",
      "252.34646470211075\n",
      "length of actions is  234\n",
      "268.5293442337955\n",
      "length of actions is  387\n",
      "Your final reward is : 235.13\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2379])\n",
      "237.06870768058258\n",
      "length of actions is  236\n",
      "277.8048388336391\n",
      "length of actions is  292\n",
      "131.47787541931092\n",
      "length of actions is  1000\n",
      "45.36979186117067\n",
      "length of actions is  1000\n",
      "126.72727413421102\n",
      "length of actions is  1000\n",
      "Your final reward is : 163.69\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1984])\n",
      "239.13740205615477\n",
      "length of actions is  212\n",
      "270.7340143432236\n",
      "length of actions is  258\n",
      "263.74113871665674\n",
      "length of actions is  302\n",
      "292.6604888694086\n",
      "length of actions is  239\n",
      "246.89847172257328\n",
      "length of actions is  224\n",
      "Your final reward is : 262.63\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2082])\n",
      "241.4250230220651\n",
      "length of actions is  221\n",
      "243.02441248289995\n",
      "length of actions is  220\n",
      "233.37828308069737\n",
      "length of actions is  285\n",
      "254.66248273676533\n",
      "length of actions is  426\n",
      "-35.19248145856274\n",
      "length of actions is  1000\n",
      "Your final reward is : 187.46\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "239.34300130730875\n",
      "length of actions is  228\n",
      "-0.8017522634247314\n",
      "length of actions is  176\n",
      "239.44135495432135\n",
      "length of actions is  501\n",
      "230.4901452335804\n",
      "length of actions is  324\n",
      "260.65474622453866\n",
      "length of actions is  317\n",
      "Your final reward is : 193.83\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1214])\n",
      "237.3848129290551\n",
      "length of actions is  252\n",
      "271.06225597972923\n",
      "length of actions is  197\n",
      "126.35585536189177\n",
      "length of actions is  1000\n",
      "138.1856638719726\n",
      "length of actions is  1000\n",
      "233.7648043365631\n",
      "length of actions is  282\n",
      "Your final reward is : 201.35\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2411])\n",
      "230.25721524067967\n",
      "length of actions is  843\n",
      "271.3794182795991\n",
      "length of actions is  278\n",
      "267.5497109654524\n",
      "length of actions is  246\n",
      "263.62888421785476\n",
      "length of actions is  385\n",
      "254.04260972651403\n",
      "length of actions is  234\n",
      "Your final reward is : 257.37\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1722])\n",
      "240.70237986156417\n",
      "length of actions is  237\n",
      "232.05873390983473\n",
      "length of actions is  223\n",
      "255.90826557512233\n",
      "length of actions is  188\n",
      "250.02375618278884\n",
      "length of actions is  224\n",
      "248.55434878684613\n",
      "length of actions is  215\n",
      "Your final reward is : 245.45\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1187])\n",
      "246.38926949963175\n",
      "length of actions is  225\n",
      "248.3711186427025\n",
      "length of actions is  242\n",
      "30.5298102025518\n",
      "length of actions is  134\n",
      "158.86769210054516\n",
      "length of actions is  1000\n",
      "263.4617366603784\n",
      "length of actions is  181\n",
      "Your final reward is : 189.52\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1578])\n",
      "238.44098796188445\n",
      "length of actions is  226\n",
      "235.31849033931675\n",
      "length of actions is  266\n",
      "236.66569466046468\n",
      "length of actions is  216\n",
      "265.1169222779753\n",
      "length of actions is  292\n",
      "118.69871506393075\n",
      "length of actions is  1000\n",
      "Your final reward is : 218.85\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1705])\n",
      "225.42058637707544\n",
      "length of actions is  332\n",
      "190.58199100644697\n",
      "length of actions is  821\n",
      "262.6557447134646\n",
      "length of actions is  240\n",
      "255.99204823924185\n",
      "length of actions is  266\n",
      "6.396566447845456\n",
      "length of actions is  1000\n",
      "Your final reward is : 188.21\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3668])\n",
      "211.27332477526699\n",
      "length of actions is  843\n",
      "2.6332960415191087\n",
      "length of actions is  1000\n",
      "228.53021939194718\n",
      "length of actions is  485\n",
      "93.22796133754882\n",
      "length of actions is  1000\n",
      "-13.518510725064163\n",
      "length of actions is  1000\n",
      "Your final reward is : 104.43\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2732])\n",
      "234.3697648948378\n",
      "length of actions is  272\n",
      "216.93171770716913\n",
      "length of actions is  377\n",
      "9.868959647534728\n",
      "length of actions is  1000\n",
      "271.53599999413296\n",
      "length of actions is  233\n",
      "85.93048110327548\n",
      "length of actions is  1000\n",
      "Your final reward is : 163.73\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1705])\n",
      "232.54032417306894\n",
      "length of actions is  249\n",
      "200.48413332515435\n",
      "length of actions is  392\n",
      "222.14479700857115\n",
      "length of actions is  402\n",
      "222.68025322324561\n",
      "length of actions is  353\n",
      "252.66646533446888\n",
      "length of actions is  214\n",
      "Your final reward is : 226.10\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4447])\n",
      "241.55750386560513\n",
      "length of actions is  220\n",
      "238.35834526824794\n",
      "length of actions is  287\n",
      "117.12296559260503\n",
      "length of actions is  1000\n",
      "258.14671225281165\n",
      "length of actions is  593\n",
      "146.58052484860445\n",
      "length of actions is  1000\n",
      "Your final reward is : 200.35\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1503])\n",
      "225.2241549981449\n",
      "length of actions is  790\n",
      "196.14864111286914\n",
      "length of actions is  440\n",
      "50.50588577754823\n",
      "length of actions is  94\n",
      "142.52639667878702\n",
      "length of actions is  1000\n",
      "174.05264319723074\n",
      "length of actions is  554\n",
      "Your final reward is : 157.69\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1318])\n",
      "221.61269795711095\n",
      "length of actions is  344\n",
      "267.1530654225126\n",
      "length of actions is  327\n",
      "192.16522326621072\n",
      "length of actions is  550\n",
      "117.56002811677193\n",
      "length of actions is  1000\n",
      "207.8494375302139\n",
      "length of actions is  403\n",
      "Your final reward is : 201.27\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2062])\n",
      "220.8673186722522\n",
      "length of actions is  844\n",
      "250.68048151458444\n",
      "length of actions is  194\n",
      "267.2493334011569\n",
      "length of actions is  278\n",
      "267.53112560229204\n",
      "length of actions is  181\n",
      "293.4767472830839\n",
      "length of actions is  159\n",
      "Your final reward is : 259.96\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3116])\n",
      "215.48124960269945\n",
      "length of actions is  286\n",
      "211.71497375262322\n",
      "length of actions is  349\n",
      "234.7630826119472\n",
      "length of actions is  296\n",
      "138.87441306826688\n",
      "length of actions is  1000\n",
      "112.48364941131737\n",
      "length of actions is  1000\n",
      "Your final reward is : 182.66\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1966])\n",
      "207.5171088483725\n",
      "length of actions is  352\n",
      "254.8986642529723\n",
      "length of actions is  228\n",
      "217.4982820739711\n",
      "length of actions is  266\n",
      "103.41091120197858\n",
      "length of actions is  1000\n",
      "237.6294579614754\n",
      "length of actions is  313\n",
      "Your final reward is : 204.19\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1307])\n",
      "220.88535225575635\n",
      "length of actions is  265\n",
      "76.32823488219111\n",
      "length of actions is  1000\n",
      "4.7622137466122325\n",
      "length of actions is  207\n",
      "216.19832192364476\n",
      "length of actions is  263\n",
      "116.69884634709234\n",
      "length of actions is  1000\n",
      "Your final reward is : 126.97\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1964])\n",
      "216.78339104689678\n",
      "length of actions is  266\n",
      "276.9888002387886\n",
      "length of actions is  198\n",
      "202.1625402518236\n",
      "length of actions is  381\n",
      "102.66635763864986\n",
      "length of actions is  1000\n",
      "36.55335794209989\n",
      "length of actions is  144\n",
      "Your final reward is : 167.03\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2426])\n",
      "223.58567632674394\n",
      "length of actions is  256\n",
      "143.49840046800696\n",
      "length of actions is  1000\n",
      "277.88072977797134\n",
      "length of actions is  261\n",
      "226.4973442089427\n",
      "length of actions is  269\n",
      "114.03656048102008\n",
      "length of actions is  1000\n",
      "Your final reward is : 197.10\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1593])\n",
      "94.15183859832084\n",
      "length of actions is  1000\n",
      "280.3472762766474\n",
      "length of actions is  232\n",
      "267.10489777040146\n",
      "length of actions is  525\n",
      "251.23236486508705\n",
      "length of actions is  221\n",
      "260.4515167835706\n",
      "length of actions is  395\n",
      "Your final reward is : 230.66\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2076])\n",
      "215.7644643143804\n",
      "length of actions is  534\n",
      "161.61962079959636\n",
      "length of actions is  1000\n",
      "167.21513640183207\n",
      "length of actions is  1000\n",
      "181.65858891062828\n",
      "length of actions is  1000\n",
      "267.85436436439477\n",
      "length of actions is  324\n",
      "Your final reward is : 198.82\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1349])\n",
      "220.12611194362478\n",
      "length of actions is  287\n",
      "88.57875838537798\n",
      "length of actions is  1000\n",
      "225.880366465211\n",
      "length of actions is  379\n",
      "116.28843398056253\n",
      "length of actions is  1000\n",
      "222.24897964701836\n",
      "length of actions is  587\n",
      "Your final reward is : 174.62\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1587])\n",
      "199.7439923764219\n",
      "length of actions is  334\n",
      "121.76933435026338\n",
      "length of actions is  1000\n",
      "233.47956500021084\n",
      "length of actions is  289\n",
      "41.8332469332087\n",
      "length of actions is  209\n",
      "271.01580739465066\n",
      "length of actions is  305\n",
      "Your final reward is : 173.57\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "219.21397174920347\n",
      "length of actions is  245\n",
      "306.36793102390504\n",
      "length of actions is  165\n",
      "116.70550729576865\n",
      "length of actions is  1000\n",
      "7.262135029851464\n",
      "length of actions is  180\n",
      "281.79448176628273\n",
      "length of actions is  220\n",
      "Your final reward is : 186.27\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3041])\n",
      "202.58509553329077\n",
      "length of actions is  374\n",
      "-7.234334807056371\n",
      "length of actions is  364\n",
      "165.2158553773907\n",
      "length of actions is  316\n",
      "172.47500697819524\n",
      "length of actions is  521\n",
      "240.1655875734739\n",
      "length of actions is  386\n",
      "Your final reward is : 154.64\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2623])\n",
      "224.12782291174665\n",
      "length of actions is  645\n",
      "254.66995851192615\n",
      "length of actions is  275\n",
      "165.40273502512116\n",
      "length of actions is  691\n",
      "233.46342787045378\n",
      "length of actions is  418\n",
      "239.20444498625383\n",
      "length of actions is  253\n",
      "Your final reward is : 223.37\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2296])\n",
      "168.72899537040792\n",
      "length of actions is  746\n",
      "183.88722277595073\n",
      "length of actions is  264\n",
      "209.18529024821441\n",
      "length of actions is  424\n",
      "167.96282976559993\n",
      "length of actions is  1000\n",
      "160.45381917068218\n",
      "length of actions is  642\n",
      "Your final reward is : 178.04\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1734])\n",
      "199.84343380587012\n",
      "length of actions is  343\n",
      "17.315978915699432\n",
      "length of actions is  227\n",
      "242.24166026799514\n",
      "length of actions is  258\n",
      "115.73393603763472\n",
      "length of actions is  1000\n",
      "274.2576935085049\n",
      "length of actions is  185\n",
      "Your final reward is : 169.88\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3096])\n",
      "-6.545198074922851\n",
      "length of actions is  250\n",
      "229.83718641784358\n",
      "length of actions is  259\n",
      "212.83030227325395\n",
      "length of actions is  264\n",
      "215.46371045738601\n",
      "length of actions is  357\n",
      "141.87700456939632\n",
      "length of actions is  1000\n",
      "Your final reward is : 158.69\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1964])\n",
      "221.8873366263539\n",
      "length of actions is  261\n",
      "92.9668389769368\n",
      "length of actions is  1000\n",
      "226.33859670823207\n",
      "length of actions is  203\n",
      "172.9443917178205\n",
      "length of actions is  399\n",
      "101.87348498333378\n",
      "length of actions is  1000\n",
      "Your final reward is : 163.20\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1314])\n",
      "209.08615413278602\n",
      "length of actions is  358\n",
      "-27.60407899826764\n",
      "length of actions is  1000\n",
      "162.40172584036642\n",
      "length of actions is  449\n",
      "118.42736537683294\n",
      "length of actions is  1000\n",
      "252.30764048774535\n",
      "length of actions is  844\n",
      "Your final reward is : 142.92\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1087])\n",
      "191.0909381373386\n",
      "length of actions is  441\n",
      "-47.66335144541849\n",
      "length of actions is  1000\n",
      "272.76884531238915\n",
      "length of actions is  320\n",
      "293.0484104150165\n",
      "length of actions is  166\n",
      "289.09098208835735\n",
      "length of actions is  223\n",
      "Your final reward is : 199.67\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2502])\n",
      "102.41498969696619\n",
      "length of actions is  1000\n",
      "295.0773194432307\n",
      "length of actions is  240\n",
      "285.21218152067456\n",
      "length of actions is  257\n",
      "267.6281013528373\n",
      "length of actions is  188\n",
      "89.07703664940561\n",
      "length of actions is  1000\n",
      "Your final reward is : 207.88\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1963])\n",
      "218.02275703921134\n",
      "length of actions is  280\n",
      "-28.783977452883324\n",
      "length of actions is  1000\n",
      "258.2986220315505\n",
      "length of actions is  207\n",
      "279.4387408195061\n",
      "length of actions is  193\n",
      "235.59845836669496\n",
      "length of actions is  297\n",
      "Your final reward is : 192.51\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2412])\n",
      "67.33759574195832\n",
      "length of actions is  1000\n",
      "291.2686853587103\n",
      "length of actions is  255\n",
      "264.9770116626388\n",
      "length of actions is  198\n",
      "107.91732071962792\n",
      "length of actions is  1000\n",
      "150.62970254703748\n",
      "length of actions is  506\n",
      "Your final reward is : 176.43\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2045])\n",
      "224.06072612078117\n",
      "length of actions is  238\n",
      "-0.46675489781021895\n",
      "length of actions is  166\n",
      "290.5171734739787\n",
      "length of actions is  208\n",
      "38.75486873292755\n",
      "length of actions is  189\n",
      "200.71352356944072\n",
      "length of actions is  230\n",
      "Your final reward is : 150.72\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2044])\n",
      "224.1573146677436\n",
      "length of actions is  263\n",
      "284.50268171563664\n",
      "length of actions is  194\n",
      "204.57836470310198\n",
      "length of actions is  466\n",
      "295.6733700439585\n",
      "length of actions is  255\n",
      "13.784615170874915\n",
      "length of actions is  213\n",
      "Your final reward is : 204.54\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1576])\n",
      "219.7766265742092\n",
      "length of actions is  281\n",
      "223.59591685076717\n",
      "length of actions is  705\n",
      "114.21399926422214\n",
      "length of actions is  1000\n",
      "145.4400291975481\n",
      "length of actions is  1000\n",
      "31.708931664448556\n",
      "length of actions is  215\n",
      "Your final reward is : 146.95\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2224])\n",
      "223.87562276386853\n",
      "length of actions is  216\n",
      "274.43405931395824\n",
      "length of actions is  194\n",
      "301.1873836528242\n",
      "length of actions is  274\n",
      "204.43274317023509\n",
      "length of actions is  225\n",
      "261.04217003203996\n",
      "length of actions is  177\n",
      "Your final reward is : 252.99\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3296])\n",
      "220.01371093898302\n",
      "length of actions is  253\n",
      "283.23527080218264\n",
      "length of actions is  196\n",
      "109.28141209248633\n",
      "length of actions is  959\n",
      "191.41407390031426\n",
      "length of actions is  346\n",
      "231.37992400753046\n",
      "length of actions is  176\n",
      "Your final reward is : 207.06\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1898])\n",
      "221.74412794258882\n",
      "length of actions is  268\n",
      "99.81495546484936\n",
      "length of actions is  1000\n",
      "293.00185096312396\n",
      "length of actions is  260\n",
      "301.31878564176714\n",
      "length of actions is  253\n",
      "267.45880399766475\n",
      "length of actions is  185\n",
      "Your final reward is : 236.67\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1708])\n",
      "214.0542125728648\n",
      "length of actions is  317\n",
      "121.60955502238909\n",
      "length of actions is  1000\n",
      "108.86480570660527\n",
      "length of actions is  1000\n",
      "211.348281158795\n",
      "length of actions is  240\n",
      "201.6598055268451\n",
      "length of actions is  286\n",
      "Your final reward is : 171.51\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2600])\n",
      "118.06370825372917\n",
      "length of actions is  1000\n",
      "303.01828999901295\n",
      "length of actions is  225\n",
      "118.46479281232807\n",
      "length of actions is  1000\n",
      "196.8327255597071\n",
      "length of actions is  268\n",
      "291.85288421343444\n",
      "length of actions is  195\n",
      "Your final reward is : 205.65\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1372])\n",
      "84.81830006397261\n",
      "length of actions is  1000\n",
      "302.6036547227946\n",
      "length of actions is  217\n",
      "134.23106297658822\n",
      "length of actions is  1000\n",
      "137.0790832027327\n",
      "length of actions is  1000\n",
      "255.33664969525134\n",
      "length of actions is  295\n",
      "Your final reward is : 182.81\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2041])\n",
      "209.4041332460266\n",
      "length of actions is  297\n",
      "238.3854923814243\n",
      "length of actions is  396\n",
      "241.1339517166427\n",
      "length of actions is  259\n",
      "239.203239074247\n",
      "length of actions is  208\n",
      "231.05674340205897\n",
      "length of actions is  441\n",
      "Your final reward is : 231.84\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1539])\n",
      "101.32003005158911\n",
      "length of actions is  1000\n",
      "302.21276010631277\n",
      "length of actions is  222\n",
      "116.0506148288618\n",
      "length of actions is  1000\n",
      "92.67882588057255\n",
      "length of actions is  1000\n",
      "205.85938179995728\n",
      "length of actions is  397\n",
      "Your final reward is : 163.62\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2047])\n",
      "218.0004726111169\n",
      "length of actions is  273\n",
      "235.5332987153646\n",
      "length of actions is  168\n",
      "232.50281967194366\n",
      "length of actions is  185\n",
      "308.58670183204026\n",
      "length of actions is  233\n",
      "245.8804315191841\n",
      "length of actions is  278\n",
      "Your final reward is : 248.10\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2600])\n",
      "204.21181181611385\n",
      "length of actions is  311\n",
      "281.53147103431513\n",
      "length of actions is  176\n",
      "232.36763164414992\n",
      "length of actions is  195\n",
      "144.00820763423258\n",
      "length of actions is  1000\n",
      "253.5341585827797\n",
      "length of actions is  183\n",
      "Your final reward is : 223.13\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1349])\n",
      "216.2912206586658\n",
      "length of actions is  293\n",
      "134.87554471479942\n",
      "length of actions is  1000\n",
      "191.8103070020752\n",
      "length of actions is  267\n",
      "144.78704445796416\n",
      "length of actions is  1000\n",
      "224.9631529766475\n",
      "length of actions is  191\n",
      "Your final reward is : 182.55\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1377])\n",
      "214.7171951890847\n",
      "length of actions is  285\n",
      "290.4787380111225\n",
      "length of actions is  241\n",
      "288.20437123525755\n",
      "length of actions is  254\n",
      "272.70216705408006\n",
      "length of actions is  245\n",
      "215.10413451573237\n",
      "length of actions is  232\n",
      "Your final reward is : 256.24\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1987])\n",
      "-13.082014900243522\n",
      "length of actions is  266\n",
      "274.9183100395341\n",
      "length of actions is  223\n",
      "223.96120033772524\n",
      "length of actions is  356\n",
      "232.82783736169705\n",
      "length of actions is  331\n",
      "5.068676578227382\n",
      "length of actions is  251\n",
      "Your final reward is : 144.74\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1551])\n",
      "197.15785113403896\n",
      "length of actions is  294\n",
      "279.89947595208065\n",
      "length of actions is  238\n",
      "248.5698306562903\n",
      "length of actions is  292\n",
      "192.0740694972157\n",
      "length of actions is  578\n",
      "148.6561686195024\n",
      "length of actions is  1000\n",
      "Your final reward is : 213.27\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1314])\n",
      "213.26258273527765\n",
      "length of actions is  440\n",
      "7.105627925038036\n",
      "length of actions is  264\n",
      "266.1607265843261\n",
      "length of actions is  182\n",
      "226.806575828964\n",
      "length of actions is  297\n",
      "263.4396716608203\n",
      "length of actions is  169\n",
      "Your final reward is : 195.36\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1214])\n",
      "225.96719374011155\n",
      "length of actions is  260\n",
      "214.4526910261327\n",
      "length of actions is  201\n",
      "270.99566003851476\n",
      "length of actions is  212\n",
      "222.71047113978415\n",
      "length of actions is  262\n",
      "292.47691930942403\n",
      "length of actions is  194\n",
      "Your final reward is : 245.32\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2083])\n",
      "215.2567294447632\n",
      "length of actions is  843\n",
      "288.05880685600874\n",
      "length of actions is  237\n",
      "290.1157150865581\n",
      "length of actions is  192\n",
      "262.93826903922405\n",
      "length of actions is  200\n",
      "279.2161877065055\n",
      "length of actions is  221\n",
      "Your final reward is : 267.12\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2025])\n",
      "200.7300642595725\n",
      "length of actions is  843\n",
      "286.5312927590618\n",
      "length of actions is  229\n",
      "256.86221003070784\n",
      "length of actions is  232\n",
      "297.58901305581566\n",
      "length of actions is  250\n",
      "316.0717103713396\n",
      "length of actions is  218\n",
      "Your final reward is : 271.56\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2017])\n",
      "213.19879598706433\n",
      "length of actions is  279\n",
      "206.12674640784712\n",
      "length of actions is  271\n",
      "291.2396724509505\n",
      "length of actions is  237\n",
      "225.4013546689199\n",
      "length of actions is  362\n",
      "237.1113322677942\n",
      "length of actions is  313\n",
      "Your final reward is : 234.62\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4081])\n",
      "228.13435730499805\n",
      "length of actions is  286\n",
      "221.4929493275961\n",
      "length of actions is  257\n",
      "240.39263429648008\n",
      "length of actions is  330\n",
      "297.2966518028709\n",
      "length of actions is  224\n",
      "138.06710769877265\n",
      "length of actions is  1000\n",
      "Your final reward is : 225.08\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1987])\n",
      "219.799669085007\n",
      "length of actions is  279\n",
      "204.61711333836047\n",
      "length of actions is  266\n",
      "224.61899307752748\n",
      "length of actions is  268\n",
      "256.6559500174568\n",
      "length of actions is  179\n",
      "213.66155330215508\n",
      "length of actions is  292\n",
      "Your final reward is : 223.87\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3981])\n",
      "228.14142478300602\n",
      "length of actions is  239\n",
      "237.583703041962\n",
      "length of actions is  227\n",
      "168.91293461744988\n",
      "length of actions is  1000\n",
      "234.3305889613333\n",
      "length of actions is  260\n",
      "276.09608872715097\n",
      "length of actions is  541\n",
      "Your final reward is : 229.01\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1734])\n",
      "224.8860571128268\n",
      "length of actions is  252\n",
      "277.2262755094651\n",
      "length of actions is  154\n",
      "222.86363351300446\n",
      "length of actions is  302\n",
      "241.59221514767918\n",
      "length of actions is  483\n",
      "236.30231612398103\n",
      "length of actions is  948\n",
      "Your final reward is : 240.57\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1315])\n",
      "230.6103704525025\n",
      "length of actions is  575\n",
      "206.33723590448545\n",
      "length of actions is  298\n",
      "232.66960031075885\n",
      "length of actions is  193\n",
      "271.31638186212126\n",
      "length of actions is  170\n",
      "286.0658251874755\n",
      "length of actions is  194\n",
      "Your final reward is : 245.40\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1303])\n",
      "224.3913428081134\n",
      "length of actions is  790\n",
      "202.62501886673573\n",
      "length of actions is  430\n",
      "283.3887335338594\n",
      "length of actions is  200\n",
      "142.6212980425172\n",
      "length of actions is  1000\n",
      "220.37150728676232\n",
      "length of actions is  188\n",
      "Your final reward is : 214.68\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1346])\n",
      "214.9164820408812\n",
      "length of actions is  790\n",
      "193.71736213488657\n",
      "length of actions is  462\n",
      "285.0111764642004\n",
      "length of actions is  224\n",
      "62.657631160797706\n",
      "length of actions is  117\n",
      "26.231152822636915\n",
      "length of actions is  214\n",
      "Your final reward is : 156.51\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1250])\n",
      "241.4518664490043\n",
      "length of actions is  250\n",
      "253.23922307327285\n",
      "length of actions is  180\n",
      "286.890525009478\n",
      "length of actions is  223\n",
      "164.58621574668823\n",
      "length of actions is  1000\n",
      "281.82273078287477\n",
      "length of actions is  163\n",
      "Your final reward is : 245.60\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1348])\n",
      "230.75743111736458\n",
      "length of actions is  291\n",
      "72.9431752520725\n",
      "length of actions is  132\n",
      "156.63962811395453\n",
      "length of actions is  1000\n",
      "41.644192899557225\n",
      "length of actions is  145\n",
      "39.20871741932564\n",
      "length of actions is  132\n",
      "Your final reward is : 108.24\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1180])\n",
      "233.78727607857752\n",
      "length of actions is  255\n",
      "257.46371785354296\n",
      "length of actions is  194\n",
      "12.48877384971891\n",
      "length of actions is  296\n",
      "279.47772993055787\n",
      "length of actions is  198\n",
      "282.3209723704787\n",
      "length of actions is  219\n",
      "Your final reward is : 213.11\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1723])\n",
      "110.1209779198864\n",
      "length of actions is  1000\n",
      "169.26788737513678\n",
      "length of actions is  1000\n",
      "291.20786618472823\n",
      "length of actions is  192\n",
      "27.559540167248514\n",
      "length of actions is  129\n",
      "38.788135145389674\n",
      "length of actions is  116\n",
      "Your final reward is : 127.39\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1063])\n",
      "233.55212890400497\n",
      "length of actions is  263\n",
      "284.6651626186399\n",
      "length of actions is  233\n",
      "13.884831504893768\n",
      "length of actions is  174\n",
      "5.227954517488598\n",
      "length of actions is  241\n",
      "58.071832121254175\n",
      "length of actions is  137\n",
      "Your final reward is : 119.08\n",
      "torch.from_numpy(rewards) looks like  torch.Size([758])\n",
      "229.67714223294985\n",
      "length of actions is  262\n",
      "285.5759611408778\n",
      "length of actions is  272\n",
      "55.17334408249832\n",
      "length of actions is  148\n",
      "179.94033554203153\n",
      "length of actions is  1000\n",
      "42.25923292055322\n",
      "length of actions is  116\n",
      "Your final reward is : 158.53\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2179])\n",
      "221.32511171702944\n",
      "length of actions is  480\n",
      "242.2743806916864\n",
      "length of actions is  162\n",
      "28.207309794708237\n",
      "length of actions is  130\n",
      "297.21201734539545\n",
      "length of actions is  206\n",
      "-2.2921821749699944\n",
      "length of actions is  203\n",
      "Your final reward is : 157.35\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1058])\n",
      "226.72102139724734\n",
      "length of actions is  790\n",
      "218.86848665423008\n",
      "length of actions is  365\n",
      "-12.357069092110379\n",
      "length of actions is  186\n",
      "16.153961053322462\n",
      "length of actions is  111\n",
      "257.2744858360229\n",
      "length of actions is  209\n",
      "Your final reward is : 141.33\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1047])\n",
      "232.1624249440084\n",
      "length of actions is  239\n",
      "256.4952656885371\n",
      "length of actions is  197\n",
      "250.8028401909966\n",
      "length of actions is  391\n",
      "43.66166985757471\n",
      "length of actions is  138\n",
      "252.16976441880777\n",
      "length of actions is  285\n",
      "Your final reward is : 207.06\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2333])\n",
      "217.97539938393288\n",
      "length of actions is  843\n",
      "51.00020705484695\n",
      "length of actions is  149\n",
      "74.16813245199288\n",
      "length of actions is  160\n",
      "240.7417518791818\n",
      "length of actions is  197\n",
      "-11.493691129365189\n",
      "length of actions is  196\n",
      "Your final reward is : 114.48\n",
      "torch.from_numpy(rewards) looks like  torch.Size([816])\n",
      "224.7284362275352\n",
      "length of actions is  790\n",
      "214.27171811852602\n",
      "length of actions is  371\n",
      "225.73488470268103\n",
      "length of actions is  556\n",
      "51.11044761935855\n",
      "length of actions is  130\n",
      "55.138138053137595\n",
      "length of actions is  115\n",
      "Your final reward is : 154.20\n",
      "torch.from_numpy(rewards) looks like  torch.Size([677])\n",
      "231.40486864502546\n",
      "length of actions is  215\n",
      "26.592825554506902\n",
      "length of actions is  121\n",
      "295.20093850255597\n",
      "length of actions is  243\n",
      "243.4194086971903\n",
      "length of actions is  208\n",
      "277.17545526097297\n",
      "length of actions is  219\n",
      "Your final reward is : 214.76\n",
      "torch.from_numpy(rewards) looks like  torch.Size([785])\n",
      "232.66439237521936\n",
      "length of actions is  207\n",
      "253.57597141478053\n",
      "length of actions is  239\n",
      "19.87910904531985\n",
      "length of actions is  150\n",
      "193.76543899422407\n",
      "length of actions is  272\n",
      "252.00754351039856\n",
      "length of actions is  638\n",
      "Your final reward is : 190.38\n",
      "torch.from_numpy(rewards) looks like  torch.Size([639])\n",
      "233.5121296983192\n",
      "length of actions is  214\n",
      "61.47374807976382\n",
      "length of actions is  136\n",
      "34.41659515360209\n",
      "length of actions is  192\n",
      "282.07402161215725\n",
      "length of actions is  254\n",
      "122.68943618062661\n",
      "length of actions is  1000\n",
      "Your final reward is : 146.83\n",
      "torch.from_numpy(rewards) looks like  torch.Size([862])\n",
      "232.67220723451712\n",
      "length of actions is  211\n",
      "139.20352945772584\n",
      "length of actions is  1000\n",
      "12.531551030468208\n",
      "length of actions is  123\n",
      "36.4436535976418\n",
      "length of actions is  116\n",
      "34.013596109443654\n",
      "length of actions is  102\n",
      "Your final reward is : 90.97\n",
      "torch.from_numpy(rewards) looks like  torch.Size([666])\n",
      "235.474543548837\n",
      "length of actions is  205\n",
      "141.30680594507925\n",
      "length of actions is  1000\n",
      "40.3197617212752\n",
      "length of actions is  184\n",
      "21.529398787139527\n",
      "length of actions is  109\n",
      "34.59928587164538\n",
      "length of actions is  178\n",
      "Your final reward is : 94.65\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1489])\n",
      "233.38028918637377\n",
      "length of actions is  790\n",
      "225.6081562887178\n",
      "length of actions is  343\n",
      "34.78647253317027\n",
      "length of actions is  100\n",
      "38.206906675074265\n",
      "length of actions is  92\n",
      "12.998073312255528\n",
      "length of actions is  143\n",
      "Your final reward is : 109.00\n",
      "torch.from_numpy(rewards) looks like  torch.Size([553])\n",
      "242.01008592759354\n",
      "length of actions is  246\n",
      "33.22983270850216\n",
      "length of actions is  114\n",
      "46.07053035441271\n",
      "length of actions is  143\n",
      "21.321395421391756\n",
      "length of actions is  152\n",
      "38.39401175506103\n",
      "length of actions is  129\n",
      "Your final reward is : 76.21\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1408])\n",
      "239.59058229629724\n",
      "length of actions is  240\n",
      "20.627638718280494\n",
      "length of actions is  104\n",
      "35.495154182429275\n",
      "length of actions is  101\n",
      "31.031420897318156\n",
      "length of actions is  104\n",
      "61.72006994313861\n",
      "length of actions is  175\n",
      "Your final reward is : 77.69\n",
      "torch.from_numpy(rewards) looks like  torch.Size([622])\n",
      "12.501767778123764\n",
      "length of actions is  142\n",
      "21.724832133894495\n",
      "length of actions is  115\n",
      "27.80671070645812\n",
      "length of actions is  180\n",
      "27.3545773357134\n",
      "length of actions is  166\n",
      "30.95682129741533\n",
      "length of actions is  119\n",
      "Your final reward is : 24.07\n",
      "torch.from_numpy(rewards) looks like  torch.Size([673])\n",
      "19.416230459046645\n",
      "length of actions is  143\n",
      "22.684834998782136\n",
      "length of actions is  152\n",
      "41.33609066994268\n",
      "length of actions is  141\n",
      "59.11894882375478\n",
      "length of actions is  166\n",
      "26.612333664500227\n",
      "length of actions is  131\n",
      "Your final reward is : 33.83\n",
      "torch.from_numpy(rewards) looks like  torch.Size([638])\n",
      "231.16637285122042\n",
      "length of actions is  790\n",
      "9.585041233293836\n",
      "length of actions is  191\n",
      "36.550573359765906\n",
      "length of actions is  183\n",
      "54.8583500313147\n",
      "length of actions is  176\n",
      "61.21623107225449\n",
      "length of actions is  136\n",
      "Your final reward is : 78.68\n",
      "torch.from_numpy(rewards) looks like  torch.Size([748])\n",
      "234.01162662277602\n",
      "length of actions is  790\n",
      "3.269827683706083\n",
      "length of actions is  182\n",
      "59.525568987989885\n",
      "length of actions is  190\n",
      "22.56616910072431\n",
      "length of actions is  122\n",
      "8.9548523315554\n",
      "length of actions is  142\n",
      "Your final reward is : 65.67\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1794])\n",
      "10.052535178284586\n",
      "length of actions is  144\n",
      "56.79152091674828\n",
      "length of actions is  138\n",
      "42.03233158685143\n",
      "length of actions is  157\n",
      "15.83057400648498\n",
      "length of actions is  104\n",
      "-5.824350498466686\n",
      "length of actions is  169\n",
      "Your final reward is : 23.78\n",
      "torch.from_numpy(rewards) looks like  torch.Size([603])\n",
      "22.72765953676935\n",
      "length of actions is  141\n",
      "18.898005918696654\n",
      "length of actions is  143\n",
      "52.87165147197226\n",
      "length of actions is  91\n",
      "5.370149612795899\n",
      "length of actions is  109\n",
      "8.646282346091226\n",
      "length of actions is  102\n",
      "Your final reward is : 21.70\n",
      "torch.from_numpy(rewards) looks like  torch.Size([692])\n",
      "14.884066912433525\n",
      "length of actions is  147\n",
      "21.048177078913596\n",
      "length of actions is  139\n",
      "47.14410529543761\n",
      "length of actions is  131\n",
      "2.300788526367114\n",
      "length of actions is  167\n",
      "20.726888925687348\n",
      "length of actions is  135\n",
      "Your final reward is : 21.22\n",
      "torch.from_numpy(rewards) looks like  torch.Size([690])\n",
      "18.62203195540505\n",
      "length of actions is  134\n",
      "-6.744748312110701\n",
      "length of actions is  130\n",
      "8.549615744255576\n",
      "length of actions is  121\n",
      "38.063969881567715\n",
      "length of actions is  123\n",
      "20.549491580612653\n",
      "length of actions is  117\n",
      "Your final reward is : 15.81\n",
      "torch.from_numpy(rewards) looks like  torch.Size([687])\n",
      "25.19912007431293\n",
      "length of actions is  136\n",
      "16.25375771823562\n",
      "length of actions is  141\n",
      "32.61794620309678\n",
      "length of actions is  132\n",
      "18.285495892180506\n",
      "length of actions is  112\n",
      "29.265438666379225\n",
      "length of actions is  127\n",
      "Your final reward is : 24.32\n",
      "torch.from_numpy(rewards) looks like  torch.Size([649])\n",
      "10.438873185255616\n",
      "length of actions is  131\n",
      "-5.060284946887805\n",
      "length of actions is  133\n",
      "19.58554575897911\n",
      "length of actions is  127\n",
      "59.919368754879514\n",
      "length of actions is  124\n",
      "26.04233329501463\n",
      "length of actions is  145\n",
      "Your final reward is : 22.19\n",
      "torch.from_numpy(rewards) looks like  torch.Size([655])\n",
      "38.32428268033226\n",
      "length of actions is  140\n",
      "14.574449801531244\n",
      "length of actions is  101\n",
      "23.76277889149344\n",
      "length of actions is  103\n",
      "11.65076287455014\n",
      "length of actions is  99\n",
      "23.798338875220622\n",
      "length of actions is  132\n",
      "Your final reward is : 22.42\n",
      "torch.from_numpy(rewards) looks like  torch.Size([552])\n",
      "25.87203695618834\n",
      "length of actions is  134\n",
      "-2.5005266923839997\n",
      "length of actions is  128\n",
      "14.441637358587656\n",
      "length of actions is  143\n",
      "-3.756271866945994\n",
      "length of actions is  103\n",
      "24.947047058251528\n",
      "length of actions is  116\n",
      "Your final reward is : 11.80\n",
      "torch.from_numpy(rewards) looks like  torch.Size([532])\n",
      "33.40217754758433\n",
      "length of actions is  137\n",
      "25.19958681630662\n",
      "length of actions is  89\n",
      "8.837297832825584\n",
      "length of actions is  115\n",
      "24.169223637331825\n",
      "length of actions is  134\n",
      "19.85968457015875\n",
      "length of actions is  109\n",
      "Your final reward is : 22.29\n",
      "torch.from_numpy(rewards) looks like  torch.Size([570])\n",
      "25.7603471351362\n",
      "length of actions is  131\n",
      "-2.230264606964724\n",
      "length of actions is  133\n",
      "13.461815727214798\n",
      "length of actions is  128\n",
      "21.935067311850787\n",
      "length of actions is  122\n",
      "27.51823962190639\n",
      "length of actions is  103\n",
      "Your final reward is : 17.29\n",
      "torch.from_numpy(rewards) looks like  torch.Size([575])\n",
      "28.970221192842615\n",
      "length of actions is  132\n",
      "13.477229035336862\n",
      "length of actions is  163\n",
      "32.854143694336244\n",
      "length of actions is  132\n",
      "3.0093237567544833\n",
      "length of actions is  110\n",
      "7.3184022661957755\n",
      "length of actions is  113\n",
      "Your final reward is : 17.13\n",
      "torch.from_numpy(rewards) looks like  torch.Size([515])\n",
      "8.74373541696312\n",
      "length of actions is  133\n",
      "31.40122970391627\n",
      "length of actions is  86\n",
      "14.599616383715542\n",
      "length of actions is  101\n",
      "23.260576090632625\n",
      "length of actions is  103\n",
      "16.026728426589088\n",
      "length of actions is  105\n",
      "Your final reward is : 18.81\n",
      "torch.from_numpy(rewards) looks like  torch.Size([669])\n",
      "9.73325532262129\n",
      "length of actions is  131\n",
      "9.54049301507483\n",
      "length of actions is  132\n",
      "8.911426121888596\n",
      "length of actions is  149\n",
      "9.925105476234037\n",
      "length of actions is  132\n",
      "29.801856098924503\n",
      "length of actions is  120\n",
      "Your final reward is : 13.58\n",
      "torch.from_numpy(rewards) looks like  torch.Size([516])\n",
      "17.936388214201997\n",
      "length of actions is  131\n",
      "11.119821633857484\n",
      "length of actions is  128\n",
      "8.207186678961023\n",
      "length of actions is  91\n",
      "-8.128741803776919\n",
      "length of actions is  121\n",
      "3.199375653822372\n",
      "length of actions is  89\n",
      "Your final reward is : 6.47\n",
      "torch.from_numpy(rewards) looks like  torch.Size([573])\n",
      "25.538431419441537\n",
      "length of actions is  135\n",
      "42.049871636640745\n",
      "length of actions is  77\n",
      "21.01081673404599\n",
      "length of actions is  133\n",
      "3.3388310917286788\n",
      "length of actions is  106\n",
      "6.442272766327349\n",
      "length of actions is  99\n",
      "Your final reward is : 19.68\n",
      "torch.from_numpy(rewards) looks like  torch.Size([641])\n",
      "-1.33580895118493\n",
      "length of actions is  126\n",
      "-14.076465111255288\n",
      "length of actions is  146\n",
      "43.549895347584055\n",
      "length of actions is  112\n",
      "41.1563520664416\n",
      "length of actions is  114\n",
      "-14.621597730356143\n",
      "length of actions is  113\n",
      "Your final reward is : 10.93\n",
      "torch.from_numpy(rewards) looks like  torch.Size([659])\n",
      "0.39014525278219025\n",
      "length of actions is  115\n",
      "-42.285718262265306\n",
      "length of actions is  154\n",
      "-60.3077214818185\n",
      "length of actions is  91\n",
      "2.50705558799973\n",
      "length of actions is  97\n",
      "0.5623131475360452\n",
      "length of actions is  130\n",
      "Your final reward is : -19.83\n",
      "torch.from_numpy(rewards) looks like  torch.Size([572])\n",
      "31.92852168243772\n",
      "length of actions is  124\n",
      "-9.355639682434614\n",
      "length of actions is  105\n",
      "9.561997690966834\n",
      "length of actions is  93\n",
      "37.477422498005836\n",
      "length of actions is  161\n",
      "23.484912789661493\n",
      "length of actions is  85\n",
      "Your final reward is : 18.62\n",
      "torch.from_numpy(rewards) looks like  torch.Size([494])\n",
      "23.766950649151582\n",
      "length of actions is  124\n",
      "2.2834134788115676\n",
      "length of actions is  106\n",
      "-9.561924975612158\n",
      "length of actions is  104\n",
      "9.29228956221256\n",
      "length of actions is  79\n",
      "-3.6036843557853473\n",
      "length of actions is  136\n",
      "Your final reward is : 4.44\n",
      "torch.from_numpy(rewards) looks like  torch.Size([593])\n",
      "23.64409747066061\n",
      "length of actions is  119\n",
      "39.07095285963598\n",
      "length of actions is  91\n",
      "19.831885440132424\n",
      "length of actions is  117\n",
      "28.39167035971488\n",
      "length of actions is  106\n",
      "17.20599688520761\n",
      "length of actions is  152\n",
      "Your final reward is : 25.63\n",
      "torch.from_numpy(rewards) looks like  torch.Size([672])\n",
      "24.20558390355781\n",
      "length of actions is  124\n",
      "-2.3911286328928014\n",
      "length of actions is  105\n",
      "8.222897584607125\n",
      "length of actions is  94\n",
      "37.48224358598736\n",
      "length of actions is  112\n",
      "-11.366412987415401\n",
      "length of actions is  138\n",
      "Your final reward is : 11.23\n",
      "torch.from_numpy(rewards) looks like  torch.Size([473])\n",
      "24.590804543460436\n",
      "length of actions is  117\n",
      "-12.943645616460245\n",
      "length of actions is  99\n",
      "1.3563229953244615\n",
      "length of actions is  139\n",
      "-15.393637989266551\n",
      "length of actions is  104\n",
      "13.691668349357755\n",
      "length of actions is  114\n",
      "Your final reward is : 2.26\n",
      "torch.from_numpy(rewards) looks like  torch.Size([484])\n",
      "16.95758944213034\n",
      "length of actions is  115\n",
      "-32.397483306558556\n",
      "length of actions is  145\n",
      "7.091035173937712\n",
      "length of actions is  108\n",
      "2.5341081200065645\n",
      "length of actions is  119\n",
      "21.58004798572496\n",
      "length of actions is  123\n",
      "Your final reward is : 3.15\n",
      "torch.from_numpy(rewards) looks like  torch.Size([510])\n",
      "34.66560247263908\n",
      "length of actions is  125\n",
      "9.391435119117617\n",
      "length of actions is  98\n",
      "27.444604602740142\n",
      "length of actions is  124\n",
      "8.12849026825701\n",
      "length of actions is  124\n",
      "0.19856418996759828\n",
      "length of actions is  85\n",
      "Your final reward is : 15.97\n",
      "torch.from_numpy(rewards) looks like  torch.Size([519])\n",
      "14.111925258663675\n",
      "length of actions is  120\n",
      "0.3639797898406414\n",
      "length of actions is  97\n",
      "3.2713180159323656\n",
      "length of actions is  102\n",
      "-16.521438804660548\n",
      "length of actions is  95\n",
      "-14.948030509858043\n",
      "length of actions is  122\n",
      "Your final reward is : -2.74\n",
      "torch.from_numpy(rewards) looks like  torch.Size([558])\n",
      "15.557594038080637\n",
      "length of actions is  124\n",
      "-0.9302511244009679\n",
      "length of actions is  106\n",
      "1.8376618268490148\n",
      "length of actions is  105\n",
      "42.33685085905765\n",
      "length of actions is  98\n",
      "8.46996081315443\n",
      "length of actions is  163\n",
      "Your final reward is : 13.45\n",
      "torch.from_numpy(rewards) looks like  torch.Size([587])\n",
      "24.28118552242509\n",
      "length of actions is  129\n",
      "7.5723619176495305\n",
      "length of actions is  121\n",
      "9.421706690705761\n",
      "length of actions is  96\n",
      "2.6581960080698366\n",
      "length of actions is  154\n",
      "6.658485264650707\n",
      "length of actions is  108\n",
      "Your final reward is : 10.12\n",
      "torch.from_numpy(rewards) looks like  torch.Size([482])\n",
      "22.51102292062508\n",
      "length of actions is  124\n",
      "-2.2786851263983863\n",
      "length of actions is  107\n",
      "16.81343316372822\n",
      "length of actions is  125\n",
      "26.072270600325098\n",
      "length of actions is  120\n",
      "-3.375209974105559\n",
      "length of actions is  98\n",
      "Your final reward is : 11.95\n",
      "torch.from_numpy(rewards) looks like  torch.Size([694])\n",
      "28.093652594249477\n",
      "length of actions is  121\n",
      "52.595642197242114\n",
      "length of actions is  120\n",
      "25.131155307201468\n",
      "length of actions is  97\n",
      "-14.16074597522335\n",
      "length of actions is  127\n",
      "50.77412420566861\n",
      "length of actions is  83\n",
      "Your final reward is : 28.49\n",
      "torch.from_numpy(rewards) looks like  torch.Size([529])\n",
      "27.331534153633797\n",
      "length of actions is  125\n",
      "-10.459416006827595\n",
      "length of actions is  101\n",
      "10.737874683088464\n",
      "length of actions is  115\n",
      "8.09880745541723\n",
      "length of actions is  120\n",
      "30.25822233938476\n",
      "length of actions is  107\n",
      "Your final reward is : 13.19\n",
      "torch.from_numpy(rewards) looks like  torch.Size([548])\n",
      "15.385681635153048\n",
      "length of actions is  121\n",
      "36.45750674916394\n",
      "length of actions is  116\n",
      "38.612420886693855\n",
      "length of actions is  93\n",
      "15.785090162460591\n",
      "length of actions is  116\n",
      "16.321207825172067\n",
      "length of actions is  116\n",
      "Your final reward is : 24.51\n",
      "torch.from_numpy(rewards) looks like  torch.Size([561])\n",
      "16.830757691338604\n",
      "length of actions is  121\n",
      "51.63342513079073\n",
      "length of actions is  120\n",
      "16.56532771421189\n",
      "length of actions is  98\n",
      "38.95090583609792\n",
      "length of actions is  109\n",
      "35.65699820366041\n",
      "length of actions is  103\n",
      "Your final reward is : 31.93\n",
      "torch.from_numpy(rewards) looks like  torch.Size([566])\n",
      "23.446593917386068\n",
      "length of actions is  123\n",
      "-20.192318654319834\n",
      "length of actions is  98\n",
      "35.1067448808146\n",
      "length of actions is  84\n",
      "5.1651728094288245\n",
      "length of actions is  110\n",
      "18.42455436158113\n",
      "length of actions is  117\n",
      "Your final reward is : 12.39\n",
      "torch.from_numpy(rewards) looks like  torch.Size([603])\n",
      "17.43958295275563\n",
      "length of actions is  122\n",
      "47.6232648983858\n",
      "length of actions is  115\n",
      "51.303795128829904\n",
      "length of actions is  97\n",
      "11.097610822996856\n",
      "length of actions is  84\n",
      "51.49415412869206\n",
      "length of actions is  112\n",
      "Your final reward is : 35.79\n",
      "torch.from_numpy(rewards) looks like  torch.Size([633])\n",
      "21.762375912424048\n",
      "length of actions is  122\n",
      "50.676924956516245\n",
      "length of actions is  116\n",
      "23.93252261575374\n",
      "length of actions is  101\n",
      "64.41056494628828\n",
      "length of actions is  111\n",
      "36.2671522891778\n",
      "length of actions is  123\n",
      "Your final reward is : 39.41\n",
      "torch.from_numpy(rewards) looks like  torch.Size([496])\n",
      "15.062442401605395\n",
      "length of actions is  120\n",
      "9.062358334578676\n",
      "length of actions is  103\n",
      "50.77750860135748\n",
      "length of actions is  122\n",
      "4.348434993211839\n",
      "length of actions is  105\n",
      "27.929448159149956\n",
      "length of actions is  119\n",
      "Your final reward is : 21.44\n",
      "torch.from_numpy(rewards) looks like  torch.Size([602])\n",
      "6.395993911776429\n",
      "length of actions is  124\n",
      "25.37601262576341\n",
      "length of actions is  113\n",
      "63.42645561216645\n",
      "length of actions is  94\n",
      "35.11230897034312\n",
      "length of actions is  100\n",
      "29.370361126182615\n",
      "length of actions is  100\n",
      "Your final reward is : 31.94\n",
      "torch.from_numpy(rewards) looks like  torch.Size([696])\n",
      "10.735481530304455\n",
      "length of actions is  126\n",
      "-11.59585404243569\n",
      "length of actions is  139\n",
      "56.202198363408314\n",
      "length of actions is  98\n",
      "-4.950161034533352\n",
      "length of actions is  138\n",
      "18.46522160174034\n",
      "length of actions is  104\n",
      "Your final reward is : 13.77\n",
      "torch.from_numpy(rewards) looks like  torch.Size([560])\n",
      "5.624524844206391\n",
      "length of actions is  135\n",
      "32.99404146568929\n",
      "length of actions is  90\n",
      "195.22589001938488\n",
      "length of actions is  514\n",
      "25.250134797064945\n",
      "length of actions is  116\n",
      "21.67186082413967\n",
      "length of actions is  140\n",
      "Your final reward is : 56.15\n",
      "torch.from_numpy(rewards) looks like  torch.Size([603])\n",
      "-2.9788295406260374\n",
      "length of actions is  128\n",
      "-14.858811125361015\n",
      "length of actions is  140\n",
      "20.576548851206937\n",
      "length of actions is  125\n",
      "244.47595325371907\n",
      "length of actions is  300\n",
      "38.59498677824939\n",
      "length of actions is  103\n",
      "Your final reward is : 57.16\n",
      "torch.from_numpy(rewards) looks like  torch.Size([591])\n",
      "-1.4749656134600855\n",
      "length of actions is  138\n",
      "52.331350088048\n",
      "length of actions is  135\n",
      "202.24302672449542\n",
      "length of actions is  481\n",
      "43.580854012085155\n",
      "length of actions is  112\n",
      "45.03841459455501\n",
      "length of actions is  108\n",
      "Your final reward is : 68.34\n",
      "torch.from_numpy(rewards) looks like  torch.Size([566])\n",
      "122.01292095179805\n",
      "length of actions is  1000\n",
      "63.30498129901022\n",
      "length of actions is  137\n",
      "291.99053679998644\n",
      "length of actions is  218\n",
      "16.746154998951013\n",
      "length of actions is  137\n",
      "0.8298970167352167\n",
      "length of actions is  159\n",
      "Your final reward is : 98.98\n",
      "torch.from_numpy(rewards) looks like  torch.Size([632])\n",
      "239.82538664600526\n",
      "length of actions is  845\n",
      "29.874429344120642\n",
      "length of actions is  120\n",
      "32.98570116419262\n",
      "length of actions is  141\n",
      "43.32854925501397\n",
      "length of actions is  135\n",
      "41.2353603698827\n",
      "length of actions is  103\n",
      "Your final reward is : 77.45\n",
      "torch.from_numpy(rewards) looks like  torch.Size([813])\n",
      "127.39233921282704\n",
      "length of actions is  1000\n",
      "77.37987479209332\n",
      "length of actions is  139\n",
      "37.60693476984321\n",
      "length of actions is  121\n",
      "52.62311176728667\n",
      "length of actions is  135\n",
      "43.97305796411047\n",
      "length of actions is  126\n",
      "Your final reward is : 67.80\n",
      "torch.from_numpy(rewards) looks like  torch.Size([699])\n",
      "130.0907530941323\n",
      "length of actions is  1000\n",
      "59.79827831191085\n",
      "length of actions is  145\n",
      "25.854061925946127\n",
      "length of actions is  118\n",
      "53.98403972107192\n",
      "length of actions is  165\n",
      "29.22153991699912\n",
      "length of actions is  99\n",
      "Your final reward is : 59.79\n",
      "torch.from_numpy(rewards) looks like  torch.Size([657])\n",
      "133.44592857915077\n",
      "length of actions is  1000\n",
      "53.4133944380026\n",
      "length of actions is  129\n",
      "226.07746087041693\n",
      "length of actions is  347\n",
      "52.48442143604075\n",
      "length of actions is  104\n",
      "9.797228694307762\n",
      "length of actions is  157\n",
      "Your final reward is : 95.04\n",
      "torch.from_numpy(rewards) looks like  torch.Size([644])\n",
      "206.92018251758682\n",
      "length of actions is  736\n",
      "11.499057385048218\n",
      "length of actions is  136\n",
      "-12.240947786298449\n",
      "length of actions is  148\n",
      "25.10279316529534\n",
      "length of actions is  140\n",
      "53.073441987335286\n",
      "length of actions is  167\n",
      "Your final reward is : 56.87\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1501])\n",
      "231.88558173253477\n",
      "length of actions is  765\n",
      "129.57551714908897\n",
      "length of actions is  1000\n",
      "251.40212341931334\n",
      "length of actions is  379\n",
      "67.7697613855899\n",
      "length of actions is  127\n",
      "114.97881599941769\n",
      "length of actions is  1000\n",
      "Your final reward is : 159.12\n",
      "torch.from_numpy(rewards) looks like  torch.Size([637])\n",
      "251.29428465053857\n",
      "length of actions is  591\n",
      "28.229755169565976\n",
      "length of actions is  115\n",
      "252.79840217735406\n",
      "length of actions is  498\n",
      "36.138375934933464\n",
      "length of actions is  114\n",
      "21.324749488939858\n",
      "length of actions is  144\n",
      "Your final reward is : 117.96\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1378])\n",
      "146.79587115560224\n",
      "length of actions is  1000\n",
      "76.83028809005339\n",
      "length of actions is  150\n",
      "1.2718363004090918\n",
      "length of actions is  130\n",
      "158.38124285405638\n",
      "length of actions is  1000\n",
      "41.2500450879017\n",
      "length of actions is  171\n",
      "Your final reward is : 84.91\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1306])\n",
      "255.14364736079528\n",
      "length of actions is  500\n",
      "248.3984489075201\n",
      "length of actions is  173\n",
      "300.4907837212335\n",
      "length of actions is  176\n",
      "233.9924720376086\n",
      "length of actions is  485\n",
      "277.1119240605861\n",
      "length of actions is  204\n",
      "Your final reward is : 263.03\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1515])\n",
      "137.7052864081676\n",
      "length of actions is  1000\n",
      "62.9785974888224\n",
      "length of actions is  133\n",
      "263.4787311130667\n",
      "length of actions is  184\n",
      "2.1644479744915657\n",
      "length of actions is  155\n",
      "275.12770585732346\n",
      "length of actions is  212\n",
      "Your final reward is : 148.29\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1340])\n",
      "148.8576758599767\n",
      "length of actions is  1000\n",
      "297.4894311819545\n",
      "length of actions is  230\n",
      "143.65333388125208\n",
      "length of actions is  1000\n",
      "162.26242654026302\n",
      "length of actions is  1000\n",
      "-11.031812569776818\n",
      "length of actions is  157\n",
      "Your final reward is : 148.25\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1819])\n",
      "130.75629967638983\n",
      "length of actions is  1000\n",
      "67.41431328987258\n",
      "length of actions is  136\n",
      "222.36234971016688\n",
      "length of actions is  223\n",
      "286.4073097316575\n",
      "length of actions is  231\n",
      "288.7748914959152\n",
      "length of actions is  200\n",
      "Your final reward is : 199.14\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2067])\n",
      "135.39428947768104\n",
      "length of actions is  1000\n",
      "282.58848792402296\n",
      "length of actions is  451\n",
      "79.78345062658292\n",
      "length of actions is  142\n",
      "286.71230937409706\n",
      "length of actions is  207\n",
      "254.71509650188102\n",
      "length of actions is  192\n",
      "Your final reward is : 207.84\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1670])\n",
      "134.7579968284539\n",
      "length of actions is  1000\n",
      "278.64029162980614\n",
      "length of actions is  736\n",
      "301.0087247536187\n",
      "length of actions is  249\n",
      "167.083381470212\n",
      "length of actions is  1000\n",
      "309.2676774333386\n",
      "length of actions is  225\n",
      "Your final reward is : 238.15\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2110])\n",
      "238.19241730948843\n",
      "length of actions is  223\n",
      "276.22994973316383\n",
      "length of actions is  531\n",
      "202.59758841284204\n",
      "length of actions is  418\n",
      "263.0230981391171\n",
      "length of actions is  588\n",
      "253.23190895032158\n",
      "length of actions is  329\n",
      "Your final reward is : 246.65\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1674])\n",
      "228.92002192105724\n",
      "length of actions is  235\n",
      "283.45432704227994\n",
      "length of actions is  264\n",
      "281.0678221094763\n",
      "length of actions is  203\n",
      "262.95259294333266\n",
      "length of actions is  243\n",
      "228.63241824696897\n",
      "length of actions is  239\n",
      "Your final reward is : 257.01\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1316])\n",
      "240.78535078620666\n",
      "length of actions is  210\n",
      "285.68163301112077\n",
      "length of actions is  215\n",
      "289.5038010859139\n",
      "length of actions is  224\n",
      "268.61174237542525\n",
      "length of actions is  202\n",
      "287.36581140480905\n",
      "length of actions is  291\n",
      "Your final reward is : 274.39\n",
      "Improve to score 274.39 at batch 500\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2058])\n",
      "224.62447776573293\n",
      "length of actions is  252\n",
      "251.5996080086658\n",
      "length of actions is  200\n",
      "238.60316025059336\n",
      "length of actions is  237\n",
      "206.89114794264967\n",
      "length of actions is  275\n",
      "144.79127701664365\n",
      "length of actions is  1000\n",
      "Your final reward is : 213.30\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1969])\n",
      "242.7751969901477\n",
      "length of actions is  254\n",
      "270.6674155727512\n",
      "length of actions is  226\n",
      "251.02483150238086\n",
      "length of actions is  250\n",
      "236.28805151615086\n",
      "length of actions is  841\n",
      "312.63678224560647\n",
      "length of actions is  227\n",
      "Your final reward is : 262.68\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1988])\n",
      "222.9187143052528\n",
      "length of actions is  298\n",
      "206.04580481360335\n",
      "length of actions is  302\n",
      "143.2790706447676\n",
      "length of actions is  1000\n",
      "281.1681589121581\n",
      "length of actions is  325\n",
      "111.705251468493\n",
      "length of actions is  1000\n",
      "Your final reward is : 193.02\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1817])\n",
      "214.51072760242448\n",
      "length of actions is  322\n",
      "144.94241395366927\n",
      "length of actions is  1000\n",
      "251.97400300243666\n",
      "length of actions is  261\n",
      "245.47488950976918\n",
      "length of actions is  797\n",
      "253.6679095023657\n",
      "length of actions is  225\n",
      "Your final reward is : 222.11\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1517])\n",
      "209.26402692669546\n",
      "length of actions is  322\n",
      "232.54017428986717\n",
      "length of actions is  295\n",
      "274.482330157325\n",
      "length of actions is  246\n",
      "277.6186971093011\n",
      "length of actions is  650\n",
      "148.82127450626137\n",
      "length of actions is  1000\n",
      "Your final reward is : 228.55\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2047])\n",
      "223.32335342157023\n",
      "length of actions is  277\n",
      "292.0498411003829\n",
      "length of actions is  206\n",
      "242.5122360276952\n",
      "length of actions is  286\n",
      "291.96008286118706\n",
      "length of actions is  265\n",
      "259.1138000329313\n",
      "length of actions is  255\n",
      "Your final reward is : 261.79\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3197])\n",
      "221.19442297876344\n",
      "length of actions is  790\n",
      "250.1261555450628\n",
      "length of actions is  349\n",
      "248.25715048922467\n",
      "length of actions is  241\n",
      "25.03450299830243\n",
      "length of actions is  199\n",
      "245.90179134928113\n",
      "length of actions is  234\n",
      "Your final reward is : 198.10\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2078])\n",
      "236.67755292559005\n",
      "length of actions is  235\n",
      "162.77713206168198\n",
      "length of actions is  1000\n",
      "170.35917956976738\n",
      "length of actions is  1000\n",
      "266.0272319296171\n",
      "length of actions is  214\n",
      "239.40996954136133\n",
      "length of actions is  291\n",
      "Your final reward is : 215.05\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1536])\n",
      "220.28004445040153\n",
      "length of actions is  790\n",
      "136.8799757686851\n",
      "length of actions is  1000\n",
      "296.3127884771758\n",
      "length of actions is  297\n",
      "253.74010674582132\n",
      "length of actions is  242\n",
      "192.03756737455416\n",
      "length of actions is  933\n",
      "Your final reward is : 219.85\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2046])\n",
      "243.01568173956912\n",
      "length of actions is  233\n",
      "146.02729898807223\n",
      "length of actions is  1000\n",
      "140.67763311778202\n",
      "length of actions is  1000\n",
      "224.85238451583535\n",
      "length of actions is  298\n",
      "291.5938509458931\n",
      "length of actions is  219\n",
      "Your final reward is : 209.23\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2226])\n",
      "224.0780689238809\n",
      "length of actions is  306\n",
      "134.59782304566784\n",
      "length of actions is  1000\n",
      "296.8541774422239\n",
      "length of actions is  211\n",
      "205.95562195468625\n",
      "length of actions is  338\n",
      "240.2336412139151\n",
      "length of actions is  268\n",
      "Your final reward is : 220.34\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1348])\n",
      "230.4489160010924\n",
      "length of actions is  790\n",
      "269.88617107571577\n",
      "length of actions is  279\n",
      "171.04603729404354\n",
      "length of actions is  1000\n",
      "282.2453075910366\n",
      "length of actions is  280\n",
      "159.6345286134394\n",
      "length of actions is  1000\n",
      "Your final reward is : 222.65\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2293])\n",
      "236.01593575997956\n",
      "length of actions is  265\n",
      "237.78351612987373\n",
      "length of actions is  388\n",
      "254.54271937540497\n",
      "length of actions is  197\n",
      "105.3892057800856\n",
      "length of actions is  1000\n",
      "249.98246391409018\n",
      "length of actions is  269\n",
      "Your final reward is : 216.74\n",
      "torch.from_numpy(rewards) looks like  torch.Size([3573])\n",
      "237.30632966691064\n",
      "length of actions is  279\n",
      "242.52098586681402\n",
      "length of actions is  269\n",
      "238.05509975230385\n",
      "length of actions is  543\n",
      "248.13739770131536\n",
      "length of actions is  498\n",
      "140.9121441323731\n",
      "length of actions is  1000\n",
      "Your final reward is : 221.39\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1577])\n",
      "237.6959321069395\n",
      "length of actions is  257\n",
      "253.82920238928023\n",
      "length of actions is  277\n",
      "276.7219082576743\n",
      "length of actions is  246\n",
      "279.9167575732771\n",
      "length of actions is  225\n",
      "124.87691389722329\n",
      "length of actions is  1000\n",
      "Your final reward is : 234.61\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2838])\n",
      "239.78832218290955\n",
      "length of actions is  249\n",
      "108.35556031576493\n",
      "length of actions is  1000\n",
      "249.11700557002243\n",
      "length of actions is  243\n",
      "140.30074599036897\n",
      "length of actions is  1000\n",
      "248.18457333664625\n",
      "length of actions is  303\n",
      "Your final reward is : 197.15\n",
      "torch.from_numpy(rewards) looks like  torch.Size([4084])\n",
      "240.00826341897505\n",
      "length of actions is  247\n",
      "262.5738970711367\n",
      "length of actions is  205\n",
      "238.3654844276669\n",
      "length of actions is  255\n",
      "298.73055633657043\n",
      "length of actions is  221\n",
      "294.51429781072557\n",
      "length of actions is  214\n",
      "Your final reward is : 266.84\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2319])\n",
      "235.87398515167553\n",
      "length of actions is  267\n",
      "262.7120552551922\n",
      "length of actions is  234\n",
      "260.2990913327368\n",
      "length of actions is  231\n",
      "264.15334300721725\n",
      "length of actions is  238\n",
      "258.5118983521229\n",
      "length of actions is  261\n",
      "Your final reward is : 256.31\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1620])\n",
      "238.88080906001423\n",
      "length of actions is  270\n",
      "236.48496689421302\n",
      "length of actions is  275\n",
      "160.41561695286782\n",
      "length of actions is  1000\n",
      "294.62649043548583\n",
      "length of actions is  256\n",
      "242.09256571419098\n",
      "length of actions is  825\n",
      "Your final reward is : 234.50\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1348])\n",
      "235.69445832097077\n",
      "length of actions is  267\n",
      "270.2077000763406\n",
      "length of actions is  226\n",
      "262.6150373411519\n",
      "length of actions is  233\n",
      "289.56285974458353\n",
      "length of actions is  251\n",
      "158.31899723123257\n",
      "length of actions is  1000\n",
      "Your final reward is : 243.28\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1539])\n",
      "233.73453506488514\n",
      "length of actions is  266\n",
      "266.4799377614829\n",
      "length of actions is  257\n",
      "238.57049842659143\n",
      "length of actions is  229\n",
      "288.7203587189657\n",
      "length of actions is  224\n",
      "298.4779230738359\n",
      "length of actions is  235\n",
      "Your final reward is : 265.20\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1526])\n",
      "239.33662953163025\n",
      "length of actions is  274\n",
      "281.4762155254915\n",
      "length of actions is  220\n",
      "272.8638224272529\n",
      "length of actions is  245\n",
      "223.1065076262413\n",
      "length of actions is  740\n",
      "269.2957107234727\n",
      "length of actions is  209\n",
      "Your final reward is : 257.22\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2832])\n",
      "243.33612589552774\n",
      "length of actions is  279\n",
      "159.70249642816583\n",
      "length of actions is  1000\n",
      "245.71133854284759\n",
      "length of actions is  253\n",
      "267.721919146314\n",
      "length of actions is  282\n",
      "254.19076514018138\n",
      "length of actions is  303\n",
      "Your final reward is : 234.13\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1965])\n",
      "242.0843830875462\n",
      "length of actions is  264\n",
      "253.01534409867494\n",
      "length of actions is  289\n",
      "268.02449363192204\n",
      "length of actions is  239\n",
      "116.11979615121473\n",
      "length of actions is  1000\n",
      "284.6832427947378\n",
      "length of actions is  269\n",
      "Your final reward is : 232.79\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1373])\n",
      "241.3167784802065\n",
      "length of actions is  287\n",
      "267.847725691927\n",
      "length of actions is  353\n",
      "149.89330102357434\n",
      "length of actions is  1000\n",
      "263.21184956498695\n",
      "length of actions is  248\n",
      "230.27402086162428\n",
      "length of actions is  907\n",
      "Your final reward is : 230.51\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2431])\n",
      "240.5108144201439\n",
      "length of actions is  282\n",
      "277.11753458262206\n",
      "length of actions is  290\n",
      "261.73874245784384\n",
      "length of actions is  232\n",
      "134.9069225200772\n",
      "length of actions is  1000\n",
      "279.89805661920747\n",
      "length of actions is  249\n",
      "Your final reward is : 238.83\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2047])\n",
      "241.54625273216408\n",
      "length of actions is  269\n",
      "288.4329882570124\n",
      "length of actions is  255\n",
      "245.7244903308167\n",
      "length of actions is  264\n",
      "246.25101979646848\n",
      "length of actions is  293\n",
      "156.82312225437988\n",
      "length of actions is  1000\n",
      "Your final reward is : 235.76\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1497])\n",
      "249.57646119635731\n",
      "length of actions is  267\n",
      "262.3871622987993\n",
      "length of actions is  260\n",
      "242.4523789498514\n",
      "length of actions is  272\n",
      "224.70577387530687\n",
      "length of actions is  250\n",
      "281.73616861020423\n",
      "length of actions is  268\n",
      "Your final reward is : 252.17\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1675])\n",
      "129.36070708288435\n",
      "length of actions is  1000\n",
      "293.11691781916016\n",
      "length of actions is  251\n",
      "116.85009406433099\n",
      "length of actions is  1000\n",
      "267.8338909486547\n",
      "length of actions is  333\n",
      "118.69046005500101\n",
      "length of actions is  1000\n",
      "Your final reward is : 185.17\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1678])\n",
      "136.66103528370527\n",
      "length of actions is  1000\n",
      "294.1119869120373\n",
      "length of actions is  251\n",
      "241.09911549604448\n",
      "length of actions is  270\n",
      "268.23571227499156\n",
      "length of actions is  289\n",
      "314.3277687786483\n",
      "length of actions is  243\n",
      "Your final reward is : 250.89\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1497])\n",
      "241.488750923555\n",
      "length of actions is  620\n",
      "241.23510955706172\n",
      "length of actions is  261\n",
      "284.8881982340239\n",
      "length of actions is  282\n",
      "239.34015130385635\n",
      "length of actions is  281\n",
      "275.5572845664416\n",
      "length of actions is  281\n",
      "Your final reward is : 256.50\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1532])\n",
      "140.13612976868635\n",
      "length of actions is  1000\n",
      "293.01214434583994\n",
      "length of actions is  261\n",
      "222.8324995382315\n",
      "length of actions is  267\n",
      "292.62335378027126\n",
      "length of actions is  269\n",
      "266.38408260614796\n",
      "length of actions is  239\n",
      "Your final reward is : 243.00\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2354])\n",
      "135.6467964433482\n",
      "length of actions is  1000\n",
      "289.19485256146993\n",
      "length of actions is  261\n",
      "224.9171811107675\n",
      "length of actions is  286\n",
      "239.20417923262767\n",
      "length of actions is  284\n",
      "269.5821440563674\n",
      "length of actions is  256\n",
      "Your final reward is : 231.71\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1349])\n",
      "137.92100164534838\n",
      "length of actions is  1000\n",
      "290.4919103716468\n",
      "length of actions is  262\n",
      "235.73740356472837\n",
      "length of actions is  252\n",
      "277.26350242655917\n",
      "length of actions is  248\n",
      "231.42278694092386\n",
      "length of actions is  255\n",
      "Your final reward is : 234.57\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1349])\n",
      "135.1155004584993\n",
      "length of actions is  1000\n",
      "293.00974795466186\n",
      "length of actions is  259\n",
      "241.9758967951818\n",
      "length of actions is  269\n",
      "285.83116799947675\n",
      "length of actions is  297\n",
      "296.56003968841173\n",
      "length of actions is  269\n",
      "Your final reward is : 250.50\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1620])\n",
      "251.87021558068238\n",
      "length of actions is  275\n",
      "231.70284124770404\n",
      "length of actions is  257\n",
      "171.67226447870704\n",
      "length of actions is  1000\n",
      "277.83863341498187\n",
      "length of actions is  260\n",
      "279.1577347265731\n",
      "length of actions is  286\n",
      "Your final reward is : 242.45\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1621])\n",
      "232.44042485558145\n",
      "length of actions is  842\n",
      "299.8225266217023\n",
      "length of actions is  323\n",
      "278.536306783741\n",
      "length of actions is  312\n",
      "308.38189865458605\n",
      "length of actions is  229\n",
      "253.6841156119091\n",
      "length of actions is  299\n",
      "Your final reward is : 274.57\n",
      "Improve to score 274.57 at batch 537\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1498])\n",
      "129.25119635113657\n",
      "length of actions is  1000\n",
      "292.42523369367746\n",
      "length of actions is  259\n",
      "241.02563283713982\n",
      "length of actions is  263\n",
      "251.97899185063025\n",
      "length of actions is  267\n",
      "234.15439822069914\n",
      "length of actions is  245\n",
      "Your final reward is : 229.77\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1964])\n",
      "249.3379866922195\n",
      "length of actions is  290\n",
      "285.2581442842462\n",
      "length of actions is  261\n",
      "304.14956692296755\n",
      "length of actions is  262\n",
      "251.0271730210977\n",
      "length of actions is  245\n",
      "255.66556256633282\n",
      "length of actions is  244\n",
      "Your final reward is : 269.09\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1497])\n",
      "249.70742208435433\n",
      "length of actions is  294\n",
      "275.2402648636965\n",
      "length of actions is  303\n",
      "228.45974699422726\n",
      "length of actions is  279\n",
      "267.9995183117861\n",
      "length of actions is  293\n",
      "276.5679604069603\n",
      "length of actions is  256\n",
      "Your final reward is : 259.59\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2312])\n",
      "135.60455959096373\n",
      "length of actions is  1000\n",
      "297.405872200741\n",
      "length of actions is  229\n",
      "151.506135903999\n",
      "length of actions is  1000\n",
      "123.62916070797259\n",
      "length of actions is  1000\n",
      "286.770078194978\n",
      "length of actions is  237\n",
      "Your final reward is : 198.98\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1708])\n",
      "137.24632685634018\n",
      "length of actions is  1000\n",
      "297.5797332653102\n",
      "length of actions is  228\n",
      "166.1637896887631\n",
      "length of actions is  1000\n",
      "254.9020420157112\n",
      "length of actions is  282\n",
      "263.6098717352752\n",
      "length of actions is  265\n",
      "Your final reward is : 223.90\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1640])\n",
      "245.861355845408\n",
      "length of actions is  373\n",
      "303.3563745957606\n",
      "length of actions is  244\n",
      "282.3855215236795\n",
      "length of actions is  290\n",
      "147.6701229557514\n",
      "length of actions is  1000\n",
      "164.66224239285842\n",
      "length of actions is  1000\n",
      "Your final reward is : 228.79\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1813])\n",
      "137.60702431924332\n",
      "length of actions is  1000\n",
      "295.23752623462116\n",
      "length of actions is  235\n",
      "310.77190105337775\n",
      "length of actions is  247\n",
      "309.728465483504\n",
      "length of actions is  217\n",
      "154.9566160659866\n",
      "length of actions is  1000\n",
      "Your final reward is : 241.66\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2086])\n",
      "251.59879401835002\n",
      "length of actions is  294\n",
      "273.4843811790579\n",
      "length of actions is  292\n",
      "239.69098635131274\n",
      "length of actions is  309\n",
      "315.3158721468192\n",
      "length of actions is  197\n",
      "249.42682104623324\n",
      "length of actions is  299\n",
      "Your final reward is : 265.90\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1315])\n",
      "254.03911078560165\n",
      "length of actions is  279\n",
      "275.6023871974175\n",
      "length of actions is  254\n",
      "264.21319130481334\n",
      "length of actions is  263\n",
      "303.31800226914476\n",
      "length of actions is  224\n",
      "308.8879539325342\n",
      "length of actions is  200\n",
      "Your final reward is : 281.21\n",
      "Improve to score 281.21 at batch 546\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1497])\n",
      "253.7035393656014\n",
      "length of actions is  274\n",
      "277.39513821272755\n",
      "length of actions is  266\n",
      "283.76466025331763\n",
      "length of actions is  276\n",
      "242.0293165943281\n",
      "length of actions is  290\n",
      "235.89855474555083\n",
      "length of actions is  303\n",
      "Your final reward is : 258.56\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1497])\n",
      "249.2809420896738\n",
      "length of actions is  290\n",
      "280.418989639967\n",
      "length of actions is  258\n",
      "271.3250531880125\n",
      "length of actions is  299\n",
      "295.26922986050937\n",
      "length of actions is  243\n",
      "235.03255806810415\n",
      "length of actions is  298\n",
      "Your final reward is : 266.27\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1528])\n",
      "253.2051855028628\n",
      "length of actions is  279\n",
      "276.04263128031585\n",
      "length of actions is  262\n",
      "277.5785225662993\n",
      "length of actions is  280\n",
      "256.0409841102939\n",
      "length of actions is  296\n",
      "243.81507748089425\n",
      "length of actions is  289\n",
      "Your final reward is : 261.34\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1374])\n",
      "250.45539843119852\n",
      "length of actions is  297\n",
      "244.4516835626223\n",
      "length of actions is  276\n",
      "241.6970766622739\n",
      "length of actions is  320\n",
      "287.07280912405804\n",
      "length of actions is  314\n",
      "290.86279255022293\n",
      "length of actions is  209\n",
      "Your final reward is : 262.91\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1416])\n",
      "250.77886652685322\n",
      "length of actions is  293\n",
      "265.74236743971517\n",
      "length of actions is  263\n",
      "253.74527393881073\n",
      "length of actions is  285\n",
      "296.1983929137017\n",
      "length of actions is  247\n",
      "239.99582925960692\n",
      "length of actions is  288\n",
      "Your final reward is : 261.29\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1153])\n",
      "258.4178695016982\n",
      "length of actions is  269\n",
      "293.51996107663285\n",
      "length of actions is  186\n",
      "276.57003459869924\n",
      "length of actions is  284\n",
      "235.36104513832083\n",
      "length of actions is  266\n",
      "249.17250546469134\n",
      "length of actions is  263\n",
      "Your final reward is : 262.61\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1577])\n",
      "262.3593408119692\n",
      "length of actions is  286\n",
      "264.6948393604887\n",
      "length of actions is  257\n",
      "293.01437811062215\n",
      "length of actions is  246\n",
      "294.409425668313\n",
      "length of actions is  230\n",
      "259.08804788691776\n",
      "length of actions is  228\n",
      "Your final reward is : 274.71\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1100])\n",
      "257.3294699924137\n",
      "length of actions is  278\n",
      "266.08437416012146\n",
      "length of actions is  247\n",
      "251.22569032987138\n",
      "length of actions is  300\n",
      "264.1554079193998\n",
      "length of actions is  268\n",
      "229.69018592863327\n",
      "length of actions is  280\n",
      "Your final reward is : 253.70\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1497])\n",
      "262.2458179544949\n",
      "length of actions is  251\n",
      "260.9118123687455\n",
      "length of actions is  268\n",
      "302.76363296817374\n",
      "length of actions is  217\n",
      "295.16512969292893\n",
      "length of actions is  258\n",
      "283.79246368121017\n",
      "length of actions is  253\n",
      "Your final reward is : 280.98\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2198])\n",
      "260.3244417334221\n",
      "length of actions is  264\n",
      "286.42910850162434\n",
      "length of actions is  230\n",
      "267.7499308281967\n",
      "length of actions is  242\n",
      "293.85488917388244\n",
      "length of actions is  263\n",
      "160.6959298011781\n",
      "length of actions is  1000\n",
      "Your final reward is : 253.81\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2083])\n",
      "262.0557894904251\n",
      "length of actions is  254\n",
      "267.2805724864528\n",
      "length of actions is  226\n",
      "280.3333108852985\n",
      "length of actions is  226\n",
      "253.44176094238617\n",
      "length of actions is  243\n",
      "268.60540629738693\n",
      "length of actions is  309\n",
      "Your final reward is : 266.34\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1029])\n",
      "262.00713558587665\n",
      "length of actions is  242\n",
      "303.4604999903763\n",
      "length of actions is  200\n",
      "298.5985781441787\n",
      "length of actions is  933\n",
      "294.77265621654215\n",
      "length of actions is  209\n",
      "252.395973983397\n",
      "length of actions is  247\n",
      "Your final reward is : 282.25\n",
      "Improve to score 282.25 at batch 558\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1123])\n",
      "264.2420443100426\n",
      "length of actions is  245\n",
      "297.52271676001965\n",
      "length of actions is  235\n",
      "280.0845680504284\n",
      "length of actions is  232\n",
      "249.0860695084084\n",
      "length of actions is  229\n",
      "299.6678997892513\n",
      "length of actions is  211\n",
      "Your final reward is : 278.12\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1099])\n",
      "269.6925094421084\n",
      "length of actions is  277\n",
      "293.5188602990813\n",
      "length of actions is  235\n",
      "263.2357567510569\n",
      "length of actions is  204\n",
      "252.17897291436003\n",
      "length of actions is  274\n",
      "270.2910958997373\n",
      "length of actions is  250\n",
      "Your final reward is : 269.78\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1816])\n",
      "261.4695352899278\n",
      "length of actions is  265\n",
      "288.2932945269447\n",
      "length of actions is  299\n",
      "300.49109720125284\n",
      "length of actions is  216\n",
      "278.68625904288695\n",
      "length of actions is  245\n",
      "249.44451529926013\n",
      "length of actions is  280\n",
      "Your final reward is : 275.68\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1171])\n",
      "267.7670679570043\n",
      "length of actions is  241\n",
      "42.99504598684672\n",
      "length of actions is  217\n",
      "56.122514827706084\n",
      "length of actions is  139\n",
      "226.36681154164626\n",
      "length of actions is  261\n",
      "46.25551332475496\n",
      "length of actions is  208\n",
      "Your final reward is : 127.90\n",
      "torch.from_numpy(rewards) looks like  torch.Size([985])\n",
      "268.92350610200884\n",
      "length of actions is  261\n",
      "14.131963103722043\n",
      "length of actions is  198\n",
      "275.46768702063696\n",
      "length of actions is  244\n",
      "33.075885991338\n",
      "length of actions is  143\n",
      "163.67637523553162\n",
      "length of actions is  1000\n",
      "Your final reward is : 151.06\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1179])\n",
      "44.58101071791717\n",
      "length of actions is  195\n",
      "124.10355013119191\n",
      "length of actions is  1000\n",
      "264.0697506084879\n",
      "length of actions is  221\n",
      "48.62541188081872\n",
      "length of actions is  152\n",
      "59.75179173410393\n",
      "length of actions is  161\n",
      "Your final reward is : 108.23\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1106])\n",
      "270.5219461250789\n",
      "length of actions is  249\n",
      "238.12849626739361\n",
      "length of actions is  233\n",
      "230.8149193860582\n",
      "length of actions is  222\n",
      "245.3996211558193\n",
      "length of actions is  239\n",
      "265.6683499862072\n",
      "length of actions is  269\n",
      "Your final reward is : 250.11\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1349])\n",
      "273.9839163178654\n",
      "length of actions is  246\n",
      "264.17388843706385\n",
      "length of actions is  191\n",
      "55.64954060857997\n",
      "length of actions is  158\n",
      "160.16500035324214\n",
      "length of actions is  1000\n",
      "269.2365573980771\n",
      "length of actions is  260\n",
      "Your final reward is : 204.64\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1188])\n",
      "273.3916370931295\n",
      "length of actions is  259\n",
      "264.16146116177094\n",
      "length of actions is  554\n",
      "263.256902897282\n",
      "length of actions is  277\n",
      "268.8767586490718\n",
      "length of actions is  245\n",
      "234.424193941371\n",
      "length of actions is  263\n",
      "Your final reward is : 260.82\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1314])\n",
      "270.5862959881839\n",
      "length of actions is  221\n",
      "291.8809380844215\n",
      "length of actions is  204\n",
      "284.5470285179488\n",
      "length of actions is  226\n",
      "259.4683464358783\n",
      "length of actions is  247\n",
      "271.3927857410611\n",
      "length of actions is  287\n",
      "Your final reward is : 275.58\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1349])\n",
      "268.79999449794036\n",
      "length of actions is  247\n",
      "254.18728246818486\n",
      "length of actions is  199\n",
      "251.92049277702276\n",
      "length of actions is  267\n",
      "278.2245300065157\n",
      "length of actions is  200\n",
      "70.44170026908549\n",
      "length of actions is  167\n",
      "Your final reward is : 224.71\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1317])\n",
      "267.14016313341915\n",
      "length of actions is  263\n",
      "283.9535443911265\n",
      "length of actions is  220\n",
      "269.1578831534111\n",
      "length of actions is  227\n",
      "275.0127865756717\n",
      "length of actions is  239\n",
      "273.9526354623691\n",
      "length of actions is  264\n",
      "Your final reward is : 273.84\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1348])\n",
      "267.83398851632114\n",
      "length of actions is  259\n",
      "269.70172424772517\n",
      "length of actions is  251\n",
      "286.5221760339736\n",
      "length of actions is  225\n",
      "228.4022424271849\n",
      "length of actions is  235\n",
      "285.06261389945524\n",
      "length of actions is  214\n",
      "Your final reward is : 267.50\n",
      "torch.from_numpy(rewards) looks like  torch.Size([694])\n",
      "267.8331718273628\n",
      "length of actions is  250\n",
      "245.1523237562585\n",
      "length of actions is  248\n",
      "265.1011598443538\n",
      "length of actions is  228\n",
      "55.311853263219234\n",
      "length of actions is  150\n",
      "48.199699331937694\n",
      "length of actions is  220\n",
      "Your final reward is : 176.32\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1756])\n",
      "150.94349761309056\n",
      "length of actions is  1000\n",
      "199.99618570325646\n",
      "length of actions is  1000\n",
      "155.77475093133268\n",
      "length of actions is  1000\n",
      "259.44185555581737\n",
      "length of actions is  274\n",
      "169.11530511556234\n",
      "length of actions is  1000\n",
      "Your final reward is : 187.05\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1187])\n",
      "270.8884096656419\n",
      "length of actions is  254\n",
      "264.1989825726839\n",
      "length of actions is  215\n",
      "234.6445046791696\n",
      "length of actions is  263\n",
      "281.6920204193667\n",
      "length of actions is  250\n",
      "66.6246361330684\n",
      "length of actions is  116\n",
      "Your final reward is : 223.61\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1415])\n",
      "269.3994744786514\n",
      "length of actions is  253\n",
      "282.9838735348708\n",
      "length of actions is  186\n",
      "250.15891068235607\n",
      "length of actions is  255\n",
      "31.791089622907037\n",
      "length of actions is  156\n",
      "298.5421518985661\n",
      "length of actions is  175\n",
      "Your final reward is : 226.58\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1091])\n",
      "271.06957668484233\n",
      "length of actions is  250\n",
      "249.36217597362548\n",
      "length of actions is  273\n",
      "22.62331784570837\n",
      "length of actions is  180\n",
      "269.5434217562796\n",
      "length of actions is  205\n",
      "290.27127203581784\n",
      "length of actions is  204\n",
      "Your final reward is : 220.57\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1079])\n",
      "56.54784194340672\n",
      "length of actions is  185\n",
      "285.2385269534494\n",
      "length of actions is  259\n",
      "68.61998331194528\n",
      "length of actions is  155\n",
      "59.04065832270203\n",
      "length of actions is  158\n",
      "281.12903403308644\n",
      "length of actions is  230\n",
      "Your final reward is : 150.12\n",
      "torch.from_numpy(rewards) looks like  torch.Size([883])\n",
      "270.9028205552369\n",
      "length of actions is  265\n",
      "266.99838166727795\n",
      "length of actions is  276\n",
      "286.2328602758348\n",
      "length of actions is  246\n",
      "-203.28904251042866\n",
      "length of actions is  788\n",
      "259.0113984792322\n",
      "length of actions is  231\n",
      "Your final reward is : 175.97\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1039])\n",
      "267.6819748785274\n",
      "length of actions is  252\n",
      "272.2976327638739\n",
      "length of actions is  262\n",
      "282.15405997235075\n",
      "length of actions is  490\n",
      "316.76593318105495\n",
      "length of actions is  229\n",
      "33.57209545813788\n",
      "length of actions is  180\n",
      "Your final reward is : 234.49\n",
      "torch.from_numpy(rewards) looks like  torch.Size([2042])\n",
      "45.89156417202926\n",
      "length of actions is  184\n",
      "292.7792919892541\n",
      "length of actions is  253\n",
      "185.69269653317957\n",
      "length of actions is  1000\n",
      "268.89244772304016\n",
      "length of actions is  246\n",
      "282.58524367535506\n",
      "length of actions is  222\n",
      "Your final reward is : 215.17\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1349])\n",
      "266.26632836536066\n",
      "length of actions is  238\n",
      "16.213607566424514\n",
      "length of actions is  202\n",
      "167.84308994279237\n",
      "length of actions is  1000\n",
      "18.209564860248364\n",
      "length of actions is  198\n",
      "160.94063516404546\n",
      "length of actions is  1000\n",
      "Your final reward is : 125.89\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1315])\n",
      "262.9804690654372\n",
      "length of actions is  264\n",
      "164.3521596034811\n",
      "length of actions is  1000\n",
      "286.97569060552314\n",
      "length of actions is  224\n",
      "267.67351288991347\n",
      "length of actions is  211\n",
      "281.5934788466583\n",
      "length of actions is  219\n",
      "Your final reward is : 252.72\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1175])\n",
      "265.13918086342676\n",
      "length of actions is  242\n",
      "304.0955531196722\n",
      "length of actions is  204\n",
      "254.51945362640626\n",
      "length of actions is  244\n",
      "307.2710772507859\n",
      "length of actions is  175\n",
      "303.3568156435153\n",
      "length of actions is  211\n",
      "Your final reward is : 286.88\n",
      "Improve to score 286.88 at batch 583\n",
      "torch.from_numpy(rewards) looks like  torch.Size([987])\n",
      "265.99416006214415\n",
      "length of actions is  246\n",
      "276.0967393671049\n",
      "length of actions is  189\n",
      "271.65550321994357\n",
      "length of actions is  246\n",
      "42.85320226513784\n",
      "length of actions is  94\n",
      "262.47644922921234\n",
      "length of actions is  226\n",
      "Your final reward is : 223.82\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1317])\n",
      "267.0989472109962\n",
      "length of actions is  245\n",
      "308.0497545049219\n",
      "length of actions is  175\n",
      "275.3247612693935\n",
      "length of actions is  237\n",
      "53.63836004993098\n",
      "length of actions is  164\n",
      "241.6370785201803\n",
      "length of actions is  268\n",
      "Your final reward is : 229.15\n",
      "torch.from_numpy(rewards) looks like  torch.Size([934])\n",
      "265.0808142284577\n",
      "length of actions is  238\n",
      "243.44357105780182\n",
      "length of actions is  257\n",
      "234.26348415601174\n",
      "length of actions is  240\n",
      "232.12178516463575\n",
      "length of actions is  266\n",
      "304.4942734861812\n",
      "length of actions is  236\n",
      "Your final reward is : 255.88\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1224])\n",
      "266.19862847357285\n",
      "length of actions is  242\n",
      "309.6138297095679\n",
      "length of actions is  213\n",
      "277.6908739833339\n",
      "length of actions is  249\n",
      "248.3483443937708\n",
      "length of actions is  285\n",
      "158.33665536056841\n",
      "length of actions is  1000\n",
      "Your final reward is : 252.04\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1993])\n",
      "148.3841477993065\n",
      "length of actions is  1000\n",
      "305.59575498637986\n",
      "length of actions is  216\n",
      "281.6002182158877\n",
      "length of actions is  236\n",
      "293.14324262872475\n",
      "length of actions is  192\n",
      "155.63879578934788\n",
      "length of actions is  1000\n",
      "Your final reward is : 236.87\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1178])\n",
      "263.5932936491471\n",
      "length of actions is  241\n",
      "260.3233090274041\n",
      "length of actions is  247\n",
      "289.89232070876596\n",
      "length of actions is  232\n",
      "289.51369967672593\n",
      "length of actions is  215\n",
      "289.4813149156115\n",
      "length of actions is  213\n",
      "Your final reward is : 278.56\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1187])\n",
      "257.93894972400005\n",
      "length of actions is  244\n",
      "245.01288755230928\n",
      "length of actions is  254\n",
      "264.5002136747036\n",
      "length of actions is  242\n",
      "271.9184637791266\n",
      "length of actions is  213\n",
      "276.7037581278141\n",
      "length of actions is  224\n",
      "Your final reward is : 263.21\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1214])\n",
      "258.7578073907467\n",
      "length of actions is  267\n",
      "275.83348388669737\n",
      "length of actions is  225\n",
      "232.14890096741297\n",
      "length of actions is  255\n",
      "275.6295600675081\n",
      "length of actions is  249\n",
      "19.25727474492666\n",
      "length of actions is  147\n",
      "Your final reward is : 212.33\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1102])\n",
      "257.752009711359\n",
      "length of actions is  285\n",
      "50.09701555047124\n",
      "length of actions is  145\n",
      "32.2511383414184\n",
      "length of actions is  140\n",
      "252.6728714064093\n",
      "length of actions is  249\n",
      "295.82686216588365\n",
      "length of actions is  228\n",
      "Your final reward is : 177.72\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1178])\n",
      "252.87199185821638\n",
      "length of actions is  303\n",
      "50.85411430667688\n",
      "length of actions is  155\n",
      "290.8775529819893\n",
      "length of actions is  171\n",
      "261.4266481710918\n",
      "length of actions is  264\n",
      "299.9513345414905\n",
      "length of actions is  178\n",
      "Your final reward is : 231.20\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1002])\n",
      "252.1922445159163\n",
      "length of actions is  289\n",
      "237.66257993906385\n",
      "length of actions is  277\n",
      "239.74006072213925\n",
      "length of actions is  261\n",
      "296.6336243368898\n",
      "length of actions is  224\n",
      "44.86612284858447\n",
      "length of actions is  171\n",
      "Your final reward is : 214.22\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1314])\n",
      "253.70691762357774\n",
      "length of actions is  255\n",
      "237.3399451978163\n",
      "length of actions is  254\n",
      "260.6666046119486\n",
      "length of actions is  269\n",
      "234.6382825833148\n",
      "length of actions is  243\n",
      "219.99793878571717\n",
      "length of actions is  281\n",
      "Your final reward is : 241.27\n",
      "torch.from_numpy(rewards) looks like  torch.Size([950])\n",
      "246.9836095123593\n",
      "length of actions is  309\n",
      "278.14752604502326\n",
      "length of actions is  208\n",
      "256.0232781543649\n",
      "length of actions is  205\n",
      "27.680532657901693\n",
      "length of actions is  141\n",
      "48.59537954081341\n",
      "length of actions is  135\n",
      "Your final reward is : 171.49\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1735])\n",
      "238.2250862814921\n",
      "length of actions is  904\n",
      "231.13831868629106\n",
      "length of actions is  258\n",
      "260.72895656609205\n",
      "length of actions is  331\n",
      "259.7315398083988\n",
      "length of actions is  279\n",
      "37.33893251040004\n",
      "length of actions is  152\n",
      "Your final reward is : 205.43\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1312])\n",
      "246.75014691068677\n",
      "length of actions is  308\n",
      "127.7785323084635\n",
      "length of actions is  1000\n",
      "158.917559982051\n",
      "length of actions is  1000\n",
      "158.12541359448608\n",
      "length of actions is  1000\n",
      "269.42720626024004\n",
      "length of actions is  324\n",
      "Your final reward is : 192.20\n",
      "torch.from_numpy(rewards) looks like  torch.Size([1600])\n",
      "249.77858732961397\n",
      "length of actions is  301\n",
      "172.23713559113952\n",
      "length of actions is  1000\n",
      "232.5485632044008\n",
      "length of actions is  263\n",
      "147.83103856758947\n",
      "length of actions is  1000\n",
      "244.11285781295066\n",
      "length of actions is  224\n",
      "Your final reward is : 209.30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EPISODE_PER_BATCH = 5  # 每蒐集 5 個 episodes 更新一次 agent\n",
    "NUM_BATCH = 600        # 總共更新 400 次\n",
    "BATCH_SIZE = 32\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "\n",
    "best_score = 0\n",
    "best_batch = 0\n",
    "\n",
    "# 訓練前，先確保 network 處在 training 模式\n",
    "agent.main_q_network.train()\n",
    "agent.target_q_network.train()\n",
    "steps_done = 0\n",
    "\n",
    "avg_total_rewards, avg_final_rewards = [], []\n",
    "\n",
    "prg_bar = tqdm(range(NUM_BATCH))\n",
    "for batch in prg_bar:\n",
    "\n",
    "    rewards = []\n",
    "    total_rewards, final_rewards = [], []\n",
    "\n",
    "    # 蒐集訓練資料\n",
    "    for episode in range(EPISODE_PER_BATCH):\n",
    "        \n",
    "        observation = env.reset() # 環境的初始化\n",
    "        state = observation  # 將觀測結果直接當成狀態s使用\n",
    "        state = torch.from_numpy(state).type(\n",
    "                torch.FloatTensor)  # 將NumPy變數轉換成PyTorch的張量\n",
    "        state = torch.unsqueeze(state, 0)  # 將size 4轉換成size 1x4\n",
    "        total_reward, total_step = 0, 0\n",
    "\n",
    "        while True:\n",
    "\n",
    "            action = agent.get_action(state, batch)  # 求出動作\n",
    "            # 執行動作a_t後，算出s_{t+1}與done旗標\n",
    "            # 根據action指定.item()、再取得內容\n",
    "            observation_next, reward, done, _ = env.step(action.item())  # 不會用到info，所以設定為_\n",
    "\n",
    "            total_reward += reward\n",
    "            total_step += 1\n",
    "            rewards.append(reward) #改這裡\n",
    "            # ! 重要 ！\n",
    "            # 現在的reward 的implementation 為每個時刻的瞬時reward, 給定action_list : a1, a2, a3 ......\n",
    "            #                                                       reward :     r1, r2 ,r3 ......\n",
    "            # medium：將reward調整成accumulative decaying reward, 給定action_list : a1,                         a2,                           a3 ......\n",
    "            #                                                       reward :     r1+0.99*r2+0.99^2*r3+......, r2+0.99*r3+0.99^2*r4+...... ,r3+0.99*r4+0.99^2*r5+ ......\n",
    "            # boss : implement DQN\n",
    "            if done:\n",
    "                state_next = None  # 沒有下個狀態，所以存入None\n",
    "\n",
    "            else:\n",
    "                state_next = observation_next  # 直接將觀測結果當成狀態使用\n",
    "                state_next = torch.from_numpy(state_next).type(\n",
    "                        torch.FloatTensor)  # 將numpy變數轉換成PyTorch的張量\n",
    "                state_next = torch.unsqueeze(state_next, 0)  # 將size 4轉換成size 1x4\n",
    "                \n",
    "            # 將學習經驗存入記憶體\n",
    "            agent.memorize(state, action, state_next, torch.FloatTensor([reward]))\n",
    "            \n",
    "            # 以Experience Replay更新Q函數\n",
    "            agent.update_q_function()\n",
    "            \n",
    "            # 觀測狀態的更新\n",
    "            state = state_next\n",
    "            \n",
    "            # 結束時的處理\n",
    "            if done:\n",
    "                final_rewards.append(reward)\n",
    "                total_rewards.append(total_reward)\n",
    "                break\n",
    "                \n",
    "\n",
    "    #print(f\"rewards looks like \", np.shape(rewards))      \n",
    "    # 紀錄訓練過程\n",
    "    avg_total_reward = sum(total_rewards) / len(total_rewards)\n",
    "    avg_final_reward = sum(final_rewards) / len(final_rewards)\n",
    "    avg_total_rewards.append(avg_total_reward)\n",
    "    avg_final_rewards.append(avg_final_reward)\n",
    "    prg_bar.set_description(f\"Total: {avg_total_reward: 4.1f}, Final: {avg_final_reward: 4.1f}\")\n",
    "\n",
    "    # 更新網路\n",
    "    # rewards = np.concatenate(rewards, axis=0)\n",
    "    #rewards = (rewards - np.mean(rewards)) / (np.std(rewards) + 1e-9)  # 將 reward 正規標準化\n",
    "    agent.update_target_q_function()\n",
    "    print(\"torch.from_numpy(rewards) looks like \", torch.from_numpy(np.array(rewards)).size())\n",
    "\n",
    "\n",
    "    ### testing\n",
    "\n",
    "    fix(env, seed)\n",
    "    agent.main_q_network.eval()  # 測試前先將 network 切換為 evaluation 模式\n",
    "    NUM_OF_TEST = 5 # Do not revise it !!!!!\n",
    "    test_total_reward = []\n",
    "    action_list = []\n",
    "    for i in range(NUM_OF_TEST):\n",
    "        actions = []\n",
    "        state = env.reset()\n",
    "\n",
    "        #img = plt.imshow(env.render(mode='rgb_array'))\n",
    "\n",
    "        total_reward = 0\n",
    "\n",
    "        done = False\n",
    "        while not done:\n",
    "            action = agent.get_action(state, episode=i, test=True)\n",
    "            actions.append(action)\n",
    "            state, reward, done, _ = env.step(action)\n",
    "\n",
    "            total_reward += reward\n",
    "\n",
    "            #img.set_data(env.render(mode='rgb_array'))\n",
    "            #display.display(plt.gcf())\n",
    "            #display.clear_output(wait=True)\n",
    "        print(total_reward)\n",
    "        test_total_reward.append(total_reward)\n",
    "\n",
    "        action_list.append(actions) #儲存你測試的結果\n",
    "        print(\"length of actions is \", len(actions))\n",
    "    print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))\n",
    "    if np.mean(test_total_reward) > 250:\n",
    "        distribution = {}\n",
    "        for actions in action_list:\n",
    "            for action in actions:\n",
    "                if action not in distribution.keys():\n",
    "                    distribution[action] = 1\n",
    "                else:\n",
    "                    distribution[action] += 1\n",
    "        PATH = \"Action_List_test\" + str(batch) + \".npy\" # 可以改成你想取的名字或路徑\n",
    "        np.save(PATH ,np.array(action_list)) \n",
    "        if np.mean(test_total_reward) > best_score:\n",
    "            best_score = np.mean(test_total_reward)\n",
    "            best_batch = batch\n",
    "            print('Improve to score %.2f at batch %d'% (best_score, best_batch ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNb_tuFYhKVK"
   },
   "source": [
    "### 訓練結果\n",
    "\n",
    "訓練過程中，我們持續記下了 `avg_total_reward`，這個數值代表的是：每次更新 policy network 前，我們讓 agent 玩數個回合（episodes），而這些回合的平均 total rewards 為何。\n",
    "理論上，若是 agent 一直在進步，則所得到的 `avg_total_reward` 也會持續上升，直至 250 上下。\n",
    "若將其畫出來則結果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1622995846123,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "wZYOI8H10SHN",
    "outputId": "99efb48d-4b6b-4d14-9142-daf0b0fd6a80"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "end = time.time()\n",
    "plt.plot(avg_total_rewards)\n",
    "plt.title(\"Total Rewards\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mV5jj4dThz0Y"
   },
   "source": [
    "另外，`avg_final_reward` 代表的是多個回合的平均 final rewards，而 final reward 即是 agent 在單一回合中拿到的最後一個 reward。\n",
    "如果同學們還記得環境給予登月小艇 reward 的方式，便會知道，不論**回合的最後**小艇是不幸墜毀、飛出畫面、或是靜止在地面上，都會受到額外地獎勵或處罰。\n",
    "也因此，final reward 可被用來觀察 agent 的「著地」是否順利等資訊。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1622995846124,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "txDZ5vlGWz5w",
    "outputId": "e0d49c30-d325-4796-8835-dfdbd21154c6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(avg_final_rewards)\n",
    "plt.title(\"Final Rewards\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyT7tNwkVdS-"
   },
   "source": [
    "訓練時間\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 34,
     "status": "ok",
     "timestamp": 1622995846125,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "_t-JsKxUViFy",
    "outputId": "53bda640-a275-49bb-9d43-95f8657a2361"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total time is 3853.3108212947845 sec\n"
     ]
    }
   ],
   "source": [
    "print(f\"total time is {end-start} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1622995934275,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "YrDaF1ORGIbj",
    "outputId": "9ffd6a9b-8057-4c4f-c4af-910c9f630188"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583"
      ]
     },
     "execution_count": 28,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "seT4NUmWmAZ1"
   },
   "source": [
    "# Server 測試\n",
    "到時候下面會是我們Server上測試的環境，可以給大家看一下自己的表現如何"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "executionInfo": {
     "elapsed": 1248,
     "status": "ok",
     "timestamp": 1622996464716,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "U69c-YTxaw6b",
    "outputId": "5c004f64-b743-41d1-afa2-4b02ac279b2d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/torch/__init__.py:422: UserWarning: torch.set_deterministic is deprecated and will be removed in a future release. Please use torch.use_deterministic_algorithms instead\n",
      "  \"torch.set_deterministic is deprecated and will be removed in a future \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your reward is : 265.14\n",
      "Your reward is : 304.10\n",
      "Your reward is : 254.52\n",
      "Your reward is : 307.27\n",
      "Your reward is : 303.36\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH = \"Action_List_test\" + str(best_batch) + \".npy\"\n",
    "action_list = np.load(PATH,allow_pickle=True) #到時候你上傳的檔案\n",
    "seed = 543 #到時候測試的seed 請不要更改\n",
    "fix(env, seed)\n",
    "\n",
    "#agent.network.eval()  # 測試前先將 network 切換為 evaluation 模式\n",
    "\n",
    "test_total_reward = []\n",
    "for actions in action_list:\n",
    "    state = env.reset()\n",
    "    img = plt.imshow(env.render(mode='rgb_array'))\n",
    "\n",
    "    total_reward = 0\n",
    "\n",
    "    done = False\n",
    "    # while not done:\n",
    "    done_count = 0\n",
    "    for action in actions:\n",
    "        # action, _ = agent1.sample(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        done_count += 1\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "    #   img.set_data(env.render(mode='rgb_array'))\n",
    "    #   display.display(plt.gcf())\n",
    "    #   display.clear_output(wait=True)\n",
    "    print(f\"Your reward is : %.2f\"%total_reward)\n",
    "    test_total_reward.append(total_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjFBWwQP1hVe"
   },
   "source": [
    "# 你的成績"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1622995846923,
     "user": {
      "displayName": "白曜瑋",
      "photoUrl": "",
      "userId": "08022902471796002564"
     },
     "user_tz": -480
    },
    "id": "GpJpZz3Wbm0X",
    "outputId": "1fddf04b-1f66-4ddd-e6a4-c4f3cfce8b0a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your final reward is : 286.88\n"
     ]
    }
   ],
   "source": [
    "print(f\"Your final reward is : %.2f\"%np.mean(test_total_reward))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "* https://github.com/ranjitation/DQN-for-LunarLander\n",
    "* https://github.com/udacity/deep-reinforcement-learning\n",
    "* https://github.com/openai/baselines\n",
    "* https://github.com/YutaroOgawa/Deep-Reinforcement-Learning-Book\n",
    "* https://pytorch.org/tutorials/intermediate/reinforcement_q_learning.html\n",
    "* https://titanwolf.org/Network/Articles/Article?AID=15c7d9d5-1a0a-41e8-96fb-23a900e10d3b#gsc.tab=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wUBtYXG2eaqf"
   },
   "source": [
    "## 參考資料\n",
    "\n",
    "以下是一些有用的參考資料。\n",
    "建議同學們實做前，可以先參考第一則連結的上課影片。\n",
    "在影片的最後有提到兩個有用的 Tips，這對於本次作業的實做非常有幫助。\n",
    "\n",
    "- [DRL Lecture 1: Policy Gradient (Review)](https://youtu.be/z95ZYgPgXOY)\n",
    "- [ML Lecture 23-3: Reinforcement Learning (including Q-learning) start at 30:00](https://youtu.be/2-JNBzCq77c?t=1800)\n",
    "- [Lecture 7: Policy Gradient, David Silver](http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching_files/pg.pdf)\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "hw12_dqn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "09d8700c082848af8328d746998e721b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Total:  250.4, Final:  100.0: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_976ca84aba354ed1ad46487b9e91c8ea",
      "max": 600,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_98c7bd45812b402d95230e781fb7cfec",
      "value": 600
     }
    },
    "4aef868dce034f94a52ce46fd19cbc88": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cf7ecf87efa5404982dc47579d1275cb",
      "placeholder": "​",
      "style": "IPY_MODEL_88588620a2314c1b87eb37a1a84b0a7c",
      "value": " 600/600 [1:04:02&lt;00:00,  6.40s/it]"
     }
    },
    "88588620a2314c1b87eb37a1a84b0a7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "933a3ea3831648e4bcb7079e47580691": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_09d8700c082848af8328d746998e721b",
       "IPY_MODEL_4aef868dce034f94a52ce46fd19cbc88"
      ],
      "layout": "IPY_MODEL_ca77cc53f271432ca4f311eb34098250"
     }
    },
    "976ca84aba354ed1ad46487b9e91c8ea": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "98c7bd45812b402d95230e781fb7cfec": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "ca77cc53f271432ca4f311eb34098250": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cf7ecf87efa5404982dc47579d1275cb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
